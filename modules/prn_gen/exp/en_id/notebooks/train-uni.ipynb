{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740675351638,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "a0a0765a-0875-4b33-ecc4-bd79a983e1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn_gen/exp/en_id\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5402,
     "status": "ok",
     "timestamp": 1740675357038,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "a2a9c1c8-0899-4fd8-ba03-79f0c447b594"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8519,
     "status": "ok",
     "timestamp": 1740675365559,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7e8d72e5-7442-46de-cd60-a0b8d7a078e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1740675365597,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740675365637,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL = \"dot\"\n",
    "EMB_DIM = \"64\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"128\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1740675365872,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "6b054b91-1e7f-4738-c254-2f9c73138c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/en_ma\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"val_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1740675365908,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list, lang_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list) == len(lang_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "    # Handle lang\n",
    "    self.lang_list = lang_list\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    lang = self.lang_list[index]\n",
    "    return graphemes, phonemes, lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740675365912,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.'))\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675365919,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[1]) for pair in pairs]\n",
    "    lang_list = [pair[2] for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list, lang_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1775,
     "status": "ok",
     "timestamp": 1740675367697,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "ec8792bd-f2b2-4246-9f0b-b93dbb078385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n",
      "EN_WEIGHT: 0.6141991030673498\n",
      "ID_WEIGHT: 2.6891590501596188\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "\n",
    "# Initialize weight loss for en and id\n",
    "N = len(train_pairs)\n",
    "K = 2\n",
    "EN_WEIGHT = N/(K * sum(1 for pair in train_pairs if pair[2]==\"en\"))\n",
    "ID_WEIGHT = N/(K * sum(1 for pair in train_pairs if pair[2]==\"ma\"))\n",
    "print(f\"EN_WEIGHT: {EN_WEIGHT}\")\n",
    "print(f\"ID_WEIGHT: {ID_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740675367742,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq, lang), ...]\n",
    "  graphemes, phonemes, langs = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded, langs\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1740675367879,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1)\n",
    "  if USE_CUDA :\n",
    "    var = var.cuda()\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1740675367882,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "b03a688e-d182-44ca-a5ee-f8e0b5679352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 19, 12, 26, 19, 8, 14, 19, 30, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740675367884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "801ff8d1-c0c5-49fc-a337-df5484e9e424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f2ed5826ee0> ([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "train grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "valid grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "test grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "train phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "valid phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "test phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'd': 9, 'v': 27, 'z': 31, 'f': 11, 'j': 15, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'd': 9, 'v': 27, 'z': 31, 'f': 11, 'j': 15, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'd': 9, 'v': 27, 'z': 31, 'f': 11, 'j': 15, 'x': 29}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'HH': 15, 'G': 14, 'D': 10, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'F': 13, 'JH': 17, 'Y': 34, 'OY': 24}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'HH': 15, 'G': 14, 'D': 10, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'F': 13, 'JH': 17, 'Y': 34, 'OY': 24}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'HH': 15, 'G': 14, 'D': 10, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'F': 13, 'JH': 17, 'Y': 34, 'OY': 24}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367889,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False)\n",
    "    if USE_CUDA :\n",
    "      self.embedding = self.embedding.cuda()\n",
    "      self.gru = self.gru.cuda()\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    if USE_CUDA :\n",
    "      hidden = hidden.cuda()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367890,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "      if USE_CUDA :\n",
    "        self.attn = self.attn.cuda()\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "      if USE_CUDA :\n",
    "        self.attn = self.attn.cuda()\n",
    "        self.v = self.v.cuda()\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740675367895,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    if USE_CUDA :\n",
    "      self.embedding = self.embedding.cuda()\n",
    "      self.gru = self.gru.cuda()\n",
    "      self.out = self.out.cuda()\n",
    "      self.attn = self.attn.cuda()\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740675367910,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "7c50e3bf-898c-41ed-9c99-f73b0bcbb1f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]])\n",
    "if USE_CUDA :\n",
    "  input_batch = input_batch.cuda()\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "if USE_CUDA :\n",
    "  decoder_input = decoder_input.cuda()\n",
    "  decoder_context = decoder_context.cuda()\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367916,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1740675368009,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, langs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "  if USE_CUDA :\n",
    "    input_batch = input_batch.cuda()\n",
    "    target_batch = target_batch.cuda()\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size])\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    if USE_CUDA :\n",
    "      decoder_input = decoder_input.cuda()\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Apply language weights\n",
    "  weights = torch.tensor([EN_WEIGHT if lang==\"en\" else ID_WEIGHT for lang in langs])\n",
    "  if USE_CUDA :\n",
    "    weights = weights.cuda()\n",
    "  weighted_loss = (loss * weights).mean()\n",
    "\n",
    "  # Backpropagate weighted loss\n",
    "  weighted_loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item(), weighted_loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  if USE_CUDA :\n",
    "    input_batch = input_batch.cuda()\n",
    "    target_batch = target_batch.cuda()\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size])\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1857,
     "status": "ok",
     "timestamp": 1740675369864,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "95183643-e690-43c7-c973-86c6d9cce6ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 64\n",
      "hidden_size: 128\n",
      "n_layers: 1\n",
      "Encoder has a total number of 76544 parameters\n",
      "Decoder has a total number of 135204 parameters\n",
      "Total number of all parameters is 211748\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA :\n",
    "  encoder.cuda()\n",
    "  decoder.cuda()\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "200a4116-04e5-447b-885d-c22f6ad6642f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 1 finished in 0m 46.41s (- 76m 35.05s) (1 1.0%). train avg loss: 1.087, val avg loss: 1.0775\n",
      "Training for epoch 2 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 2 finished in 1m 31.13s (- 74m 25.48s) (2 2.0%). train avg loss: 0.5423, val avg loss: 1.0679\n",
      "Training for epoch 3 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 3 finished in 2m 17.32s (- 74m 0.06s) (3 3.0%). train avg loss: 0.4734, val avg loss: 0.9765\n",
      "Training for epoch 4 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 4 finished in 3m 4.23s (- 73m 41.45s) (4 4.0%). train avg loss: 0.4588, val avg loss: 0.8883\n",
      "Training for epoch 5 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 5 finished in 3m 51.29s (- 73m 14.53s) (5 5.0%). train avg loss: 0.4379, val avg loss: 0.9851\n",
      "Training for epoch 6 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 6 finished in 4m 38.83s (- 72m 48.3s) (6 6.0%). train avg loss: 0.3875, val avg loss: 0.867\n",
      "Training for epoch 7 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 7 finished in 5m 26.19s (- 72m 13.66s) (7 7.0%). train avg loss: 0.3526, val avg loss: 0.8603\n",
      "Training for epoch 8 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 8 finished in 6m 11.18s (- 71m 8.57s) (8 8.0%). train avg loss: 0.3626, val avg loss: 0.8406\n",
      "Training for epoch 9 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 9 finished in 6m 59.67s (- 70m 43.36s) (9 9.0%). train avg loss: 0.3625, val avg loss: 0.8918\n",
      "Training for epoch 10 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 10 finished in 7m 50.13s (- 70m 31.14s) (10 10.0%). train avg loss: 0.3484, val avg loss: 0.8329\n",
      "Training for epoch 11 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 11 finished in 8m 39.5s (- 70m 3.26s) (11 11.0%). train avg loss: 0.3233, val avg loss: 0.8599\n",
      "Training for epoch 12 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 12 finished in 9m 27.3s (- 69m 20.22s) (12 12.0%). train avg loss: 0.3186, val avg loss: 0.8032\n",
      "Training for epoch 13 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 13 finished in 10m 15.29s (- 68m 37.7s) (13 13.0%). train avg loss: 0.3101, val avg loss: 0.7815\n",
      "Training for epoch 14 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 14 finished in 11m 2.87s (- 67m 51.93s) (14 14.0%). train avg loss: 0.2884, val avg loss: 0.789\n",
      "Training for epoch 15 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 15 finished in 11m 50.13s (- 67m 4.05s) (15 15.0%). train avg loss: 0.3236, val avg loss: 0.842\n",
      "Training for epoch 16 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 16 finished in 12m 38.92s (- 66m 24.3s) (16 16.0%). train avg loss: 0.2749, val avg loss: 0.7655\n",
      "Training for epoch 17 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 17 finished in 13m 28.96s (- 65m 49.61s) (17 17.0%). train avg loss: 0.2902, val avg loss: 0.9274\n",
      "Training for epoch 18 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 18 finished in 14m 19.4s (- 65m 15.05s) (18 18.0%). train avg loss: 0.2788, val avg loss: 0.7441\n",
      "Training for epoch 19 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 19 finished in 15m 8.99s (- 64m 35.16s) (19 19.0%). train avg loss: 0.2713, val avg loss: 0.7586\n",
      "Training for epoch 20 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 20 finished in 15m 58.69s (- 63m 54.78s) (20 20.0%). train avg loss: 0.3059, val avg loss: 0.7202\n",
      "Training for epoch 21 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 21 finished in 16m 47.18s (- 63m 8.93s) (21 21.0%). train avg loss: 0.2511, val avg loss: 0.7554\n",
      "Training for epoch 22 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 22 finished in 17m 34.76s (- 62m 19.62s) (22 22.0%). train avg loss: 0.2517, val avg loss: 0.7425\n",
      "Training for epoch 23 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 23 finished in 18m 23.89s (- 61m 35.62s) (23 23.0%). train avg loss: 0.2925, val avg loss: 0.7493\n",
      "Training for epoch 24 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 24 finished in 19m 13.2s (- 60m 51.79s) (24 24.0%). train avg loss: 0.2541, val avg loss: 0.6848\n",
      "Training for epoch 25 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 25 finished in 20m 1.65s (- 60m 4.94s) (25 25.0%). train avg loss: 0.2403, val avg loss: 0.6903\n",
      "Training for epoch 26 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 26 finished in 20m 51.12s (- 59m 20.88s) (26 26.0%). train avg loss: 0.2528, val avg loss: 0.712\n",
      "Training for epoch 27 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 27 finished in 21m 39.83s (- 58m 34.34s) (27 27.0%). train avg loss: 0.233, val avg loss: 0.6729\n",
      "Training for epoch 28 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 28 finished in 22m 25.45s (- 57m 39.74s) (28 28.0%). train avg loss: 0.2499, val avg loss: 0.7024\n",
      "Training for epoch 29 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 29 finished in 23m 13.55s (- 56m 51.8s) (29 29.0%). train avg loss: 0.2383, val avg loss: 0.7145\n",
      "Training for epoch 30 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 30 finished in 24m 16.48s (- 56m 38.44s) (30 30.0%). train avg loss: 0.2306, val avg loss: 0.682\n",
      "Training for epoch 31 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 31 finished in 25m 2.45s (- 55m 44.17s) (31 31.0%). train avg loss: 0.2203, val avg loss: 0.7047\n",
      "Training for epoch 32 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 32 finished in 25m 51.72s (- 54m 57.4s) (32 32.0%). train avg loss: 0.245, val avg loss: 0.7086\n",
      "Training for epoch 33 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 33 finished in 26m 36.61s (- 54m 1.6s) (33 33.0%). train avg loss: 0.2159, val avg loss: 0.6767\n",
      "Training for epoch 34 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 34 finished in 27m 20.95s (- 53m 5.38s) (34 34.0%). train avg loss: 0.2149, val avg loss: 0.7286\n",
      "Training for epoch 35 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 35 finished in 28m 4.74s (- 52m 8.8s) (35 35.0%). train avg loss: 0.2224, val avg loss: 0.6397\n",
      "Training for epoch 36 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 36 finished in 28m 49.52s (- 51m 14.7s) (36 36.0%). train avg loss: 0.2156, val avg loss: 0.6522\n",
      "Training for epoch 37 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 37 finished in 29m 34.31s (- 50m 21.12s) (37 37.0%). train avg loss: 0.2081, val avg loss: 0.6849\n",
      "Training for epoch 38 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 38 finished in 30m 19.88s (- 49m 29.28s) (38 38.0%). train avg loss: 0.2176, val avg loss: 0.7138\n",
      "Training for epoch 39 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 39 finished in 31m 4.88s (- 48m 36.87s) (39 39.0%). train avg loss: 0.2085, val avg loss: 0.7061\n",
      "Training for epoch 40 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 40 finished in 31m 50.13s (- 47m 45.2s) (40 40.0%). train avg loss: 0.207, val avg loss: 0.6688\n",
      "Training for epoch 41 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 41 finished in 32m 35.69s (- 46m 54.28s) (41 41.0%). train avg loss: 0.2175, val avg loss: 0.6472\n",
      "Training for epoch 42 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 42 finished in 33m 21.92s (- 46m 4.56s) (42 42.0%). train avg loss: 0.205, val avg loss: 0.6483\n",
      "Training for epoch 43 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 43 finished in 34m 8.49s (- 45m 15.45s) (43 43.0%). train avg loss: 0.1977, val avg loss: 0.6543\n",
      "Training for epoch 44 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 44 finished in 34m 53.58s (- 44m 24.56s) (44 44.0%). train avg loss: 0.203, val avg loss: 0.6471\n",
      "Training for epoch 45 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 45 finished in 35m 39.41s (- 43m 34.84s) (45 45.0%). train avg loss: 0.2167, val avg loss: 0.6734\n",
      "Training for epoch 46 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 46 finished in 36m 25.44s (- 42m 45.52s) (46 46.0%). train avg loss: 0.1977, val avg loss: 0.6199\n",
      "Training for epoch 47 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 47 finished in 37m 11.78s (- 41m 56.68s) (47 47.0%). train avg loss: 0.2003, val avg loss: 0.6382\n",
      "Training for epoch 48 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 48 finished in 37m 58.59s (- 41m 8.48s) (48 48.0%). train avg loss: 0.1922, val avg loss: 0.6788\n",
      "Training for epoch 49 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 49 finished in 38m 44.83s (- 40m 19.72s) (49 49.0%). train avg loss: 0.1946, val avg loss: 0.6433\n",
      "Training for epoch 50 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 50 finished in 39m 30.67s (- 39m 30.67s) (50 50.0%). train avg loss: 0.1919, val avg loss: 0.6032\n",
      "Training for epoch 51 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 51 finished in 40m 17.52s (- 38m 42.72s) (51 51.0%). train avg loss: 0.1824, val avg loss: 0.6004\n",
      "Training for epoch 52 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 52 finished in 41m 5.22s (- 37m 55.59s) (52 52.0%). train avg loss: 0.175, val avg loss: 0.6032\n",
      "Training for epoch 53 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 53 finished in 41m 53.54s (- 37m 8.99s) (53 53.0%). train avg loss: 0.1894, val avg loss: 0.6312\n",
      "Training for epoch 54 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 54 finished in 42m 41.41s (- 36m 21.94s) (54 54.0%). train avg loss: 0.1806, val avg loss: 0.6153\n",
      "Training for epoch 55 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 55 finished in 43m 27.13s (- 35m 33.1s) (55 55.0%). train avg loss: 0.2088, val avg loss: 0.6076\n",
      "Training for epoch 56 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 56 finished in 44m 11.6s (- 34m 43.4s) (56 56.0%). train avg loss: 0.2069, val avg loss: 0.672\n",
      "Training for epoch 57 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 57 finished in 44m 54.97s (- 33m 53.05s) (57 57.0%). train avg loss: 0.1876, val avg loss: 0.5957\n",
      "Training for epoch 58 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 58 finished in 45m 40.64s (- 33m 4.6s) (58 58.0%). train avg loss: 0.1877, val avg loss: 0.6123\n",
      "Training for epoch 59 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 59 finished in 46m 24.43s (- 32m 14.95s) (59 59.0%). train avg loss: 0.1747, val avg loss: 0.5963\n",
      "Training for epoch 60 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 60 finished in 47m 7.48s (- 31m 24.99s) (60 60.0%). train avg loss: 0.1865, val avg loss: 0.8784\n",
      "Training for epoch 61 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 61 finished in 47m 53.97s (- 30m 37.46s) (61 61.0%). train avg loss: 0.1999, val avg loss: 0.6164\n",
      "Training for epoch 62 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 62 finished in 48m 40.56s (- 29m 50.02s) (62 62.0%). train avg loss: 0.179, val avg loss: 0.6229\n",
      "Training for epoch 63 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 63 finished in 49m 24.27s (- 29m 0.92s) (63 63.0%). train avg loss: 0.1954, val avg loss: 0.619\n",
      "Training for epoch 64 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 64 finished in 50m 6.66s (- 28m 11.24s) (64 64.0%). train avg loss: 0.1859, val avg loss: 0.672\n",
      "Training for epoch 65 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 65 finished in 51m 4.92s (- 27m 30.34s) (65 65.0%). train avg loss: 0.1884, val avg loss: 0.6511\n",
      "Training for epoch 66 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 66 finished in 52m 0.72s (- 26m 47.64s) (66 66.0%). train avg loss: 0.1731, val avg loss: 0.6508\n",
      "Training for epoch 67 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 67 finished in 53m 3.26s (- 26m 7.87s) (67 67.0%). train avg loss: 0.1964, val avg loss: 0.6362\n",
      "Training for epoch 68 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 68 finished in 54m 2.55s (- 25m 25.91s) (68 68.0%). train avg loss: 0.1892, val avg loss: 0.6136\n",
      "Training for epoch 69 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 69 finished in 55m 1.66s (- 24m 43.35s) (69 69.0%). train avg loss: 0.1658, val avg loss: 0.5659\n",
      "Training for epoch 70 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 70 finished in 56m 0.45s (- 24m 0.19s) (70 70.0%). train avg loss: 0.1469, val avg loss: 0.5805\n",
      "Training for epoch 71 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 71 finished in 56m 55.62s (- 23m 15.11s) (71 71.0%). train avg loss: 0.1482, val avg loss: 0.5677\n",
      "Training for epoch 72 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 72 finished in 57m 56.11s (- 22m 31.82s) (72 72.0%). train avg loss: 0.1457, val avg loss: 0.6207\n",
      "Training for epoch 73 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 73 finished in 58m 54.81s (- 21m 47.39s) (73 73.0%). train avg loss: 0.1429, val avg loss: 0.5556\n",
      "Training for epoch 74 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 74 finished in 59m 53.78s (- 21m 2.68s) (74 74.0%). train avg loss: 0.1393, val avg loss: 0.5617\n",
      "Training for epoch 75 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 75 finished in 60m 52.74s (- 20m 17.58s) (75 75.0%). train avg loss: 0.1396, val avg loss: 0.5583\n",
      "Training for epoch 76 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 76 finished in 61m 51.59s (- 19m 32.08s) (76 76.0%). train avg loss: 0.1351, val avg loss: 0.5818\n",
      "Training for epoch 77 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 77 finished in 62m 54.65s (- 18m 47.49s) (77 77.0%). train avg loss: 0.1366, val avg loss: 0.5812\n",
      "Training for epoch 78 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 78 finished in 63m 56.88s (- 18m 2.2s) (78 78.0%). train avg loss: 0.1345, val avg loss: 0.5768\n",
      "Training for epoch 79 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 79 finished in 65m 0.98s (- 17m 16.97s) (79 79.0%). train avg loss: 0.1364, val avg loss: 0.6059\n",
      "Training for epoch 80 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 80 finished in 66m 1.79s (- 16m 30.45s) (80 80.0%). train avg loss: 0.1419, val avg loss: 0.6032\n",
      "Training for epoch 81 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 81 finished in 67m 2.89s (- 15m 43.64s) (81 81.0%). train avg loss: 0.1342, val avg loss: 0.5675\n",
      "Training for epoch 82 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 82 finished in 67m 59.66s (- 14m 55.54s) (82 82.0%). train avg loss: 0.128, val avg loss: 0.5544\n",
      "Training for epoch 83 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 83 finished in 68m 59.36s (- 14m 7.82s) (83 83.0%). train avg loss: 0.1308, val avg loss: 0.5609\n",
      "Training for epoch 84 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 84 finished in 69m 59.04s (- 13m 19.82s) (84 84.0%). train avg loss: 0.1277, val avg loss: 0.5521\n",
      "Training for epoch 85 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 85 finished in 71m 0.84s (- 12m 31.91s) (85 85.0%). train avg loss: 0.1301, val avg loss: 0.5684\n",
      "Training for epoch 86 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 86 finished in 72m 6.27s (- 11m 44.28s) (86 86.0%). train avg loss: 0.1277, val avg loss: 0.5811\n",
      "Training for epoch 87 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 87 finished in 73m 11.42s (- 10m 56.19s) (87 87.0%). train avg loss: 0.1244, val avg loss: 0.5901\n",
      "Training for epoch 88 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 88 finished in 74m 13.22s (- 10m 7.26s) (88 88.0%). train avg loss: 0.125, val avg loss: 0.5778\n",
      "Training for epoch 89 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 89 finished in 75m 19.17s (- 9m 18.55s) (89 89.0%). train avg loss: 0.1266, val avg loss: 0.6091\n",
      "Training for epoch 90 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 90 finished in 76m 23.44s (- 8m 29.27s) (90 90.0%). train avg loss: 0.1244, val avg loss: 0.5927\n",
      "Training for epoch 91 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 91 finished in 77m 25.05s (- 7m 39.4s) (91 91.0%). train avg loss: 0.1245, val avg loss: 0.594\n",
      "Training for epoch 92 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 92 finished in 78m 28.0s (- 6m 49.39s) (92 92.0%). train avg loss: 0.1242, val avg loss: 0.5714\n",
      "Training for epoch 93 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 93 finished in 79m 20.87s (- 5m 58.35s) (93 93.0%). train avg loss: 0.1221, val avg loss: 0.6134\n",
      "Training for epoch 94 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 94 finished in 80m 17.67s (- 5m 7.51s) (94 94.0%). train avg loss: 0.1184, val avg loss: 0.585\n",
      "Training for epoch 95 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 95 finished in 81m 21.12s (- 4m 16.9s) (95 95.0%). train avg loss: 0.1242, val avg loss: 0.5985\n",
      "Training for epoch 96 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 96 finished in 82m 17.45s (- 3m 25.73s) (96 96.0%). train avg loss: 0.108, val avg loss: 0.5678\n",
      "Training for epoch 97 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 97 finished in 83m 19.9s (- 2m 34.64s) (97 97.0%). train avg loss: 0.106, val avg loss: 0.6135\n",
      "Training for epoch 98 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 98 finished in 84m 19.97s (- 1m 43.26s) (98 98.0%). train avg loss: 0.1053, val avg loss: 0.5801\n",
      "Training for epoch 99 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 99 finished in 85m 20.13s (- 0m 51.72s) (99 99.0%). train avg loss: 0.1056, val avg loss: 0.5934\n",
      "Training for epoch 100 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 100 finished in 86m 18.19s (- 0m 0.0s) (100 100.0%). train avg loss: 0.1037, val avg loss: 0.6033\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns, langs) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get WEIGHTED loss\n",
    "    unweighted_train_loss, weighted_train_loss = train_batch(grps, phns, langs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track UNWEIGHTED train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns, langs in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-498emHUaNzb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5.5, min_value-.075, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]])\n",
    "    if USE_CUDA :\n",
    "      decoder_input = decoder_input.cuda()\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, arpabet_phoneme_sequence, lang = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MlSPdqo3QDyr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on val set: 19.104162699491198%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, arpabet_phoneme_sequence, lang = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on val set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "HSHGOjSmc3Vi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> schmuckler\n",
      "= ['SH', 'M', 'AA', 'K', 'L', 'AX', 'R']\n",
      "< SH M AA K L AX R ['SH', 'M', 'AA', 'K', 'L', 'AX', 'R']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d570a1d00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAGkCAYAAAAsb2x+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAYDElEQVR4nO3df2yddd3/8Xdp2RlgW2TQud0rY6BxY2MOVoL7AQyB3ZlskURRCOAU/WNS2EajwsA/EIWCRoJxUu1CZpCMLX7lxzQCDv2ygTgYgwkC4Ydws/JjzhHsGTM5uPbcf3xv+rX3GOw67ellP3s8khNyDtfhvHKF5JnrnNO2plwulwMASMYBeQ8AAAaXuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0Bikon7zTffHBMmTIiRI0fG9OnT48EHH8x7UrLa29vjxBNPjPr6+mhqaoqzzz47nnvuubxn7Vfa29ujpqYmli5dmveUpL322mtxwQUXxKhRo+Lggw+OadOmxebNm/Oelazdu3fHt771rZgwYUIcdNBBcfTRR8c111wTvb29eU8bdpKI+5o1a2Lp0qVx1VVXxRNPPBEnn3xyzJs3L7Zu3Zr3tCStX78+WltbY+PGjbFu3brYvXt3zJ07N3bt2pX3tP3Cpk2borOzM6ZOnZr3lKS99dZbMWvWrDjwwAPjnnvuiWeeeSZ+8IMfxKGHHpr3tGTdcMMN8ZOf/CSWL18ezz77bHzve9+L73//+/GjH/0o72nDTk0KfzjmpJNOihNOOCE6Ojr6Hps0aVKcffbZ0d7enuOy/cPf/va3aGpqivXr18cpp5yS95ykvf3223HCCSfEzTffHN/97ndj2rRpcdNNN+U9K0lXXHFF/OEPf/Au4BCaP39+jB49Om655Za+xz772c/GwQcfHD//+c9zXDb8DPsr93feeSc2b94cc+fO7ff43Llz4+GHH85p1f6lu7s7IiIOO+ywnJekr7W1Nc4666w444wz8p6SvLVr10ZLS0ucc8450dTUFMcff3ysWLEi71lJmz17dvzud7+L559/PiIi/vSnP8VDDz0Un/70p3NeNvzU5T1goHbs2BE9PT0xevTofo+PHj06tm3bltOq/Ue5XI62traYPXt2TJkyJe85SVu9enU8/vjjsWnTpryn7Bdeeuml6OjoiLa2trjyyivj0UcfjcWLF0ehUIgvfvGLec9L0uWXXx7d3d0xceLEqK2tjZ6enrj22mvjvPPOy3vasDPs4/6umpqafvfL5fIejzH4LrnkknjyySfjoYceyntK0rq6umLJkiXx29/+NkaOHJn3nP1Cb29vtLS0xHXXXRcREccff3w8/fTT0dHRIe5VsmbNmrjtttti1apVMXny5NiyZUssXbo0xo4dGwsXLsx73rAy7ON++OGHR21t7R5X6du3b9/jap7Bdemll8batWtjw4YNMW7cuLznJG3z5s2xffv2mD59et9jPT09sWHDhli+fHmUSqWora3NcWF6xowZE8cee2y/xyZNmhS//OUvc1qUvm984xtxxRVXxLnnnhsREccdd1y88sor0d7eLu4ZDfvP3EeMGBHTp0+PdevW9Xt83bp1MXPmzJxWpa1cLscll1wSd9xxR/z+97+PCRMm5D0peaeffno89dRTsWXLlr5bS0tLnH/++bFlyxZhr4JZs2bt8SOezz//fIwfPz6nRen7xz/+EQcc0D9LtbW1fhSuAsP+yj0ioq2tLS688MJoaWmJGTNmRGdnZ2zdujUWLVqU97Qktba2xqpVq+Luu++O+vr6vndNGhsb46CDDsp5XZrq6+v3+E7DIYccEqNGjfJdhyq57LLLYubMmXHdddfF5z//+Xj00Uejs7MzOjs7856WrAULFsS1114bRx55ZEyePDmeeOKJuPHGG+Oiiy7Ke9rwU07Ej3/84/L48ePLI0aMKJ9wwgnl9evX5z0pWRHxnreVK1fmPW2/cuqpp5aXLFmS94yk/epXvypPmTKlXCgUyhMnTix3dnbmPSlpxWKxvGTJkvKRRx5ZHjlyZPnoo48uX3XVVeVSqZT3tGEniZ9zBwD+v2H/mTsA0J+4A0BixB0AEiPuAJAYcQeAxIg7ACQmqbiXSqW4+uqro1Qq5T1lv+GcDz3nfOg550PPOR+YpH7OvVgsRmNjY3R3d0dDQ0Pec/YLzvnQc86HnnM+9JzzgUnqyh0AEHcASM6Q/+GY3t7eeP3116O+vn7Q/956sVjs90+qzzkfes750HPOh55z/t7K5XLs3Lkzxo4du8df0PtXQ/6Z+6uvvhrNzc1D+ZIAkJSurq4YN27cXv/9kF+519fXR0TE7Ph01MWBQ/3yA3L9nx/Je0LFrppzVt4TKtKzY0feEwD+beyOf8ZD8Zu+lu7NkMf93bfi6+LAqKsZXnH/UP3w/YpC3QEj8p5QkZph9v8IQFX9z3vtH/Sx9vCtFQDwnsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBITEVxv/nmm2PChAkxcuTImD59ejz44IODvQsAqFDmuK9ZsyaWLl0aV111VTzxxBNx8sknx7x582Lr1q3V2AcAZJQ57jfeeGN85Stfia9+9asxadKkuOmmm6K5uTk6OjqqsQ8AyChT3N95553YvHlzzJ07t9/jc+fOjYcffvg9n1MqlaJYLPa7AQDVkynuO3bsiJ6enhg9enS/x0ePHh3btm17z+e0t7dHY2Nj3625ubnytQDAB6roC3U1NTX97pfL5T0ee9eyZcuiu7u779bV1VXJSwIA+6guy8GHH3541NbW7nGVvn379j2u5t9VKBSiUChUvhAAyCTTlfuIESNi+vTpsW7dun6Pr1u3LmbOnDmowwCAymS6co+IaGtriwsvvDBaWlpixowZ0dnZGVu3bo1FixZVYx8AkFHmuH/hC1+IN998M6655pp44403YsqUKfGb3/wmxo8fX419AEBGmeMeEXHxxRfHxRdfPNhbAIBB4HfLA0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEhMXd4DhpOlE2blPaFiv3713rwnVGT+f0zPe0LlamryXlCZcjnvBcAAuXIHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAxmeO+YcOGWLBgQYwdOzZqamrirrvuqsYuAKBCmeO+a9eu+MQnPhHLly+vxh4AYIDqsj5h3rx5MW/evGpsAQAGQea4Z1UqlaJUKvXdLxaL1X5JANivVf0Lde3t7dHY2Nh3a25urvZLAsB+repxX7ZsWXR3d/fdurq6qv2SALBfq/rb8oVCIQqFQrVfBgD4H37OHQASk/nK/e23344XX3yx7/7LL78cW7ZsicMOOyyOPPLIQR0HAGSXOe6PPfZYnHbaaX3329raIiJi4cKF8bOf/WzQhgEAlckc9zlz5kS5XK7GFgBgEPjMHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0Bi6vIeMKyUy3kvqNj8/5ie94T9zi+7/pj3hIp87phT855QsXKplPcE+Lfgyh0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQmExxb29vjxNPPDHq6+ujqakpzj777HjuueeqtQ0AqECmuK9fvz5aW1tj48aNsW7duti9e3fMnTs3du3aVa19AEBGdVkOvvfee/vdX7lyZTQ1NcXmzZvjlFNOGdRhAEBlMsX9f+vu7o6IiMMOO2yvx5RKpSiVSn33i8XiQF4SAPgAFX+hrlwuR1tbW8yePTumTJmy1+Pa29ujsbGx79bc3FzpSwIA+6DiuF9yySXx5JNPxu233/6+xy1btiy6u7v7bl1dXZW+JACwDyp6W/7SSy+NtWvXxoYNG2LcuHHve2yhUIhCoVDROAAgu0xxL5fLcemll8add94ZDzzwQEyYMKFauwCACmWKe2tra6xatSruvvvuqK+vj23btkVERGNjYxx00EFVGQgAZJPpM/eOjo7o7u6OOXPmxJgxY/pua9asqdY+ACCjzG/LAwD/3vxueQBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJqct7AKTqnI+fnveEiqx84b68J1TsS+NPzntCZcrlvBeQGFfuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkJlPcOzo6YurUqdHQ0BANDQ0xY8aMuOeee6q1DQCoQKa4jxs3Lq6//vp47LHH4rHHHotPfepT8ZnPfCaefvrpau0DADKqy3LwggUL+t2/9tpro6OjIzZu3BiTJ08e1GEAQGUyxf1f9fT0xC9+8YvYtWtXzJgxY6/HlUqlKJVKffeLxWKlLwkA7IPMX6h76qmn4kMf+lAUCoVYtGhR3HnnnXHsscfu9fj29vZobGzsuzU3Nw9oMADw/jLH/eMf/3hs2bIlNm7cGF/72tdi4cKF8cwzz+z1+GXLlkV3d3ffraura0CDAYD3l/lt+REjRsRHP/rRiIhoaWmJTZs2xQ9/+MP46U9/+p7HFwqFKBQKA1sJAOyzAf+ce7lc7veZOgCQr0xX7ldeeWXMmzcvmpubY+fOnbF69ep44IEH4t57763WPgAgo0xx/+tf/xoXXnhhvPHGG9HY2BhTp06Ne++9N84888xq7QMAMsoU91tuuaVaOwCAQeJ3ywNAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBITF3eAyBVvbt25T2hIl86cnbeEyp23+tP5D2hIv85dlreE0iMK3cASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYgYU9/b29qipqYmlS5cO1h4AYIAqjvumTZuis7Mzpk6dOph7AIABqijub7/9dpx//vmxYsWK+PCHPzzYmwCAAago7q2trXHWWWfFGWec8YHHlkqlKBaL/W4AQPXUZX3C6tWr4/HHH49Nmzbt0/Ht7e3x7W9/O/MwAKAyma7cu7q6YsmSJXHbbbfFyJEj9+k5y5Yti+7u7r5bV1dXRUMBgH2T6cp98+bNsX379pg+fXrfYz09PbFhw4ZYvnx5lEqlqK2t7fecQqEQhUJhcNYCAB8oU9xPP/30eOqpp/o99uUvfzkmTpwYl19++R5hBwCGXqa419fXx5QpU/o9dsghh8SoUaP2eBwAyIffUAcAicn8bfn/7YEHHhiEGQDAYHHlDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAxdXkPABgs/zl2Wt4TKvKX78/Ie0LFegu9eU+oyMcWP5L3hKpy5Q4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGIyxf3qq6+OmpqafrePfOQj1doGAFSgLusTJk+eHPfff3/f/dra2kEdBAAMTOa419XVuVoHgH9jmT9zf+GFF2Ls2LExYcKEOPfcc+Oll1563+NLpVIUi8V+NwCgejLF/aSTTopbb7017rvvvlixYkVs27YtZs6cGW+++eZen9Pe3h6NjY19t+bm5gGPBgD2rqZcLpcrffKuXbvimGOOiW9+85vR1tb2nseUSqUolUp994vFYjQ3N8ec+EzU1RxY6UsDJOMv35+R94SK9RZ6855QkY8tfiTvCRXZXf5nPBB3R3d3dzQ0NOz1uMyfuf+rQw45JI477rh44YUX9npMoVCIQqEwkJcBADIY0M+5l0qlePbZZ2PMmDGDtQcAGKBMcf/6178e69evj5dffjkeeeSR+NznPhfFYjEWLlxYrX0AQEaZ3pZ/9dVX47zzzosdO3bEEUccEZ/85Cdj48aNMX78+GrtAwAyyhT31atXV2sHADBI/G55AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMeIOAImpy3sAwP7umG/8Me8JFfv1a5vznlCRBW0n5T2hIjXlcsTuDz7OlTsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMZnj/tprr8UFF1wQo0aNioMPPjimTZsWmzdvrsY2AKACdVkOfuutt2LWrFlx2mmnxT333BNNTU3xl7/8JQ499NBq7QMAMsoU9xtuuCGam5tj5cqVfY8dddRRg70JABiATG/Lr127NlpaWuKcc86JpqamOP7442PFihXv+5xSqRTFYrHfDQConkxxf+mll6KjoyM+9rGPxX333ReLFi2KxYsXx6233rrX57S3t0djY2Pfrbm5ecCjAYC9qymXy+V9PXjEiBHR0tISDz/8cN9jixcvjk2bNsUf//jH93xOqVSKUqnUd79YLEZzc3PMic9EXc2BA5gOQN5+/drw/EL1gvEn5T2hIrvL/4z/u/uX0d3dHQ0NDXs9LtOV+5gxY+LYY4/t99ikSZNi69ate31OoVCIhoaGfjcAoHoyxX3WrFnx3HPP9Xvs+eefj/Hjxw/qKACgcpniftlll8XGjRvjuuuuixdffDFWrVoVnZ2d0draWq19AEBGmeJ+4oknxp133hm33357TJkyJb7zne/ETTfdFOeff3619gEAGWX6OfeIiPnz58f8+fOrsQUAGAR+tzwAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxNTlPQCA4WvB0TPznlCR//Nf6/OeUJHizt5onvjBx7lyB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMSIOwAkRtwBIDHiDgCJEXcASIy4A0BixB0AEiPuAJAYcQeAxIg7ACRG3AEgMZniftRRR0VNTc0et9bW1mrtAwAyqsty8KZNm6Knp6fv/p///Oc488wz45xzzhn0YQBAZTLF/Ygjjuh3//rrr49jjjkmTj311EEdBQBULlPc/9U777wTt912W7S1tUVNTc1ejyuVSlEqlfruF4vFSl8SANgHFX+h7q677oq///3v8aUvfel9j2tvb4/Gxsa+W3Nzc6UvCQDsg4rjfsstt8S8efNi7Nix73vcsmXLoru7u+/W1dVV6UsCAPugorflX3nllbj//vvjjjvu+MBjC4VCFAqFSl4GAKhARVfuK1eujKampjjrrLMGew8AMECZ497b2xsrV66MhQsXRl1dxd/HAwCqJHPc77///ti6dWtcdNFF1dgDAAxQ5kvvuXPnRrlcrsYWAGAQ+N3yAJAYcQeAxIg7ACRG3AEgMeIOAIkRdwBIjLgDQGLEHQASI+4AkBhxB4DEiDsAJEbcASAx4g4AiRF3AEiMuANAYjL/PfeBevdvwe+Of0b4s/AAw1pNeXheIxZ39uY9oSI73/5/u99t6d4Medx37twZEREPxW+G+qUBGGylvAdUpnli3gsGZufOndHY2LjXf19T/qD8D7Le3t54/fXXo76+Pmpqagb1v10sFqO5uTm6urqioaFhUP/bvDfnfOg550PPOR96zvl7K5fLsXPnzhg7dmwccMDe3zUZ8iv3Aw44IMaNG1fV12hoaPA/wxBzzoeecz70nPOh55zv6f2u2N81PD8sAQD2StwBIDG1V1999dV5jxhMtbW1MWfOnKirG/JPHPZbzvnQc86HnnM+9Jzzyg35F+oAgOrytjwAJEbcASAx4g4AiRF3AEiMuANAYsQdABIj7gCQGHEHgMT8N2N3GckvPbD1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 600x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRh9GumEBVlz3ZAFeGMpGk",
   "collapsed_sections": [
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
