{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740675351638,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "a0a0765a-0875-4b33-ecc4-bd79a983e1e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn_gen/exp/en_id\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5402,
     "status": "ok",
     "timestamp": 1740675357038,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "a2a9c1c8-0899-4fd8-ba03-79f0c447b594"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8519,
     "status": "ok",
     "timestamp": 1740675365559,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7e8d72e5-7442-46de-cd60-a0b8d7a078e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1740675365597,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740675365637,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL = \"dot\"\n",
    "EMB_DIM = \"64\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"128\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1740675365872,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "6b054b91-1e7f-4738-c254-2f9c73138c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/en_ma\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"val_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1740675365908,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list, lang_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list) == len(lang_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "    # Handle lang\n",
    "    self.lang_list = lang_list\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    lang = self.lang_list[index]\n",
    "    return graphemes, phonemes, lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740675365912,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.'))\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675365919,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[1]) for pair in pairs]\n",
    "    lang_list = [pair[2] for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list, lang_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1775,
     "status": "ok",
     "timestamp": 1740675367697,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "ec8792bd-f2b2-4246-9f0b-b93dbb078385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n",
      "EN_WEIGHT: 0.6138648959009436\n",
      "ID_WEIGHT: 2.6955844953082524\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "\n",
    "# Initialize weight loss for en and id\n",
    "N = len(train_pairs)\n",
    "K = 2\n",
    "EN_WEIGHT = N/(K * sum(1 for pair in train_pairs if pair[2]==\"en\"))\n",
    "ID_WEIGHT = N/(K * sum(1 for pair in train_pairs if pair[2]==\"ma\"))\n",
    "print(f\"EN_WEIGHT: {EN_WEIGHT}\")\n",
    "print(f\"ID_WEIGHT: {ID_WEIGHT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1740675367742,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq, lang), ...]\n",
    "  graphemes, phonemes, langs = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded, langs\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1740675367879,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1)\n",
    "  if USE_CUDA :\n",
    "    var = var.cuda()\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1740675367882,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "b03a688e-d182-44ca-a5ee-f8e0b5679352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 19, 12, 26, 19, 8, 14, 19, 30, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740675367884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "801ff8d1-c0c5-49fc-a337-df5484e9e424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f58c0a87e20> ([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 35, 1], 'en')\n",
      "train grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "valid grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "test grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "train phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "valid phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "test phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'd': 9, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'v': 27, 'z': 31, 'j': 15, 'f': 11, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'd': 9, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'v': 27, 'z': 31, 'j': 15, 'f': 11, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, '-': 5, 'y': 30, 'd': 9, 'b': 7, 'l': 17, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'w': 28, 'v': 27, 'z': 31, 'j': 15, 'f': 11, 'x': 29}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'D': 10, 'B': 8, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'UW': 31, 'G': 14, 'HH': 15, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'JH': 17, 'Y': 34, 'OY': 24, 'F': 13}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'D': 10, 'B': 8, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'UW': 31, 'G': 14, 'HH': 15, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'JH': 17, 'Y': 34, 'OY': 24, 'F': 13}\n",
      "33 {'K': 18, 'AX': 6, 'Z': 35, 'AO': 4, 'R': 27, 'S': 28, 'M': 20, 'N': 21, 'W': 33, 'T': 30, 'IY': 16, 'NY': 23, 'AA': 3, 'D': 10, 'B': 8, 'L': 19, 'CH': 9, 'P': 25, 'EH': 11, 'NG': 22, 'UW': 31, 'G': 14, 'HH': 15, 'Q': 26, 'V': 32, 'AY': 7, 'SH': 29, 'EY': 12, 'AW': 5, 'JH': 17, 'Y': 34, 'OY': 24, 'F': 13}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367889,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False)\n",
    "    if USE_CUDA :\n",
    "      self.embedding = self.embedding.cuda()\n",
    "      self.gru = self.gru.cuda()\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    if USE_CUDA :\n",
    "      hidden = hidden.cuda()\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367890,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "      if USE_CUDA :\n",
    "        self.attn = self.attn.cuda()\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "      if USE_CUDA :\n",
    "        self.attn = self.attn.cuda()\n",
    "        self.v = self.v.cuda()\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740675367895,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    if USE_CUDA :\n",
    "      self.embedding = self.embedding.cuda()\n",
    "      self.gru = self.gru.cuda()\n",
    "      self.out = self.out.cuda()\n",
    "      self.attn = self.attn.cuda()\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1740675367910,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "7c50e3bf-898c-41ed-9c99-f73b0bcbb1f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]])\n",
    "if USE_CUDA :\n",
    "  input_batch = input_batch.cuda()\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "if USE_CUDA :\n",
    "  decoder_input = decoder_input.cuda()\n",
    "  decoder_context = decoder_context.cuda()\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740675367916,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1740675368009,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, langs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "  if USE_CUDA :\n",
    "    input_batch = input_batch.cuda()\n",
    "    target_batch = target_batch.cuda()\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size])\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    if USE_CUDA :\n",
    "      decoder_input = decoder_input.cuda()\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Apply language weights\n",
    "  weights = torch.tensor([EN_WEIGHT if lang==\"en\" else ID_WEIGHT for lang in langs])\n",
    "  if USE_CUDA :\n",
    "    weights = weights.cuda()\n",
    "  weighted_loss = (loss * weights).mean()\n",
    "\n",
    "  # Backpropagate weighted loss\n",
    "  weighted_loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item(), weighted_loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  if USE_CUDA :\n",
    "    input_batch = input_batch.cuda()\n",
    "    target_batch = target_batch.cuda()\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size])\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1857,
     "status": "ok",
     "timestamp": 1740675369864,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "95183643-e690-43c7-c973-86c6d9cce6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 64\n",
      "hidden_size: 128\n",
      "n_layers: 1\n",
      "Encoder has a total number of 76544 parameters\n",
      "Decoder has a total number of 135204 parameters\n",
      "Total number of all parameters is 211748\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "if USE_CUDA :\n",
    "  encoder.cuda()\n",
    "  decoder.cuda()\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "200a4116-04e5-447b-885d-c22f6ad6642f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 1 finished in 0m 40.42s (- 66m 42.02s) (1 1.0%). train avg loss: 1.0896, val avg loss: 1.0997\n",
      "Training for epoch 2 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 2 finished in 1m 20.54s (- 65m 46.5s) (2 2.0%). train avg loss: 0.5295, val avg loss: 1.0083\n",
      "Training for epoch 3 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 3 finished in 2m 0.03s (- 64m 41.09s) (3 3.0%). train avg loss: 0.4703, val avg loss: 1.0005\n",
      "Training for epoch 4 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 4 finished in 2m 39.86s (- 63m 56.57s) (4 4.0%). train avg loss: 0.4254, val avg loss: 0.9466\n",
      "Training for epoch 5 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 5 finished in 3m 19.49s (- 63m 10.29s) (5 5.0%). train avg loss: 0.3992, val avg loss: 0.9028\n",
      "Training for epoch 6 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 6 finished in 3m 57.57s (- 62m 2.0s) (6 6.0%). train avg loss: 0.3712, val avg loss: 0.8578\n",
      "Training for epoch 7 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 7 finished in 4m 38.58s (- 61m 41.08s) (7 7.0%). train avg loss: 0.386, val avg loss: 0.8951\n",
      "Training for epoch 8 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 8 finished in 5m 17.77s (- 60m 54.38s) (8 8.0%). train avg loss: 0.3552, val avg loss: 0.8977\n",
      "Training for epoch 9 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 9 finished in 5m 57.41s (- 60m 13.8s) (9 9.0%). train avg loss: 0.3393, val avg loss: 0.9308\n",
      "Training for epoch 10 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 10 finished in 6m 37.13s (- 59m 34.17s) (10 10.0%). train avg loss: 0.3491, val avg loss: 0.8862\n",
      "Training for epoch 11 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 11 finished in 7m 15.34s (- 58m 42.33s) (11 11.0%). train avg loss: 0.3169, val avg loss: 0.8068\n",
      "Training for epoch 12 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 12 finished in 7m 53.74s (- 57m 54.09s) (12 12.0%). train avg loss: 0.3207, val avg loss: 0.7748\n",
      "Training for epoch 13 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 13 finished in 8m 31.72s (- 57m 4.58s) (13 13.0%). train avg loss: 0.3042, val avg loss: 0.7859\n",
      "Training for epoch 14 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 14 finished in 9m 11.31s (- 56m 26.62s) (14 14.0%). train avg loss: 0.3417, val avg loss: 0.7777\n",
      "Training for epoch 15 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 15 finished in 9m 51.48s (- 55m 51.75s) (15 15.0%). train avg loss: 0.3272, val avg loss: 0.7861\n",
      "Training for epoch 16 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 16 finished in 10m 31.76s (- 55m 16.71s) (16 16.0%). train avg loss: 0.2973, val avg loss: 0.8058\n",
      "Training for epoch 17 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 17 finished in 11m 11.95s (- 54m 40.68s) (17 17.0%). train avg loss: 0.2834, val avg loss: 0.7985\n",
      "Training for epoch 18 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 18 finished in 11m 52.07s (- 54m 3.86s) (18 18.0%). train avg loss: 0.2934, val avg loss: 0.7381\n",
      "Training for epoch 19 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 19 finished in 12m 32.44s (- 53m 27.78s) (19 19.0%). train avg loss: 0.317, val avg loss: 0.7133\n",
      "Training for epoch 20 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 20 finished in 13m 13.56s (- 52m 54.25s) (20 20.0%). train avg loss: 0.3193, val avg loss: 0.7765\n",
      "Training for epoch 21 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 21 finished in 13m 53.22s (- 52m 14.48s) (21 21.0%). train avg loss: 0.2705, val avg loss: 0.726\n",
      "Training for epoch 22 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 22 finished in 14m 32.73s (- 51m 34.23s) (22 22.0%). train avg loss: 0.2763, val avg loss: 0.7734\n",
      "Training for epoch 23 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 23 finished in 15m 12.91s (- 50m 56.26s) (23 23.0%). train avg loss: 0.27, val avg loss: 0.7511\n",
      "Training for epoch 24 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 24 finished in 15m 53.12s (- 50m 18.23s) (24 24.0%). train avg loss: 0.265, val avg loss: 0.6854\n",
      "Training for epoch 25 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 25 finished in 16m 33.94s (- 49m 41.82s) (25 25.0%). train avg loss: 0.2763, val avg loss: 0.7793\n",
      "Training for epoch 26 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 26 finished in 17m 13.78s (- 49m 2.28s) (26 26.0%). train avg loss: 0.2602, val avg loss: 0.6642\n",
      "Training for epoch 27 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 27 finished in 17m 53.56s (- 48m 22.59s) (27 27.0%). train avg loss: 0.2389, val avg loss: 0.7482\n",
      "Training for epoch 28 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 28 finished in 18m 33.94s (- 47m 44.41s) (28 28.0%). train avg loss: 0.2526, val avg loss: 0.6978\n",
      "Training for epoch 29 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 29 finished in 19m 13.91s (- 47m 5.08s) (29 29.0%). train avg loss: 0.2344, val avg loss: 0.7177\n",
      "Training for epoch 30 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 30 finished in 19m 53.84s (- 46m 25.63s) (30 30.0%). train avg loss: 0.2353, val avg loss: 0.6841\n",
      "Training for epoch 31 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 31 finished in 20m 33.55s (- 45m 45.64s) (31 31.0%). train avg loss: 0.2405, val avg loss: 0.6528\n",
      "Training for epoch 32 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 32 finished in 21m 13.58s (- 45m 6.35s) (32 32.0%). train avg loss: 0.2487, val avg loss: 0.6393\n",
      "Training for epoch 33 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 33 finished in 21m 56.52s (- 44m 32.93s) (33 33.0%). train avg loss: 0.23, val avg loss: 0.6525\n",
      "Training for epoch 34 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 34 finished in 22m 37.41s (- 43m 54.97s) (34 34.0%). train avg loss: 0.2341, val avg loss: 0.6449\n",
      "Training for epoch 35 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 35 finished in 23m 17.54s (- 43m 15.43s) (35 35.0%). train avg loss: 0.2271, val avg loss: 0.6848\n",
      "Training for epoch 36 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 36 finished in 23m 57.29s (- 42m 35.19s) (36 36.0%). train avg loss: 0.2149, val avg loss: 0.6992\n",
      "Training for epoch 37 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 37 finished in 24m 37.82s (- 41m 56.3s) (37 37.0%). train avg loss: 0.2267, val avg loss: 0.6868\n",
      "Training for epoch 38 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 38 finished in 25m 17.62s (- 41m 16.11s) (38 38.0%). train avg loss: 0.2223, val avg loss: 0.6393\n",
      "Training for epoch 39 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 39 finished in 25m 59.16s (- 40m 38.69s) (39 39.0%). train avg loss: 0.2069, val avg loss: 0.7308\n",
      "Training for epoch 40 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 40 finished in 26m 39.81s (- 39m 59.71s) (40 40.0%). train avg loss: 0.2167, val avg loss: 0.6362\n",
      "Training for epoch 41 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 41 finished in 27m 20.84s (- 39m 21.21s) (41 41.0%). train avg loss: 0.2108, val avg loss: 0.6251\n",
      "Training for epoch 42 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 42 finished in 28m 1.66s (- 38m 42.3s) (42 42.0%). train avg loss: 0.2235, val avg loss: 0.6288\n",
      "Training for epoch 43 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 43 finished in 28m 41.74s (- 38m 2.3s) (43 43.0%). train avg loss: 0.2069, val avg loss: 0.6154\n",
      "Training for epoch 44 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 44 finished in 29m 21.26s (- 37m 21.6s) (44 44.0%). train avg loss: 0.2194, val avg loss: 0.6624\n",
      "Training for epoch 45 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 45 finished in 30m 1.54s (- 36m 41.88s) (45 45.0%). train avg loss: 0.2039, val avg loss: 0.5992\n",
      "Training for epoch 46 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 46 finished in 30m 41.59s (- 36m 1.87s) (46 46.0%). train avg loss: 0.232, val avg loss: 0.6289\n",
      "Training for epoch 47 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 47 finished in 31m 21.61s (- 35m 21.81s) (47 47.0%). train avg loss: 0.1972, val avg loss: 0.6093\n",
      "Training for epoch 48 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 48 finished in 32m 1.9s (- 34m 42.06s) (48 48.0%). train avg loss: 0.2002, val avg loss: 0.6202\n",
      "Training for epoch 49 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 49 finished in 32m 41.03s (- 34m 1.07s) (49 49.0%). train avg loss: 0.1942, val avg loss: 0.6365\n",
      "Training for epoch 50 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 50 finished in 33m 20.9s (- 33m 20.9s) (50 50.0%). train avg loss: 0.2055, val avg loss: 0.6877\n",
      "Training for epoch 51 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 51 finished in 34m 0.47s (- 32m 40.45s) (51 51.0%). train avg loss: 0.195, val avg loss: 0.6099\n",
      "Training for epoch 52 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 52 finished in 34m 41.5s (- 32m 1.38s) (52 52.0%). train avg loss: 0.1971, val avg loss: 0.6545\n",
      "Training for epoch 53 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 53 finished in 35m 21.4s (- 31m 21.24s) (53 53.0%). train avg loss: 0.1976, val avg loss: 0.61\n",
      "Training for epoch 54 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 54 finished in 36m 0.71s (- 30m 40.61s) (54 54.0%). train avg loss: 0.1879, val avg loss: 0.6344\n",
      "Training for epoch 55 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 55 finished in 36m 40.36s (- 30m 0.29s) (55 55.0%). train avg loss: 0.1972, val avg loss: 0.6903\n",
      "Training for epoch 56 has started (lr=0.001). Found 1922 batch(es).\n",
      "Epoch 56 finished in 37m 20.01s (- 29m 20.01s) (56 56.0%). train avg loss: 0.1928, val avg loss: 0.6602\n",
      "Training for epoch 57 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 57 finished in 37m 59.66s (- 28m 39.74s) (57 57.0%). train avg loss: 0.1639, val avg loss: 0.5847\n",
      "Training for epoch 58 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 58 finished in 38m 40.05s (- 28m 0.04s) (58 58.0%). train avg loss: 0.1564, val avg loss: 0.5921\n",
      "Training for epoch 59 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 59 finished in 39m 20.56s (- 27m 20.39s) (59 59.0%). train avg loss: 0.156, val avg loss: 0.5723\n",
      "Training for epoch 60 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 60 finished in 40m 2.52s (- 26m 41.68s) (60 60.0%). train avg loss: 0.1493, val avg loss: 0.595\n",
      "Training for epoch 61 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 61 finished in 40m 43.17s (- 26m 2.03s) (61 61.0%). train avg loss: 0.1533, val avg loss: 0.6011\n",
      "Training for epoch 62 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 62 finished in 41m 23.0s (- 25m 21.84s) (62 62.0%). train avg loss: 0.1493, val avg loss: 0.5777\n",
      "Training for epoch 63 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 63 finished in 42m 2.73s (- 24m 41.6s) (63 63.0%). train avg loss: 0.1486, val avg loss: 0.6002\n",
      "Training for epoch 64 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 64 finished in 42m 42.09s (- 24m 1.18s) (64 64.0%). train avg loss: 0.1492, val avg loss: 0.6084\n",
      "Training for epoch 65 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 65 finished in 43m 21.04s (- 23m 20.56s) (65 65.0%). train avg loss: 0.1417, val avg loss: 0.5787\n",
      "Training for epoch 66 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 66 finished in 44m 0.31s (- 22m 40.16s) (66 66.0%). train avg loss: 0.1462, val avg loss: 0.56\n",
      "Training for epoch 67 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 67 finished in 44m 39.81s (- 21m 59.9s) (67 67.0%). train avg loss: 0.1425, val avg loss: 0.5648\n",
      "Training for epoch 68 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 68 finished in 45m 19.4s (- 21m 19.72s) (68 68.0%). train avg loss: 0.14, val avg loss: 0.5851\n",
      "Training for epoch 69 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 69 finished in 45m 58.6s (- 20m 39.37s) (69 69.0%). train avg loss: 0.1467, val avg loss: 0.5855\n",
      "Training for epoch 70 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 70 finished in 46m 37.87s (- 19m 59.09s) (70 70.0%). train avg loss: 0.1502, val avg loss: 0.5875\n",
      "Training for epoch 71 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 71 finished in 47m 17.86s (- 19m 19.12s) (71 71.0%). train avg loss: 0.1379, val avg loss: 0.5627\n",
      "Training for epoch 72 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 72 finished in 47m 57.48s (- 18m 39.02s) (72 72.0%). train avg loss: 0.1417, val avg loss: 0.5602\n",
      "Training for epoch 73 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 73 finished in 48m 37.82s (- 17m 59.19s) (73 73.0%). train avg loss: 0.1371, val avg loss: 0.5645\n",
      "Training for epoch 74 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 74 finished in 49m 17.34s (- 17m 19.06s) (74 74.0%). train avg loss: 0.1353, val avg loss: 0.5735\n",
      "Training for epoch 75 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 75 finished in 49m 58.35s (- 16m 39.45s) (75 75.0%). train avg loss: 0.1435, val avg loss: 0.6\n",
      "Training for epoch 76 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 76 finished in 50m 38.46s (- 15m 59.51s) (76 76.0%). train avg loss: 0.1341, val avg loss: 0.6011\n",
      "Training for epoch 77 has started (lr=0.0005). Found 1922 batch(es).\n",
      "Epoch 77 finished in 51m 18.9s (- 15m 19.67s) (77 77.0%). train avg loss: 0.133, val avg loss: 0.5934\n",
      "Training for epoch 78 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 78 finished in 51m 58.69s (- 14m 39.63s) (78 78.0%). train avg loss: 0.1219, val avg loss: 0.5491\n",
      "Training for epoch 79 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 79 finished in 52m 38.21s (- 13m 59.52s) (79 79.0%). train avg loss: 0.1205, val avg loss: 0.5548\n",
      "Training for epoch 80 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 80 finished in 53m 17.29s (- 13m 19.32s) (80 80.0%). train avg loss: 0.121, val avg loss: 0.5604\n",
      "Training for epoch 81 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 81 finished in 53m 57.14s (- 12m 39.33s) (81 81.0%). train avg loss: 0.1187, val avg loss: 0.5641\n",
      "Training for epoch 82 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 82 finished in 54m 36.02s (- 11m 59.13s) (82 82.0%). train avg loss: 0.1178, val avg loss: 0.5543\n",
      "Training for epoch 83 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 83 finished in 55m 15.72s (- 11m 19.12s) (83 83.0%). train avg loss: 0.1164, val avg loss: 0.5415\n",
      "Training for epoch 84 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 84 finished in 55m 54.42s (- 10m 38.94s) (84 84.0%). train avg loss: 0.115, val avg loss: 0.5488\n",
      "Training for epoch 85 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 85 finished in 56m 33.74s (- 9m 58.9s) (85 85.0%). train avg loss: 0.1132, val avg loss: 0.546\n",
      "Training for epoch 86 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 86 finished in 57m 13.44s (- 9m 18.93s) (86 86.0%). train avg loss: 0.1127, val avg loss: 0.5629\n",
      "Training for epoch 87 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 87 finished in 57m 53.05s (- 8m 38.96s) (87 87.0%). train avg loss: 0.1179, val avg loss: 0.5626\n",
      "Training for epoch 88 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 88 finished in 58m 32.72s (- 7m 59.01s) (88 88.0%). train avg loss: 0.1126, val avg loss: 0.5793\n",
      "Training for epoch 89 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 89 finished in 59m 12.79s (- 7m 19.11s) (89 89.0%). train avg loss: 0.112, val avg loss: 0.5608\n",
      "Training for epoch 90 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 90 finished in 59m 53.01s (- 6m 39.22s) (90 90.0%). train avg loss: 0.1149, val avg loss: 0.5523\n",
      "Training for epoch 91 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 91 finished in 60m 32.85s (- 5m 59.29s) (91 91.0%). train avg loss: 0.1114, val avg loss: 0.5574\n",
      "Training for epoch 92 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 92 finished in 61m 12.69s (- 5m 19.36s) (92 92.0%). train avg loss: 0.1096, val avg loss: 0.556\n",
      "Training for epoch 93 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 93 finished in 61m 52.69s (- 4m 39.45s) (93 93.0%). train avg loss: 0.1096, val avg loss: 0.5485\n",
      "Training for epoch 94 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 94 finished in 62m 32.06s (- 3m 59.49s) (94 94.0%). train avg loss: 0.1094, val avg loss: 0.5381\n",
      "Training for epoch 95 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 95 finished in 63m 11.54s (- 3m 19.55s) (95 95.0%). train avg loss: 0.108, val avg loss: 0.5645\n",
      "Training for epoch 96 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 96 finished in 63m 50.92s (- 2m 39.62s) (96 96.0%). train avg loss: 0.1083, val avg loss: 0.5776\n",
      "Training for epoch 97 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 97 finished in 64m 29.97s (- 1m 59.69s) (97 97.0%). train avg loss: 0.1112, val avg loss: 0.5725\n",
      "Training for epoch 98 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 98 finished in 65m 9.4s (- 1m 19.78s) (98 98.0%). train avg loss: 0.1071, val avg loss: 0.564\n",
      "Training for epoch 99 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 99 finished in 65m 48.32s (- 0m 39.88s) (99 99.0%). train avg loss: 0.1067, val avg loss: 0.5557\n",
      "Training for epoch 100 has started (lr=0.00025). Found 1922 batch(es).\n",
      "Epoch 100 finished in 66m 30.88s (- 0m 0.0s) (100 100.0%). train avg loss: 0.1055, val avg loss: 0.5471\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns, langs) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get WEIGHTED loss\n",
    "    unweighted_train_loss, weighted_train_loss = train_batch(grps, phns, langs, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track UNWEIGHTED train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns, langs in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "-498emHUaNzb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5.5, min_value-.075, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "  if USE_CUDA :\n",
    "    decoder_input = decoder_input.cuda()\n",
    "    decoder_context = decoder_context.cuda()\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]])\n",
    "    if USE_CUDA :\n",
    "      decoder_input = decoder_input.cuda()\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, arpabet_phoneme_sequence, lang = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "MlSPdqo3QDyr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on val set: 14.749419075351867%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, arpabet_phoneme_sequence, lang = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on val set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "HSHGOjSmc3Vi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> colclasure\n",
      "= ['K', 'AO', 'W', 'L', 'K', 'L', 'AA', 'Z', 'AX', 'R']\n",
      "< K AO W L K L EH S AX R ['K', 'AO', 'W', 'L', 'K', 'L', 'EH', 'S', 'AX', 'R']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f588dcd1070>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAGkCAYAAADXOJmhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAWgElEQVR4nO3df2xV9f3H8Ve5hVvq2otAWugoWBIMSHVAS1RAxei68cNBZsxw6Pi6H9FZoF0ThQ63IA5uYBtpYqWmxCCOFfrHdLLNXw370sqQr6VQdbovTEWpYr+dju+9Bfa92PZ8/3AUr23lR8/tp/T9fCQn5p4ee945JDz53Nuek+R5nicAgEmDXA8AAHCHCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhAzICmzZtUk5OjlJSUpSXl6eXX37Z9UhOhMNhTZ8+XWlpacrIyNDChQt16NAh12P1C+FwWElJSSouLnY9ijMffvih7rrrLo0YMUKpqamaMmWKGhoaXI/V59ra2vTQQw8pJydHQ4cO1fjx47VmzRp1dHS4Hq1PDLgIVFdXq7i4WKtWrdLBgwd1ww03aM6cOTp69Kjr0fpcbW2tCgsLtW/fPtXU1KitrU0FBQU6efKk69Gcqq+vV2Vlpa655hrXozhz/PhxzZw5U4MHD9bzzz+vt956S7/+9a81bNgw16P1ufXr1+vxxx9XeXm5/va3v2nDhg365S9/qUcffdT1aH0iaaDdQO7aa6/VtGnTVFFR0blv0qRJWrhwocLhsMPJ3PvHP/6hjIwM1dbW6sYbb3Q9jhMnTpzQtGnTtGnTJv3iF7/QlClTVFZW5nqsPrdy5Ur95S9/MbtK/rz58+crMzNTTzzxROe+22+/XampqfrNb37jcLK+MaBWAqdPn1ZDQ4MKCgri9hcUFGjv3r2Opuo/IpGIJGn48OGOJ3GnsLBQ8+bN06233up6FKd27typ/Px83XHHHcrIyNDUqVO1efNm12M5MWvWLO3atUuHDx+WJL322mvas2eP5s6d63iyvpHsegA/ffzxx2pvb1dmZmbc/szMTDU3Nzuaqn/wPE8lJSWaNWuWcnNzXY/jxI4dO3TgwAHV19e7HsW5d999VxUVFSopKdFPf/pTvfrqq1q+fLmCwaC+973vuR6vT61YsUKRSEQTJ05UIBBQe3u71q5dqzvvvNP1aH1iQEXgjKSkpLjXnud12WfN0qVL9frrr2vPnj2uR3GiqalJRUVFeumll5SSkuJ6HOc6OjqUn5+vdevWSZKmTp2qN998UxUVFeYiUF1drW3btqmqqkqTJ09WY2OjiouLlZWVpSVLlrgeL+EGVARGjhypQCDQ5V/9LS0tXVYHlixbtkw7d+5UXV2dxowZ43ocJxoaGtTS0qK8vLzOfe3t7aqrq1N5eblisZgCgYDDCfvW6NGjddVVV8XtmzRpkn73u985msidBx54QCtXrtSiRYskSVdffbXef/99hcNhExEYUJ8JDBkyRHl5eaqpqYnbX1NToxkzZjiayh3P87R06VI9/fTT+vOf/6ycnBzXIzlzyy236I033lBjY2Pnlp+fr8WLF6uxsdFUACRp5syZXX5c+PDhwxo3bpyjidw5deqUBg2K/6swEAiY+RFReQPMjh07vMGDB3tPPPGE99Zbb3nFxcXeZZdd5r333nuuR+tzP/7xj71QKOTt3r3b++ijjzq3U6dOuR6tX7jpppu8oqIi12M48eqrr3rJycne2rVrvb///e/eb3/7Wy81NdXbtm2b69H63JIlS7yvfvWr3h//+EfvyJEj3tNPP+2NHDnSe/DBB12P1icGXAQ8z/Mee+wxb9y4cd6QIUO8adOmebW1ta5HckJSt9uWLVtcj9YvWI6A53neH/7wBy83N9cLBoPexIkTvcrKStcjORGNRr2ioiJv7NixXkpKijd+/Hhv1apVXiwWcz1anxhwvycAADh/A+ozAQDAhSECAGAYEQAAw4gAABhGBADAMCIAAIYNyAjEYjGtXr1asVjM9Sj9AtcjHtfjLK5FPIvXY0D+nkA0GlUoFFIkElF6errrcZzjesTjepzFtYhn8XoMyJUAAOD8EAEAMKzf3Uq6o6NDx44dU1pa2kU/AyAajcb91zquRzyux1lci3gD6Xp4nqfW1lZlZWV1uUvq5/W7zwQ++OADZWdnux4DAAaEpqamL32OSL9bCaSlpUmSZmmukjXY8TQAcGlq06fao+c6/07tSb+LwJm3gJI1WMlJRAAALsq/3+M519vqfDAMAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADAsYRHYtGmTcnJylJKSory8PL388suJOhUA4CIlJALV1dUqLi7WqlWrdPDgQd1www2aM2eOjh49mojTAQAuUkIisHHjRv3gBz/QD3/4Q02aNEllZWXKzs5WRUVFIk4HALhIvkfg9OnTamhoUEFBQdz+goIC7d27t8vxsVhM0Wg0bgMA9A3fI/Dxxx+rvb1dmZmZcfszMzPV3Nzc5fhwOKxQKNS58UAZAOg7Cftg+Iv3sPY8r9v7WpeWlioSiXRuTU1NiRoJAPAFvj9UZuTIkQoEAl3+1d/S0tJldSBJwWBQwWDQ7zEAAOfB95XAkCFDlJeXp5qamrj9NTU1mjFjht+nAwD0QkIeL1lSUqK7775b+fn5uv7661VZWamjR4/qvvvuS8TpAAAXKSER+M53vqNPPvlEa9as0UcffaTc3Fw999xzGjduXCJOBwC4SEme53muh/i8aDSqUCik2VrAg+YB4CK1eZ9qt55VJBJRenp6j8dx7yAAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGEJuXeQHwLD0hVIGuJ0hsde+5PT859x37hZrkcAMECxEgAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDkl0P0JP2/40qKWmw0xlyBn/F6fkBINFYCQCAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw3yPQDgc1vTp05WWlqaMjAwtXLhQhw4d8vs0AAAf+B6B2tpaFRYWat++faqpqVFbW5sKCgp08uRJv08FAOgl328l/cILL8S93rJlizIyMtTQ0KAbb7zR79MBAHoh4c8TiEQikqThw4d3+/VYLKZYLNb5OhqNJnokAMC/JfSDYc/zVFJSolmzZik3N7fbY8LhsEKhUOeWnZ2dyJEAAJ+T0AgsXbpUr7/+urZv397jMaWlpYpEIp1bU1NTIkcCAHxOwt4OWrZsmXbu3Km6ujqNGTOmx+OCwaCCwWCixgAAfAnfI+B5npYtW6ZnnnlGu3fvVk5Ojt+nAAD4xPcIFBYWqqqqSs8++6zS0tLU3NwsSQqFQho6dKjfpwMA9ILvnwlUVFQoEolo9uzZGj16dOdWXV3t96kAAL2UkLeDAACXBu4dBACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYl/KEyl7JvLrjb9QiSpH/e8xXXI0iShj+5z/UIemfDda5HkCRNWPNX1yNIkjpaW12PgEscKwEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwLNn1AP2ZV/+G6xEkSenpea5HkCT98z+ucz2Crlz3365HkCS9V3y16xEkSdmP7HU9Ai5xrAQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGEJj0A4HFZSUpKKi4sTfSoAwAVKaATq6+tVWVmpa665JpGnAQBcpIRF4MSJE1q8eLE2b96syy+/PFGnAQD0QsIiUFhYqHnz5unWW2/90uNisZii0WjcBgDoGwl5qMyOHTt04MAB1dfXn/PYcDishx9+OBFjAADOwfeVQFNTk4qKirRt2zalpKSc8/jS0lJFIpHOrampye+RAAA98H0l0NDQoJaWFuXlnX0kYnt7u+rq6lReXq5YLKZAIND5tWAwqGAw6PcYAIDz4HsEbrnlFr3xRvyzee+55x5NnDhRK1asiAsAAMAt3yOQlpam3NzcuH2XXXaZRowY0WU/AMAtfmMYAAxLyE8HfdHu3bv74jQAgAvESgAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYFif3DYCvZO8q8H1CJKk//xgn+sRdPuW61yPIEkau6F//Jl4rgfAJY+VAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABiW7HoAXDpuH3Od6xH6jReO/JfrESRJ38ia4noEXOJYCQCAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAwxISgQ8//FB33XWXRowYodTUVE2ZMkUNDQ2JOBUAoBd8v4vo8ePHNXPmTN188816/vnnlZGRoXfeeUfDhg3z+1QAgF7yPQLr169Xdna2tmzZ0rnviiuu8Ps0AAAf+P520M6dO5Wfn6877rhDGRkZmjp1qjZv3tzj8bFYTNFoNG4DAPQN3yPw7rvvqqKiQhMmTNCLL76o++67T8uXL9dTTz3V7fHhcFihUKhzy87O9nskAEAPkjzP8/z8hkOGDFF+fr727t3buW/58uWqr6/XK6+80uX4WCymWCzW+ToajSo7O1uztUDJSYP9HA3wzYvHGl2PIIkni6Fnbd6n2q1nFYlElJ6e3uNxvq8ERo8erauuuipu36RJk3T06NFujw8Gg0pPT4/bAAB9w/cIzJw5U4cOHYrbd/jwYY0bN87vUwEAesn3CPzkJz/Rvn37tG7dOr399tuqqqpSZWWlCgsL/T4VAKCXfI/A9OnT9cwzz2j79u3Kzc3VI488orKyMi1evNjvUwEAesn33xOQpPnz52v+/PmJ+NYAAB9x7yAAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGEJuW0EfDYo4HqCz3S0u56g3/jmt+5yPYIkKfOV7m/R3tc+WRRyPYIkqe39JtcjXHJYCQCAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMCzZ9QA4Dx3trifAF3j7/+p6BEnS/1zveoLPvHiszvUIkqRvZE1xPcIlh5UAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYb5HoK2tTQ899JBycnI0dOhQjR8/XmvWrFFHR4ffpwIA9JLvt5Jev369Hn/8cW3dulWTJ0/W/v37dc899ygUCqmoqMjv0wEAesH3CLzyyitasGCB5s2bJ0m64oortH37du3fv9/vUwEAesn3t4NmzZqlXbt26fDhw5Kk1157TXv27NHcuXO7PT4WiykajcZtAIC+4ftKYMWKFYpEIpo4caICgYDa29u1du1a3Xnnnd0eHw6H9fDDD/s9BgDgPPi+Eqiurta2bdtUVVWlAwcOaOvWrfrVr36lrVu3dnt8aWmpIpFI59bU1OT3SACAHvi+EnjggQe0cuVKLVq0SJJ09dVX6/3331c4HNaSJUu6HB8MBhUMBv0eAwBwHnxfCZw6dUqDBsV/20AgwI+IAkA/5PtK4LbbbtPatWs1duxYTZ48WQcPHtTGjRv1/e9/3+9TAQB6yfcIPProo/rZz36m+++/Xy0tLcrKytK9996rn//8536fCgDQS75HIC0tTWVlZSorK/P7WwMAfMa9gwDAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAw339jGIA9OX/6kesRJEmTJvePh1K1XDfc9QhqP/1/0lPPnvM4VgIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgGBEAAMOIAAAYRgQAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDiAAAGEYEAMAwIgAAhhEBADCMCACAYUQAAAwjAgBgWLLrAQBc+q78Ub3rESRJ7a4H+Lf9NY2uR1C0tUOXP3Xu41gJAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIYRAQAwjAgAgGFEAAAMIwIAYBgRAADDLjgCdXV1uu2225SVlaWkpCT9/ve/j/u653lavXq1srKyNHToUM2ePVtvvvmmbwMDAPxzwRE4efKkvva1r6m8vLzbr2/YsEEbN25UeXm56uvrNWrUKH39619Xa2trr4cFAPjrgm8lPWfOHM2ZM6fbr3mep7KyMq1atUrf/va3JUlbt25VZmamqqqqdO+99/ZuWgCAr3z9TODIkSNqbm5WQUFB575gMKibbrpJe/fu7fb/icViikajcRsAoG/4GoHm5mZJUmZmZtz+zMzMzq99UTgcVigU6tyys7P9HAkA8CUS8tNBSUlJca89z+uy74zS0lJFIpHOrampKREjAQC64evjJUeNGiXpsxXB6NGjO/e3tLR0WR2cEQwGFQwG/RwDAHCefF0J5OTkaNSoUaqpqencd/r0adXW1mrGjBl+ngoA4IMLXgmcOHFCb7/9dufrI0eOqLGxUcOHD9fYsWNVXFysdevWacKECZowYYLWrVun1NRUffe73/V1cABA711wBPbv36+bb76583VJSYkkacmSJXryySf14IMP6l//+pfuv/9+HT9+XNdee61eeuklpaWl+Tc1AMAXSZ7nea6H+LxoNKpQKKTZWqDkpMGuxwGAC/bisUbXIyja2qHLr3xXkUhE6enpPR7HvYMAwDAiAACGEQEAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMF/vIuqHM7/A3KZPpX71u8wAcH6irR2uR1D0xGcznOumEP0uAmeeRbxHzzmeBAAuzuVXup7grNbWVoVCoR6/3u/uHdTR0aFjx44pLS2txwfRnEs0GlV2draampq+9J4ZVnA94nE9zuJaxBtI18PzPLW2tiorK0uDBvX8zn+/WwkMGjRIY8aM8eV7paenX/J/kH7iesTjepzFtYg3UK7Hl60AzuCDYQAwjAgAgGGB1atXr3Y9RCIEAgHNnj1bycn97h0vJ7ge8bgeZ3Et4lm7Hv3ug2EAQN/h7SAAMIwIAIBhRAAADCMCAGAYEQAAw4gAABhGBADAMCIAAIb9PwfQziQeXvCYAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 436.364x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMRh9GumEBVlz3ZAFeGMpGk",
   "collapsed_sections": [
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
