{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1739957705963,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "29775173-7761-4953-d853-502b8b825ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn-gen/exp/en\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1739957711340,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "33e9e6e9-f2b0-4d04-e665-6f2600a2c57e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8274,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7a08073c-d249-49ab-ddaf-f827de5d8d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL = \"dot\"\n",
    "EMB_DIM = \"32\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"100\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "704ba764-a750-40fc-d5c9-0a6d289c3ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/en\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"validation_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    return graphemes, phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.')).lower()\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[1]) for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "1a7e253b-ee59-419e-f7d6-0e469cac96fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq), ...]\n",
    "  graphemes, phonemes = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  word = word.lower()\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1).to(DEVICE)\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "92da8620-4d32-4614-db38-6fdfcd7e04fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 9, 18, 11, 25, 18, 7, 13, 18, 29, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "56a821f8-be28-4de8-8e2c-f5e7b8d2bc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f75f02074f0> ([4, 7, 5, 25, 23, 9, 1], [18, 6, 34, 1])\n",
      "([4, 7, 5, 25, 23, 9, 1], [18, 6, 34, 1])\n",
      "([4, 7, 5, 25, 23, 9, 1], [18, 6, 34, 1])\n",
      "train grp 31 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: 'a', 6: 'b', 7: 'c', 8: 'd', 9: 'e', 10: 'f', 11: 'g', 12: 'h', 13: 'i', 14: 'j', 15: 'k', 16: 'l', 17: 'm', 18: 'n', 19: 'o', 20: 'p', 21: 'q', 22: 'r', 23: 's', 24: 't', 25: 'u', 26: 'v', 27: 'w', 28: 'x', 29: 'y', 30: 'z'}\n",
      "valid grp 31 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: 'a', 6: 'b', 7: 'c', 8: 'd', 9: 'e', 10: 'f', 11: 'g', 12: 'h', 13: 'i', 14: 'j', 15: 'k', 16: 'l', 17: 'm', 18: 'n', 19: 'o', 20: 'p', 21: 'q', 22: 'r', 23: 's', 24: 't', 25: 'u', 26: 'v', 27: 'w', 28: 'x', 29: 'y', 30: 'z'}\n",
      "test grp 31 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: 'a', 6: 'b', 7: 'c', 8: 'd', 9: 'e', 10: 'f', 11: 'g', 12: 'h', 13: 'i', 14: 'j', 15: 'k', 16: 'l', 17: 'm', 18: 'n', 19: 'o', 20: 'p', 21: 'q', 22: 'r', 23: 's', 24: 't', 25: 'u', 26: 'v', 27: 'w', 28: 'x', 29: 'y', 30: 'z'}\n",
      "train phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "valid phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "test phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "27 {\"'\": 4, 'c': 7, 'a': 5, 'u': 25, 's': 23, 'e': 9, 'o': 19, 'r': 22, 'm': 17, 'n': 18, 'q': 21, 't': 24, 'i': 13, 'l': 16, 'w': 27, 'b': 6, 'g': 11, 'h': 12, 'k': 15, 'd': 8, 'v': 26, 'y': 29, 'z': 30, 'f': 10, 'x': 28, 'j': 14, 'p': 20}\n",
      "27 {\"'\": 4, 'c': 7, 'a': 5, 'u': 25, 's': 23, 'e': 9, 'o': 19, 'r': 22, 'm': 17, 'n': 18, 'q': 21, 't': 24, 'i': 13, 'l': 16, 'w': 27, 'b': 6, 'g': 11, 'h': 12, 'k': 15, 'd': 8, 'v': 26, 'y': 29, 'z': 30, 'f': 10, 'x': 28, 'j': 14, 'p': 20}\n",
      "27 {\"'\": 4, 'c': 7, 'a': 5, 'u': 25, 's': 23, 'e': 9, 'o': 19, 'r': 22, 'm': 17, 'n': 18, 'q': 21, 't': 24, 'i': 13, 'l': 16, 'w': 27, 'b': 6, 'g': 11, 'h': 12, 'k': 15, 'd': 8, 'v': 26, 'y': 29, 'z': 30, 'f': 10, 'x': 28, 'j': 14, 'p': 20}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'L': 19, 'AA': 3, 'B': 8, 'G': 14, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'AW': 5, 'UW': 30, 'F': 13, 'HH': 15, 'AY': 7, 'JH': 17, 'Y': 33, 'CH': 9, 'P': 24, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'L': 19, 'AA': 3, 'B': 8, 'G': 14, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'AW': 5, 'UW': 30, 'F': 13, 'HH': 15, 'AY': 7, 'JH': 17, 'Y': 33, 'CH': 9, 'P': 24, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'L': 19, 'AA': 3, 'B': 8, 'G': 14, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'AW': 5, 'UW': 30, 'F': 13, 'HH': 15, 'AY': 7, 'JH': 17, 'Y': 33, 'CH': 9, 'P': 24, 'OY': 23}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size).to(DEVICE)\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size).to(DEVICE)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size)).to(DEVICE)\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False).to(DEVICE)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size).to(DEVICE)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "9a095505-f179-48d0-c305-f4e69125f170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]]).to(DEVICE)\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size).to(DEVICE) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n",
    "\n",
    "del encoder_test\n",
    "del decoder_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    decoder_input = decoder_input.to(DEVICE)\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Backpropagate loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "      )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1739957723364,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "68700f7a-b173-4800-d808-8d922cd64e2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 32\n",
      "hidden_size: 100\n",
      "n_layers: 1\n",
      "Encoder has a total number of 41192 parameters\n",
      "Decoder has a total number of 78355 parameters\n",
      "Total number of all parameters is 119547\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2952362,
     "status": "ok",
     "timestamp": 1739960675722,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "e9e1eaf7-3a18-4620-b007-cbad6be38496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 1 finished in 0m 35.04s (- 57m 48.66s) (1 1.0%). train avg loss: 1.2354, val avg loss: 1.2059\n",
      "Training for epoch 2 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 2 finished in 1m 7.68s (- 55m 16.41s) (2 2.0%). train avg loss: 0.5988, val avg loss: 1.0919\n",
      "Training for epoch 3 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 3 finished in 1m 41.38s (- 54m 37.89s) (3 3.0%). train avg loss: 0.4678, val avg loss: 0.9328\n",
      "Training for epoch 4 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 4 finished in 2m 16.48s (- 54m 35.55s) (4 4.0%). train avg loss: 0.4362, val avg loss: 0.9103\n",
      "Training for epoch 5 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 5 finished in 2m 50.95s (- 54m 8.04s) (5 5.0%). train avg loss: 0.3897, val avg loss: 0.8715\n",
      "Training for epoch 6 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 6 finished in 3m 23.71s (- 53m 11.52s) (6 6.0%). train avg loss: 0.3792, val avg loss: 0.8966\n",
      "Training for epoch 7 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 7 finished in 3m 54.31s (- 51m 53.02s) (7 7.0%). train avg loss: 0.3466, val avg loss: 0.9139\n",
      "Training for epoch 8 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 8 finished in 4m 27.17s (- 51m 12.42s) (8 8.0%). train avg loss: 0.3446, val avg loss: 0.8651\n",
      "Training for epoch 9 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 9 finished in 4m 59.52s (- 50m 28.47s) (9 9.0%). train avg loss: 0.3194, val avg loss: 0.8728\n",
      "Training for epoch 10 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 10 finished in 5m 30.52s (- 49m 34.64s) (10 10.0%). train avg loss: 0.3063, val avg loss: 0.8559\n",
      "Training for epoch 11 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 11 finished in 6m 2.94s (- 48m 56.54s) (11 11.0%). train avg loss: 0.3086, val avg loss: 0.798\n",
      "Training for epoch 12 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 12 finished in 6m 35.82s (- 48m 22.66s) (12 12.0%). train avg loss: 0.3032, val avg loss: 0.7925\n",
      "Training for epoch 13 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 13 finished in 7m 9.15s (- 47m 51.98s) (13 13.0%). train avg loss: 0.2979, val avg loss: 0.7991\n",
      "Training for epoch 14 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 14 finished in 7m 42.35s (- 47m 20.13s) (14 14.0%). train avg loss: 0.2787, val avg loss: 0.8391\n",
      "Training for epoch 15 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 15 finished in 8m 15.72s (- 46m 49.07s) (15 15.0%). train avg loss: 0.2959, val avg loss: 0.7801\n",
      "Training for epoch 16 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 16 finished in 8m 47.99s (- 46m 11.94s) (16 16.0%). train avg loss: 0.2565, val avg loss: 0.8027\n",
      "Training for epoch 17 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 17 finished in 9m 21.01s (- 45m 39.07s) (17 17.0%). train avg loss: 0.2706, val avg loss: 0.7324\n",
      "Training for epoch 18 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 18 finished in 9m 51.13s (- 44m 52.9s) (18 18.0%). train avg loss: 0.2785, val avg loss: 0.757\n",
      "Training for epoch 19 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 19 finished in 10m 22.77s (- 44m 14.95s) (19 19.0%). train avg loss: 0.2566, val avg loss: 0.7582\n",
      "Training for epoch 20 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 20 finished in 10m 54.17s (- 43m 36.68s) (20 20.0%). train avg loss: 0.2591, val avg loss: 0.7513\n",
      "Training for epoch 21 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 21 finished in 11m 24.72s (- 42m 55.85s) (21 21.0%). train avg loss: 0.2633, val avg loss: 0.7407\n",
      "Training for epoch 22 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 22 finished in 11m 56.95s (- 42m 21.9s) (22 22.0%). train avg loss: 0.2399, val avg loss: 0.7049\n",
      "Training for epoch 23 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 23 finished in 12m 28.52s (- 41m 45.91s) (23 23.0%). train avg loss: 0.2419, val avg loss: 0.7063\n",
      "Training for epoch 24 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 24 finished in 13m 1.33s (- 41m 14.21s) (24 24.0%). train avg loss: 0.2465, val avg loss: 0.6856\n",
      "Training for epoch 25 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 25 finished in 13m 33.26s (- 40m 39.79s) (25 25.0%). train avg loss: 0.238, val avg loss: 0.8547\n",
      "Training for epoch 26 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 26 finished in 14m 3.99s (- 40m 2.12s) (26 26.0%). train avg loss: 0.2327, val avg loss: 0.7126\n",
      "Training for epoch 27 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 27 finished in 14m 37.09s (- 39m 31.38s) (27 27.0%). train avg loss: 0.2293, val avg loss: 0.6622\n",
      "Training for epoch 28 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 28 finished in 15m 8.49s (- 38m 56.13s) (28 28.0%). train avg loss: 0.2263, val avg loss: 0.6546\n",
      "Training for epoch 29 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 29 finished in 15m 40.09s (- 38m 21.59s) (29 29.0%). train avg loss: 0.2154, val avg loss: 0.7072\n",
      "Training for epoch 30 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 30 finished in 16m 13.55s (- 37m 51.62s) (30 30.0%). train avg loss: 0.2262, val avg loss: 0.7406\n",
      "Training for epoch 31 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 31 finished in 16m 46.74s (- 37m 20.81s) (31 31.0%). train avg loss: 0.217, val avg loss: 0.7169\n",
      "Training for epoch 32 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 32 finished in 17m 19.35s (- 36m 48.61s) (32 32.0%). train avg loss: 0.2198, val avg loss: 0.6925\n",
      "Training for epoch 33 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 33 finished in 17m 52.17s (- 36m 16.83s) (33 33.0%). train avg loss: 0.2291, val avg loss: 0.6745\n",
      "Training for epoch 34 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 34 finished in 18m 23.92s (- 35m 42.9s) (34 34.0%). train avg loss: 0.2301, val avg loss: 0.6893\n",
      "Training for epoch 35 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 35 finished in 18m 57.01s (- 35m 11.59s) (35 35.0%). train avg loss: 0.2208, val avg loss: 0.681\n",
      "Training for epoch 36 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 36 finished in 19m 27.75s (- 34m 36.0s) (36 36.0%). train avg loss: 0.2098, val avg loss: 0.6845\n",
      "Training for epoch 37 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 37 finished in 19m 59.53s (- 34m 2.44s) (37 37.0%). train avg loss: 0.2004, val avg loss: 0.6705\n",
      "Training for epoch 38 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 38 finished in 20m 30.92s (- 33m 28.34s) (38 38.0%). train avg loss: 0.2033, val avg loss: 0.6894\n",
      "Training for epoch 39 has started (lr=0.001). Found 1580 batch(es).\n",
      "Epoch 39 finished in 21m 4.33s (- 32m 57.54s) (39 39.0%). train avg loss: 0.2035, val avg loss: 0.6566\n",
      "Training for epoch 40 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 40 finished in 21m 39.15s (- 32m 28.72s) (40 40.0%). train avg loss: 0.183, val avg loss: 0.6169\n",
      "Training for epoch 41 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 41 finished in 22m 14.29s (- 32m 0.07s) (41 41.0%). train avg loss: 0.1809, val avg loss: 0.6241\n",
      "Training for epoch 42 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 42 finished in 22m 49.56s (- 31m 31.3s) (42 42.0%). train avg loss: 0.175, val avg loss: 0.6258\n",
      "Training for epoch 43 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 43 finished in 23m 24.48s (- 31m 1.75s) (43 43.0%). train avg loss: 0.1743, val avg loss: 0.6241\n",
      "Training for epoch 44 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 44 finished in 24m 1.61s (- 30m 34.78s) (44 44.0%). train avg loss: 0.1722, val avg loss: 0.6299\n",
      "Training for epoch 45 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 45 finished in 24m 33.45s (- 30m 0.88s) (45 45.0%). train avg loss: 0.1738, val avg loss: 0.6236\n",
      "Training for epoch 46 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 46 finished in 25m 8.55s (- 29m 30.91s) (46 46.0%). train avg loss: 0.1693, val avg loss: 0.6303\n",
      "Training for epoch 47 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 47 finished in 25m 42.47s (- 28m 59.38s) (47 47.0%). train avg loss: 0.1724, val avg loss: 0.6201\n",
      "Training for epoch 48 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 48 finished in 26m 20.56s (- 28m 32.27s) (48 48.0%). train avg loss: 0.1683, val avg loss: 0.6404\n",
      "Training for epoch 49 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 49 finished in 27m 1.4s (- 28m 7.58s) (49 49.0%). train avg loss: 0.1657, val avg loss: 0.6367\n",
      "Training for epoch 50 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 50 finished in 27m 34.87s (- 27m 34.87s) (50 50.0%). train avg loss: 0.1662, val avg loss: 0.6175\n",
      "Training for epoch 51 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 51 finished in 28m 8.18s (- 27m 1.98s) (51 51.0%). train avg loss: 0.161, val avg loss: 0.6117\n",
      "Training for epoch 52 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 52 finished in 28m 46.53s (- 26m 33.72s) (52 52.0%). train avg loss: 0.1612, val avg loss: 0.6368\n",
      "Training for epoch 53 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 53 finished in 29m 19.16s (- 26m 0.01s) (53 53.0%). train avg loss: 0.1654, val avg loss: 0.6126\n",
      "Training for epoch 54 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 54 finished in 29m 57.45s (- 25m 31.16s) (54 54.0%). train avg loss: 0.1632, val avg loss: 0.6337\n",
      "Training for epoch 55 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 55 finished in 30m 35.41s (- 25m 1.7s) (55 55.0%). train avg loss: 0.1599, val avg loss: 0.6036\n",
      "Training for epoch 56 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 56 finished in 31m 14.04s (- 24m 32.46s) (56 56.0%). train avg loss: 0.1624, val avg loss: 0.6592\n",
      "Training for epoch 57 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 57 finished in 31m 46.03s (- 23m 57.88s) (57 57.0%). train avg loss: 0.1609, val avg loss: 0.6131\n",
      "Training for epoch 58 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 58 finished in 32m 17.19s (- 23m 22.79s) (58 58.0%). train avg loss: 0.1615, val avg loss: 0.6629\n",
      "Training for epoch 59 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 59 finished in 32m 54.54s (- 22m 52.14s) (59 59.0%). train avg loss: 0.1564, val avg loss: 0.6298\n",
      "Training for epoch 60 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 60 finished in 33m 31.96s (- 22m 21.31s) (60 60.0%). train avg loss: 0.1585, val avg loss: 0.6365\n",
      "Training for epoch 61 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 61 finished in 34m 2.97s (- 21m 46.16s) (61 61.0%). train avg loss: 0.1546, val avg loss: 0.6094\n",
      "Training for epoch 62 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 62 finished in 34m 35.56s (- 21m 12.12s) (62 62.0%). train avg loss: 0.1573, val avg loss: 0.6401\n",
      "Training for epoch 63 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 63 finished in 35m 8.48s (- 20m 38.32s) (63 63.0%). train avg loss: 0.153, val avg loss: 0.6278\n",
      "Training for epoch 64 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 64 finished in 35m 42.16s (- 20m 4.97s) (64 64.0%). train avg loss: 0.1542, val avg loss: 0.6188\n",
      "Training for epoch 65 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 65 finished in 36m 16.38s (- 19m 31.89s) (65 65.0%). train avg loss: 0.1596, val avg loss: 0.6239\n",
      "Training for epoch 66 has started (lr=0.0005). Found 1580 batch(es).\n",
      "Epoch 66 finished in 36m 48.25s (- 18m 57.58s) (66 66.0%). train avg loss: 0.1512, val avg loss: 0.6249\n",
      "Training for epoch 67 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 67 finished in 37m 19.28s (- 18m 22.93s) (67 67.0%). train avg loss: 0.141, val avg loss: 0.6256\n",
      "Training for epoch 68 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 68 finished in 37m 51.38s (- 17m 48.89s) (68 68.0%). train avg loss: 0.1401, val avg loss: 0.5993\n",
      "Training for epoch 69 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 69 finished in 38m 23.84s (- 17m 15.06s) (69 69.0%). train avg loss: 0.1377, val avg loss: 0.642\n",
      "Training for epoch 70 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 70 finished in 38m 56.61s (- 16m 41.4s) (70 70.0%). train avg loss: 0.1396, val avg loss: 0.6232\n",
      "Training for epoch 71 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 71 finished in 39m 29.16s (- 16m 7.69s) (71 71.0%). train avg loss: 0.138, val avg loss: 0.6254\n",
      "Training for epoch 72 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 72 finished in 40m 0.33s (- 15m 33.46s) (72 72.0%). train avg loss: 0.1367, val avg loss: 0.6458\n",
      "Training for epoch 73 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 73 finished in 40m 31.63s (- 14m 59.37s) (73 73.0%). train avg loss: 0.1394, val avg loss: 0.6484\n",
      "Training for epoch 74 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 74 finished in 41m 4.44s (- 14m 25.89s) (74 74.0%). train avg loss: 0.1325, val avg loss: 0.6328\n",
      "Training for epoch 75 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 75 finished in 41m 37.39s (- 13m 52.46s) (75 75.0%). train avg loss: 0.1347, val avg loss: 0.6467\n",
      "Training for epoch 76 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 76 finished in 42m 9.77s (- 13m 18.88s) (76 76.0%). train avg loss: 0.1307, val avg loss: 0.6403\n",
      "Training for epoch 77 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 77 finished in 42m 42.34s (- 12m 45.37s) (77 77.0%). train avg loss: 0.1332, val avg loss: 0.6406\n",
      "Training for epoch 78 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 78 finished in 43m 15.5s (- 12m 12.06s) (78 78.0%). train avg loss: 0.1297, val avg loss: 0.6136\n",
      "Training for epoch 79 has started (lr=0.00025). Found 1580 batch(es).\n",
      "Epoch 79 finished in 43m 46.88s (- 11m 38.28s) (79 79.0%). train avg loss: 0.1325, val avg loss: 0.6374\n",
      "Training for epoch 80 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 80 finished in 44m 19.45s (- 11m 4.86s) (80 80.0%). train avg loss: 0.1269, val avg loss: 0.6382\n",
      "Training for epoch 81 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 81 finished in 44m 52.0s (- 10m 31.46s) (81 81.0%). train avg loss: 0.1257, val avg loss: 0.6234\n",
      "Training for epoch 82 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 82 finished in 45m 23.53s (- 9m 57.85s) (82 82.0%). train avg loss: 0.1259, val avg loss: 0.619\n",
      "Training for epoch 83 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 83 finished in 45m 54.76s (- 9m 24.23s) (83 83.0%). train avg loss: 0.1247, val avg loss: 0.6192\n",
      "Training for epoch 84 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 84 finished in 46m 27.0s (- 8m 50.86s) (84 84.0%). train avg loss: 0.122, val avg loss: 0.6516\n",
      "Training for epoch 85 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 85 finished in 47m 1.75s (- 8m 17.96s) (85 85.0%). train avg loss: 0.1233, val avg loss: 0.6099\n",
      "Training for epoch 86 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 86 finished in 47m 36.35s (- 7m 44.99s) (86 86.0%). train avg loss: 0.1248, val avg loss: 0.6451\n",
      "Training for epoch 87 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 87 finished in 48m 9.72s (- 7m 11.8s) (87 87.0%). train avg loss: 0.1225, val avg loss: 0.6478\n",
      "Training for epoch 88 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 88 finished in 48m 43.62s (- 6m 38.68s) (88 88.0%). train avg loss: 0.1219, val avg loss: 0.6433\n",
      "Training for epoch 89 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 89 finished in 49m 17.01s (- 6m 5.47s) (89 89.0%). train avg loss: 0.1212, val avg loss: 0.645\n",
      "Training for epoch 90 has started (lr=0.000125). Found 1580 batch(es).\n",
      "Epoch 90 finished in 49m 49.64s (- 5m 32.18s) (90 90.0%). train avg loss: 0.12, val avg loss: 0.6289\n",
      "Training for epoch 91 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 91 finished in 50m 21.09s (- 4m 58.79s) (91 91.0%). train avg loss: 0.1191, val avg loss: 0.6271\n",
      "Training for epoch 92 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 92 finished in 50m 53.95s (- 4m 25.56s) (92 92.0%). train avg loss: 0.118, val avg loss: 0.65\n",
      "Training for epoch 93 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 93 finished in 51m 26.54s (- 3m 52.32s) (93 93.0%). train avg loss: 0.1189, val avg loss: 0.6308\n",
      "Training for epoch 94 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 94 finished in 51m 58.4s (- 3m 19.05s) (94 94.0%). train avg loss: 0.1204, val avg loss: 0.63\n",
      "Training for epoch 95 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 95 finished in 52m 29.8s (- 2m 45.78s) (95 95.0%). train avg loss: 0.1193, val avg loss: 0.6391\n",
      "Training for epoch 96 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 96 finished in 53m 1.63s (- 2m 12.57s) (96 96.0%). train avg loss: 0.1168, val avg loss: 0.6505\n",
      "Training for epoch 97 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 97 finished in 53m 35.71s (- 1m 39.46s) (97 97.0%). train avg loss: 0.1199, val avg loss: 0.6328\n",
      "Training for epoch 98 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 98 finished in 54m 8.42s (- 1m 6.29s) (98 98.0%). train avg loss: 0.1188, val avg loss: 0.6385\n",
      "Training for epoch 99 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 99 finished in 54m 42.25s (- 0m 33.15s) (99 99.0%). train avg loss: 0.1185, val avg loss: 0.6503\n",
      "Training for epoch 100 has started (lr=6.25e-05). Found 1580 batch(es).\n",
      "Epoch 100 finished in 55m 16.31s (- 0m 0.0s) (100 100.0%). train avg loss: 0.119, val avg loss: 0.6386\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get loss\n",
    "    unweighted_train_loss = train_batch(grps, phns, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"FIN-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"FIN-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"FIN-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"FIN-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "-498emHUaNzb",
    "outputId": "bab4a42d-c2d8-4a89-c7a9-eb0ace0bc12c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5, min_value-.1, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]).to(DEVICE) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]]).to(DEVICE)\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67072,
     "status": "ok",
     "timestamp": 1739960743114,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "MlSPdqo3QDyr",
    "outputId": "364c407d-3bb7-4fd9-ac12-19a8480c9076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on test set: 14.451318293049123%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on test set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1739961996036,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "HSHGOjSmc3Vi",
    "outputId": "7c2a7917-9217-4397-8be2-0c96496d6b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> MALATHION\n",
      "= ['M', 'AX', 'L', 'EH', 'T', 'IY', 'AX', 'N']\n",
      "< M EH L AX D IY AO N ['M', 'EH', 'L', 'AX', 'D', 'IY', 'AO', 'N']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f744f7ff310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLJmB0V/sNcUHuHtZcdQwt",
   "collapsed_sections": [
    "8mDO6QlJZpUZ",
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
