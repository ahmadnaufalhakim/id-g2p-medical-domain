{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1739957705963,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "29775173-7761-4953-d853-502b8b825ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn_gen/exp/en\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1739957711340,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "33e9e6e9-f2b0-4d04-e665-6f2600a2c57e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8274,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7a08073c-d249-49ab-ddaf-f827de5d8d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL =\"dot\"\n",
    "EMB_DIM = \"32\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"100\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "704ba764-a750-40fc-d5c9-0a6d289c3ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/en\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"validation_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    return graphemes, phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.')).lower()\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[1]) for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "1a7e253b-ee59-419e-f7d6-0e469cac96fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq), ...]\n",
    "  graphemes, phonemes = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  word = word.lower()\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1).to(DEVICE)\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "92da8620-4d32-4614-db38-6fdfcd7e04fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 19, 12, 26, 19, 8, 14, 19, 30, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "56a821f8-be28-4de8-8e2c-f5e7b8d2bc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f564fcad190> ([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "train grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "valid grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "test grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "train phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "valid phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "test phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size).to(DEVICE)\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size).to(DEVICE)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size)).to(DEVICE)\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False).to(DEVICE)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size).to(DEVICE)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "9a095505-f179-48d0-c305-f4e69125f170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]]).to(DEVICE)\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size).to(DEVICE) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n",
    "\n",
    "del encoder_test\n",
    "del decoder_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    decoder_input = decoder_input.to(DEVICE)\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Backpropagate loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "      )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1739957723364,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "68700f7a-b173-4800-d808-8d922cd64e2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 32\n",
      "hidden_size: 100\n",
      "n_layers: 1\n",
      "Encoder has a total number of 41224 parameters\n",
      "Decoder has a total number of 78355 parameters\n",
      "Total number of all parameters is 119579\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2952362,
     "status": "ok",
     "timestamp": 1739960675722,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "e9e1eaf7-3a18-4620-b007-cbad6be38496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 1 finished in 0m 33.37s (- 55m 3.32s) (1 1.0%). train avg loss: 1.3529, val avg loss: 1.1767\n",
      "Training for epoch 2 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 2 finished in 1m 6.36s (- 54m 11.46s) (2 2.0%). train avg loss: 0.6, val avg loss: 1.0237\n",
      "Training for epoch 3 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 3 finished in 1m 38.45s (- 53m 3.08s) (3 3.0%). train avg loss: 0.5089, val avg loss: 1.006\n",
      "Training for epoch 4 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 4 finished in 2m 9.04s (- 51m 37.04s) (4 4.0%). train avg loss: 0.5321, val avg loss: 1.0798\n",
      "Training for epoch 5 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 5 finished in 2m 40.53s (- 50m 50.1s) (5 5.0%). train avg loss: 0.4414, val avg loss: 0.9493\n",
      "Training for epoch 6 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 6 finished in 3m 12.09s (- 50m 9.42s) (6 6.0%). train avg loss: 0.3936, val avg loss: 0.8771\n",
      "Training for epoch 7 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 7 finished in 3m 44.81s (- 49m 46.79s) (7 7.0%). train avg loss: 0.393, val avg loss: 0.8536\n",
      "Training for epoch 8 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 8 finished in 4m 16.14s (- 49m 5.61s) (8 8.0%). train avg loss: 0.3687, val avg loss: 0.8875\n",
      "Training for epoch 9 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 9 finished in 4m 47.83s (- 48m 30.31s) (9 9.0%). train avg loss: 0.3434, val avg loss: 0.8462\n",
      "Training for epoch 10 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 10 finished in 5m 19.59s (- 47m 56.29s) (10 10.0%). train avg loss: 0.3538, val avg loss: 0.8393\n",
      "Training for epoch 11 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 11 finished in 5m 50.94s (- 47m 19.44s) (11 11.0%). train avg loss: 0.3418, val avg loss: 0.8326\n",
      "Training for epoch 12 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 12 finished in 6m 22.78s (- 46m 47.09s) (12 12.0%). train avg loss: 0.308, val avg loss: 0.7901\n",
      "Training for epoch 13 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 13 finished in 6m 54.81s (- 46m 16.05s) (13 13.0%). train avg loss: 0.3101, val avg loss: 0.7754\n",
      "Training for epoch 14 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 14 finished in 7m 27.1s (- 45m 46.47s) (14 14.0%). train avg loss: 0.3323, val avg loss: 0.799\n",
      "Training for epoch 15 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 15 finished in 7m 58.95s (- 45m 14.02s) (15 15.0%). train avg loss: 0.2958, val avg loss: 0.7581\n",
      "Training for epoch 16 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 16 finished in 8m 30.5s (- 44m 40.11s) (16 16.0%). train avg loss: 0.3035, val avg loss: 0.7367\n",
      "Training for epoch 17 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 17 finished in 9m 1.2s (- 44m 2.31s) (17 17.0%). train avg loss: 0.2845, val avg loss: 0.7652\n",
      "Training for epoch 18 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 18 finished in 9m 32.96s (- 43m 30.14s) (18 18.0%). train avg loss: 0.2884, val avg loss: 0.7069\n",
      "Training for epoch 19 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 19 finished in 10m 4.96s (- 42m 59.03s) (19 19.0%). train avg loss: 0.2764, val avg loss: 0.7422\n",
      "Training for epoch 20 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 20 finished in 10m 36.52s (- 42m 26.08s) (20 20.0%). train avg loss: 0.2695, val avg loss: 0.7303\n",
      "Training for epoch 21 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 21 finished in 11m 8.63s (- 41m 55.33s) (21 21.0%). train avg loss: 0.2634, val avg loss: 0.7591\n",
      "Training for epoch 22 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 22 finished in 11m 40.42s (- 41m 23.31s) (22 22.0%). train avg loss: 0.2553, val avg loss: 0.7257\n",
      "Training for epoch 23 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 23 finished in 12m 11.02s (- 40m 47.31s) (23 23.0%). train avg loss: 0.2774, val avg loss: 0.723\n",
      "Training for epoch 24 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 24 finished in 12m 42.09s (- 40m 13.27s) (24 24.0%). train avg loss: 0.2458, val avg loss: 0.7307\n",
      "Training for epoch 25 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 25 finished in 13m 14.61s (- 39m 43.84s) (25 25.0%). train avg loss: 0.2791, val avg loss: 0.8324\n",
      "Training for epoch 26 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 26 finished in 13m 46.79s (- 39m 13.17s) (26 26.0%). train avg loss: 0.2557, val avg loss: 0.6793\n",
      "Training for epoch 27 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 27 finished in 14m 18.44s (- 38m 40.97s) (27 27.0%). train avg loss: 0.2414, val avg loss: 0.6845\n",
      "Training for epoch 28 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 28 finished in 14m 50.58s (- 38m 10.07s) (28 28.0%). train avg loss: 0.2365, val avg loss: 0.6822\n",
      "Training for epoch 29 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 29 finished in 15m 22.45s (- 37m 38.42s) (29 29.0%). train avg loss: 0.2484, val avg loss: 0.6717\n",
      "Training for epoch 30 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 30 finished in 15m 53.23s (- 37m 4.2s) (30 30.0%). train avg loss: 0.233, val avg loss: 0.6533\n",
      "Training for epoch 31 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 31 finished in 16m 24.91s (- 36m 32.23s) (31 31.0%). train avg loss: 0.2549, val avg loss: 0.6998\n",
      "Training for epoch 32 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 32 finished in 16m 57.25s (- 36m 1.65s) (32 32.0%). train avg loss: 0.2282, val avg loss: 0.7208\n",
      "Training for epoch 33 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 33 finished in 17m 29.48s (- 35m 30.76s) (33 33.0%). train avg loss: 0.2345, val avg loss: 0.6707\n",
      "Training for epoch 34 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 34 finished in 18m 1.64s (- 34m 59.66s) (34 34.0%). train avg loss: 0.2236, val avg loss: 0.6546\n",
      "Training for epoch 35 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 35 finished in 18m 33.76s (- 34m 28.42s) (35 35.0%). train avg loss: 0.22, val avg loss: 0.6733\n",
      "Training for epoch 36 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 36 finished in 19m 4.74s (- 33m 55.1s) (36 36.0%). train avg loss: 0.2177, val avg loss: 0.6902\n",
      "Training for epoch 37 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 37 finished in 19m 35.49s (- 33m 21.52s) (37 37.0%). train avg loss: 0.2116, val avg loss: 0.6858\n",
      "Training for epoch 38 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 38 finished in 20m 7.21s (- 32m 49.66s) (38 38.0%). train avg loss: 0.2446, val avg loss: 0.6873\n",
      "Training for epoch 39 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 39 finished in 20m 38.72s (- 32m 17.49s) (39 39.0%). train avg loss: 0.2168, val avg loss: 0.643\n",
      "Training for epoch 40 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 40 finished in 21m 11.3s (- 31m 46.94s) (40 40.0%). train avg loss: 0.217, val avg loss: 0.6727\n",
      "Training for epoch 41 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 41 finished in 21m 43.38s (- 31m 15.59s) (41 41.0%). train avg loss: 0.21, val avg loss: 0.6795\n",
      "Training for epoch 42 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 42 finished in 22m 15.24s (- 30m 43.9s) (42 42.0%). train avg loss: 0.2066, val avg loss: 0.6777\n",
      "Training for epoch 43 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 43 finished in 22m 46.48s (- 30m 11.38s) (43 43.0%). train avg loss: 0.206, val avg loss: 0.7125\n",
      "Training for epoch 44 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 44 finished in 23m 17.75s (- 29m 38.95s) (44 44.0%). train avg loss: 0.2174, val avg loss: 0.6513\n",
      "Training for epoch 45 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 45 finished in 23m 49.62s (- 29m 7.32s) (45 45.0%). train avg loss: 0.2077, val avg loss: 0.6697\n",
      "Training for epoch 46 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 46 finished in 24m 21.33s (- 28m 35.48s) (46 46.0%). train avg loss: 0.209, val avg loss: 0.6654\n",
      "Training for epoch 47 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 47 finished in 24m 54.52s (- 28m 5.31s) (47 47.0%). train avg loss: 0.2129, val avg loss: 0.6243\n",
      "Training for epoch 48 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 48 finished in 25m 26.8s (- 27m 34.03s) (48 48.0%). train avg loss: 0.2105, val avg loss: 0.6692\n",
      "Training for epoch 49 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 49 finished in 25m 57.96s (- 27m 1.55s) (49 49.0%). train avg loss: 0.2049, val avg loss: 0.6526\n",
      "Training for epoch 50 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 50 finished in 26m 28.78s (- 26m 28.78s) (50 50.0%). train avg loss: 0.1977, val avg loss: 0.6511\n",
      "Training for epoch 51 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 51 finished in 27m 0.56s (- 25m 57.01s) (51 51.0%). train avg loss: 0.1969, val avg loss: 0.6521\n",
      "Training for epoch 52 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 52 finished in 27m 32.84s (- 25m 25.7s) (52 52.0%). train avg loss: 0.2034, val avg loss: 0.6753\n",
      "Training for epoch 53 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 53 finished in 28m 4.58s (- 24m 53.87s) (53 53.0%). train avg loss: 0.1994, val avg loss: 0.6583\n",
      "Training for epoch 54 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 54 finished in 28m 36.87s (- 24m 22.52s) (54 54.0%). train avg loss: 0.1859, val avg loss: 0.6517\n",
      "Training for epoch 55 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 55 finished in 29m 9.34s (- 23m 51.28s) (55 55.0%). train avg loss: 0.2011, val avg loss: 0.6655\n",
      "Training for epoch 56 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 56 finished in 29m 40.38s (- 23m 18.87s) (56 56.0%). train avg loss: 0.1941, val avg loss: 0.6139\n",
      "Training for epoch 57 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 57 finished in 30m 11.25s (- 22m 46.38s) (57 57.0%). train avg loss: 0.1874, val avg loss: 0.6648\n",
      "Training for epoch 58 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 58 finished in 30m 43.17s (- 22m 14.71s) (58 58.0%). train avg loss: 0.1913, val avg loss: 0.6749\n",
      "Training for epoch 59 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 59 finished in 31m 16.5s (- 21m 44.01s) (59 59.0%). train avg loss: 0.1975, val avg loss: 0.6428\n",
      "Training for epoch 60 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 60 finished in 31m 50.61s (- 21m 13.74s) (60 60.0%). train avg loss: 0.1951, val avg loss: 0.6277\n",
      "Training for epoch 61 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 61 finished in 32m 25.33s (- 20m 43.74s) (61 61.0%). train avg loss: 0.204, val avg loss: 0.6841\n",
      "Training for epoch 62 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 62 finished in 32m 59.96s (- 20m 13.53s) (62 62.0%). train avg loss: 0.1909, val avg loss: 0.6575\n",
      "Training for epoch 63 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 63 finished in 33m 33.59s (- 19m 42.58s) (63 63.0%). train avg loss: 0.1876, val avg loss: 0.6173\n",
      "Training for epoch 64 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 64 finished in 34m 6.34s (- 19m 11.07s) (64 64.0%). train avg loss: 0.1911, val avg loss: 0.678\n",
      "Training for epoch 65 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 65 finished in 34m 37.39s (- 18m 38.59s) (65 65.0%). train avg loss: 0.1843, val avg loss: 0.6519\n",
      "Training for epoch 66 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 66 finished in 35m 9.48s (- 18m 6.7s) (66 66.0%). train avg loss: 0.2157, val avg loss: 0.6989\n",
      "Training for epoch 67 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 67 finished in 35m 41.6s (- 17m 34.82s) (67 67.0%). train avg loss: 0.2074, val avg loss: 0.649\n",
      "Training for epoch 68 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 68 finished in 36m 14.38s (- 17m 3.24s) (68 68.0%). train avg loss: 0.1687, val avg loss: 0.6251\n",
      "Training for epoch 69 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 69 finished in 36m 46.36s (- 16m 31.26s) (69 69.0%). train avg loss: 0.1652, val avg loss: 0.6306\n",
      "Training for epoch 70 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 70 finished in 37m 18.66s (- 15m 59.43s) (70 70.0%). train avg loss: 0.1597, val avg loss: 0.6412\n",
      "Training for epoch 71 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 71 finished in 37m 50.0s (- 15m 27.18s) (71 71.0%). train avg loss: 0.159, val avg loss: 0.6244\n",
      "Training for epoch 72 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 72 finished in 38m 21.47s (- 14m 55.02s) (72 72.0%). train avg loss: 0.1568, val avg loss: 0.6516\n",
      "Training for epoch 73 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 73 finished in 38m 53.91s (- 14m 23.23s) (73 73.0%). train avg loss: 0.1578, val avg loss: 0.6283\n",
      "Training for epoch 74 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 74 finished in 39m 25.35s (- 13m 51.07s) (74 74.0%). train avg loss: 0.1534, val avg loss: 0.625\n",
      "Training for epoch 75 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 75 finished in 39m 58.13s (- 13m 19.38s) (75 75.0%). train avg loss: 0.1502, val avg loss: 0.6189\n",
      "Training for epoch 76 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 76 finished in 40m 30.42s (- 12m 47.5s) (76 76.0%). train avg loss: 0.1496, val avg loss: 0.6473\n",
      "Training for epoch 77 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 77 finished in 41m 2.14s (- 12m 15.45s) (77 77.0%). train avg loss: 0.1522, val avg loss: 0.6393\n",
      "Training for epoch 78 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 78 finished in 41m 33.61s (- 11m 43.32s) (78 78.0%). train avg loss: 0.1496, val avg loss: 0.626\n",
      "Training for epoch 79 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 79 finished in 42m 5.66s (- 11m 11.38s) (79 79.0%). train avg loss: 0.1387, val avg loss: 0.6205\n",
      "Training for epoch 80 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 80 finished in 42m 37.41s (- 10m 39.35s) (80 80.0%). train avg loss: 0.1367, val avg loss: 0.6283\n",
      "Training for epoch 81 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 81 finished in 43m 9.09s (- 10m 7.32s) (81 81.0%). train avg loss: 0.1359, val avg loss: 0.612\n",
      "Training for epoch 82 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 82 finished in 43m 40.5s (- 9m 35.23s) (82 82.0%). train avg loss: 0.1369, val avg loss: 0.6279\n",
      "Training for epoch 83 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 83 finished in 44m 12.45s (- 9m 3.27s) (83 83.0%). train avg loss: 0.1332, val avg loss: 0.6266\n",
      "Training for epoch 84 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 84 finished in 44m 44.35s (- 8m 31.31s) (84 84.0%). train avg loss: 0.1361, val avg loss: 0.6089\n",
      "Training for epoch 85 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 85 finished in 45m 16.95s (- 7m 59.46s) (85 85.0%). train avg loss: 0.1316, val avg loss: 0.6154\n",
      "Training for epoch 86 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 86 finished in 45m 49.26s (- 7m 27.55s) (86 86.0%). train avg loss: 0.1341, val avg loss: 0.6066\n",
      "Training for epoch 87 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 87 finished in 46m 20.95s (- 6m 55.54s) (87 87.0%). train avg loss: 0.1352, val avg loss: 0.6098\n",
      "Training for epoch 88 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 88 finished in 46m 52.0s (- 6m 23.45s) (88 88.0%). train avg loss: 0.1336, val avg loss: 0.6414\n",
      "Training for epoch 89 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 89 finished in 47m 23.82s (- 5m 51.48s) (89 89.0%). train avg loss: 0.1306, val avg loss: 0.6159\n",
      "Training for epoch 90 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 90 finished in 47m 55.73s (- 5m 19.53s) (90 90.0%). train avg loss: 0.1332, val avg loss: 0.6192\n",
      "Training for epoch 91 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 91 finished in 48m 26.79s (- 4m 47.49s) (91 91.0%). train avg loss: 0.131, val avg loss: 0.6532\n",
      "Training for epoch 92 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 92 finished in 48m 58.0s (- 4m 15.48s) (92 92.0%). train avg loss: 0.1334, val avg loss: 0.647\n",
      "Training for epoch 93 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 93 finished in 49m 30.42s (- 3m 43.58s) (93 93.0%). train avg loss: 0.1274, val avg loss: 0.6428\n",
      "Training for epoch 94 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 94 finished in 50m 2.13s (- 3m 11.63s) (94 94.0%). train avg loss: 0.1262, val avg loss: 0.6431\n",
      "Training for epoch 95 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 95 finished in 50m 33.84s (- 2m 39.68s) (95 95.0%). train avg loss: 0.129, val avg loss: 0.6389\n",
      "Training for epoch 96 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 96 finished in 51m 5.99s (- 2m 7.75s) (96 96.0%). train avg loss: 0.1296, val avg loss: 0.6399\n",
      "Training for epoch 97 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 97 finished in 51m 38.03s (- 1m 35.82s) (97 97.0%). train avg loss: 0.1254, val avg loss: 0.6712\n",
      "Training for epoch 98 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 98 finished in 52m 10.32s (- 1m 3.88s) (98 98.0%). train avg loss: 0.1232, val avg loss: 0.644\n",
      "Training for epoch 99 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 99 finished in 52m 41.96s (- 0m 31.94s) (99 99.0%). train avg loss: 0.1206, val avg loss: 0.6535\n",
      "Training for epoch 100 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 100 finished in 53m 13.77s (- 0m 0.0s) (100 100.0%). train avg loss: 0.1206, val avg loss: 0.6456\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get loss\n",
    "    unweighted_train_loss = train_batch(grps, phns, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "-498emHUaNzb",
    "outputId": "bab4a42d-c2d8-4a89-c7a9-eb0ace0bc12c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAHFCAYAAAAg3/mzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOzdd3iUVdrH8e9k0gkkJEAIHUUkgPQizQIKhqICCgqKYFlddVVYcGXV3dX1ldVFRNcFdaUsisiqgLiilEU6FhAsNOmhJISaEAKp8/5xpiSkMJNkMiTz+1zXXDPzzDMzZ0KZO+e+z30sNpvNhoiIiIiPBPh6ACIiIuLfFIyIiIiITykYEREREZ9SMCIiIiI+pWBEREREfErBiIiIiPiUghERERHxKQUjIiIi4lMKRkRERMSnFIyISJnMnj0bi8XCpk2bfD0UEamkFIyIiIiITykYEREREZ9SMCIiXpeYmMg999xDnTp1CAkJIT4+ntdee428vLwC502fPp22bdsSERFB9erVadGiBX/84x+dj2dkZDB+/HiaNm1KaGgo0dHRdOrUiXnz5lX0RxKRchTo6wGISNV2/PhxunfvTlZWFn/9619p0qQJ//3vfxk/fjx79+5l2rRpAHz00Uc8+uij/O53v2Py5MkEBASwZ88etm/f7nytcePG8f777/PSSy/Rvn17zp07xy+//MLJkyd99fFEpBwoGBERr5oyZQpHjhzh22+/pUuXLgD069eP3Nxc3n77bZ566imaN2/O+vXriYqK4s0333Q+t0+fPgVea/369fTt25exY8c6jw0YMKBiPoiIeI3SNCLiVStXrqRly5bOQMRh9OjR2Gw2Vq5cCUCXLl04c+YMd999N5999hknTpwo9FpdunThyy+/5JlnnmHVqlWcP3++Qj6DiHiXghER8aqTJ08SFxdX6Hi9evWcjwPce++9zJw5k4MHDzJ06FDq1KlD165dWb58ufM5b775Jn/4wx9YtGgRN954I9HR0dx+++3s3r27Yj6MiHiFghER8aqYmBiSkpIKHT969CgAtWrVch4bM2YMGzZsIDU1lS+++AKbzcbAgQM5ePAgANWqVeOFF15g586dJCcnM336dL755hsGDRpUMR9GRLxCwYiIeFWfPn3Yvn07P/zwQ4Hjc+bMwWKxcOONNxZ6TrVq1UhISODZZ58lKyuLbdu2FTonNjaW0aNHc/fdd7Nr1y4yMjK89hlExLtUwCoi5WLlypUcOHCg0PGHH36YOXPmMGDAAF588UUaN27MF198wbRp0/jtb39L8+bNAXjooYcICwujR48exMXFkZyczKRJk4iMjKRz584AdO3alYEDB9KmTRtq1qzJjh07eP/99+nWrRvh4eEV+XFFpBxZbDabzdeDEJHKa/bs2YwZM6bYx/fv309AQAATJ05k6dKlpKWlccUVV/Dggw8ybtw4AgLMBO2cOXOYPXs227dv5/Tp09SqVYuePXvy3HPPcc011wAwceJEVqxYwd69e8nIyKB+/frcdtttPPvss8TExFTI5xWR8qdgRERERHxKNSMiIiLiUwpGRERExKcUjIiIiIhPKRgRERERn1IwIiIiIj6lYERERER8qlI0PcvLy+Po0aNUr14di8Xi6+GIiIiIG2w2G2fPnqVevXrOnkLFneiR1atX2wYOHGiLi4uzAbaFCxe6/dx169bZrFarrW3bth6956FDh2yALrrooosuuuhSCS+HDh0q8Xve45mRc+fO0bZtW8aMGcPQoUPdfl5qaiqjRo2iT58+HDt2zKP3rF69OgCHDh2iRo0aHj1XREREfCMtLY2GDRs6v8eL43EwkpCQQEJCgscDevjhhxkxYgRWq5VFixZ59FxHaqZGjRoKRkRERCqZS5VYVEgB66xZs9i7dy9//vOf3To/MzOTtLS0AhcRERGpmrwejOzevZtnnnmGuXPnEhjo3kSMY6dOx6Vhw4ZeHqWIiIj4ileDkdzcXEaMGMELL7zg3CbcHRMnTiQ1NdV5OXTokBdHKSIiIr7k1aW9Z8+eZdOmTWzZsoXHH38cMMt0bTYbgYGBLFu2jN69exd6XkhICCEhId4cmoiICGB+cc7Ozvb1MCqloKAgrFZrmV/Hq8FIjRo1+PnnnwscmzZtGitXruSTTz6hadOm3nx7ERGRYtlsNpKTkzlz5oyvh1KpRUVFUbdu3TL1AfM4GElPT2fPnj3O+/v372fr1q1ER0fTqFEjJk6cyJEjR5gzZw4BAQG0bt26wPPr1KlDaGhooeMiIiIVyRGI1KlTh/DwcDXV9JDNZiMjI4OUlBQA4uLiSv1aHgcjmzZt4sYbb3TeHzduHAD33Xcfs2fPJikpicTExFIPSERExNtyc3OdgUhMTIyvh1NphYWFAZCSkkKdOnVKnbKx2Gw2W3kOzBvS0tKIjIwkNTVVfUZERKTMLly4wP79+2nSpInzC1VK5/z58xw4cICmTZsSGhpa4DF3v7+1UZ6IiPgtpWbKrjx+hgpGRERExKcUjIiIiPipJk2aMHXqVF8Pw7tLe0VERKR83XDDDbRr165cgojvv/+eatWqlcOoysavg5HT57JIz8whMjyIGqFBvh6OiIhImdlsNnJzc93agqV27doVMKJL8+s0zXOf/UKvV79m4Q9HfD0UERGRSxo9ejSrV6/mjTfewGKxYLFYmD17NhaLhaVLl9KpUydCQkJYu3Yte/fu5bbbbiM2NpaIiAg6d+7MihUrCrzexWkai8XCe++9x+DBgwkPD+eqq65i8eLFXv9cfh2MBAWYCuDs3Dwfj0RERHzNZrORkZXjk4u7XTbeeOMNunXrxkMPPURSUhJJSUnOzWSffvppJk2axI4dO2jTpg3p6en079+fFStWsGXLFvr168egQYMu2QvshRdeYNiwYfz000/079+fkSNHcurUqTL/fEvi12maIKuJxbIUjIiI+L3z2bm0/NNSn7z39hf7ER586a/kyMhIgoODCQ8Pp27dugDs3LkTgBdffJGbb77ZeW5MTAxt27Z13n/ppZdYuHAhixcvdu4XV5TRo0dz9913A/Dyyy/zj3/8g++++45bbrmlVJ/NHf49MxJoPn5O7mXf901ERKREnTp1KnD/3LlzPP3007Rs2ZKoqCgiIiLYuXPnJWdG2rRp47xdrVo1qlev7mz57i3+PTOiNI2IiNiFBVnZ/mI/n713WV28KmbChAksXbqUyZMn06xZM8LCwrjjjjvIysoq8XWCggou6LBYLOTlefd70r+DEaVpRETEzmKxuJUq8bXg4GByc3Mved7atWsZPXo0gwcPBsxGtwcOHPDy6EpHaRqUphERkcqjSZMmfPvttxw4cIATJ04UO2vRrFkzFixYwNatW/nxxx8ZMWKE12c4Ssu/gxGlaUREpJIZP348VquVli1bUrt27WJrQF5//XVq1qxJ9+7dGTRoEP369aNDhw4VPFr3XP7zUV7kSNMoGBERkcqiefPmbNy4scCx0aNHFzqvSZMmrFy5ssCxxx57rMD9i9M2RS0xPnPmTOkG6gH/nhkJdAQjStOIiIj4in8HI5oZERER8Tk/D0ZUMyIiIuJrfh6MKE0jIiLiawpG0MyIiIiIL/l5MKI0jYiIiK/5eTBinxnJUZpGRETEVxSMANmXaUc6ERERf+DXwUig0jQiIiI+59fBSLDSNCIi4meaNGnC1KlTfT2MAvw6GFGaRkRExPf8OhhRmkZERMT3/DoYUZpGREQqk3feeYf69euTd9GM/q233sp9993H3r17ue2224iNjSUiIoLOnTuzYsUKH43WfX4djDjSNDlK04iIiM0GWed8cylit9yi3HnnnZw4cYKvv/7aeez06dMsXbqUkSNHkp6eTv/+/VmxYgVbtmyhX79+DBo0iMTERG/91MpFoK8H4EuONE1WjoIRERG/l50BL9fzzXv/8SgEV7vkadHR0dxyyy18+OGH9OnTB4CPP/6Y6Oho+vTpg9VqpW3bts7zX3rpJRYuXMjixYt5/PHHvTb8svLrmZFg7U0jIiKVzMiRI/n000/JzMwEYO7cudx1111YrVbOnTvH008/TcuWLYmKiiIiIoKdO3dqZuRypjSNiIg4BYWbGQpfvbebBg0aRF5eHl988QWdO3dm7dq1TJkyBYAJEyawdOlSJk+eTLNmzQgLC+OOO+4gKyvLWyMvF34djLhW09iw2WxYLBYfj0hERHzGYnErVeJrYWFhDBkyhLlz57Jnzx6aN29Ox44dAVi7di2jR49m8ODBAKSnp3PgwAEfjtY9fh2MOGZGwAQkwYEKRkRE5PI3cuRIBg0axLZt27jnnnucx5s1a8aCBQsYNGgQFouF559/vtDKm8uRakbslKoREZHKonfv3kRHR7Nr1y5GjBjhPP76669Ts2ZNunfvzqBBg+jXrx8dOnTw4Ujd49czI440Ddh7jQT7cDAiIiJuslqtHD1auL6lSZMmrFy5ssCxxx57rMD9yzFt49czI4EBrmAkS11YRUREfMKvgxGLxeJM1ShNIyIi4ht+HYxAvhU1agkvIiLiE34fjDhW1ChNIyIi4hsKRpxdWBWMiIj4G5ube8JI8crjZ+j3wUiwPU2To5bwIiJ+IygoCICMjAwfj6Tyc/wMHT/T0vDrpb0AgUrTiIj4HavVSlRUFCkpKQCEh4erC7eHbDYbGRkZpKSkEBUVhdVqLfVr+X0wEuRsCa9gRETEn9StWxfAGZBI6URFRTl/lqXlcTCyZs0a/v73v7N582aSkpJYuHAht99+e7HnL1iwgOnTp7N161YyMzNp1aoVf/nLX+jXr1+ZBl5enJvlKU0jIuJXLBYLcXFx1KlTh+zsbF8Pp1IKCgoq04yIg8fByLlz52jbti1jxoxh6NChlzx/zZo13Hzzzbz88stERUUxa9YsBg0axLfffkv79u1LNejypAJWERH/ZrVay+ULVUrP42AkISGBhIQEt8+fOnVqgfsvv/wyn332GZ9//vllEoyYNI1qRkRERHyjwlfT5OXlcfbsWaKjoyv6rYukNI2IiIhvVXgB62uvvca5c+cYNmxYsedkZmaSmZnpvJ+Wlua18ShNIyIi4lsVOjMyb948/vKXvzB//nzq1KlT7HmTJk0iMjLSeWnYsKHXxqQ0jYiIiG9VWDAyf/58HnjgAf7zn/9w0003lXjuxIkTSU1NdV4OHTrktXEpTSMiIuJbFZKmmTdvHvfffz/z5s1jwIABlzw/JCSEkJCQChiZ0jQiIiK+5nEwkp6ezp49e5z39+/fz9atW4mOjqZRo0ZMnDiRI0eOMGfOHMAEIqNGjeKNN97g2muvJTk5GYCwsDAiIyPL6WOUnpqeiYiI+JbHaZpNmzbRvn1757LccePG0b59e/70pz8BkJSURGJiovP8d955h5ycHB577DHi4uKclyeffLKcPkIZ5OZQK+84NThHttI0IiIiPuHxzMgNN9xQ4g59s2fPLnB/1apVnr5FxfloBM/tXspZ60Nk5/q+54mIiIg/8u9de2vUAyDOclJpGhERER9RMALU5ZTSNCIiIj6iYASIs5zSzIiIiIiPKBgB6ioYERER8Rk/D0bqA46ZEaVpREREfMHPgxEzM1LDkkFAVrqPByMiIuKf/DsYCalOljUCgPDMYz4ejIiIiH/y72AEyAg1G/ZFZKX4eCQiIiL+ye+DkfNhdQGonnXcxyMRERHxT34fjFwIiwUgMlszIyIiIr7g98FIZriZGYnM1syIiIiIL/h9MJJdLQ6AmjknfDwSERER/6RgxD4zUjNXMyMiIiK+4PfBSE6EmRmJydXMiIiIiC/4fTBiq24an0Xa0iD7go9HIyIi4n/8PhghNIrztmBz++xR345FRETED/l9MBIUZCXJFm3upCkYERERqWh+H4wEWwNIVjAiIiLiM34fjARaLSThCEaO+HYwIiIifsjvg5EgzYyIiIj4lN8HI8HWAJJsMeaOghEREZEK5/fBSKDVkm9mRGkaERGRiub3wUiQNcC5msammREREZEKp2Akf81IegrkZvt2QCIiIn5GwYjVwimqk2kLxIINzib7ekgiIiJ+RcGINQAbAaTYapoD7qRqfv4Evp/h3YGJiIj4iUBfD8DXAgMsACQRTUOOX7qI9UIaLPgN2HKheT+IbFABoxQREam6/H5mxGKxEFRgRc0lZkaObDKBCMCp/d4dnIiIiB/w+2AECq6ouWQwcug71+0zB703KBERET+hYISLu7BeIk1z6FvX7dMKRkRERMpKwQhmRY1bXVjzcuHwJtf9M4neHZiIiIgfUDCCB/vTHN8JmWmu+0rTiIiIlJmCES6qGTmbZGZAiuJI0YTZlwErTSMiIlJmCkYw+9McJwqbxWpWyqSnFH2io3i15e3m+mwS5GRWzCBFRESqKAUjmJ178wggK6y2OVBcqsYRjLQYAEHhgA1SD1fIGEVERKoqBSOYNA3AhbC65kBRK2rOnYBTe83tBp0hqpG5ffqA9wcoIiJShSkYwaymATgfFmsOFDUz4pgVqR0PYVEQ1djcVxGriIhImSgYAQLtMyMZoSXMjDiKVxt2Mdc17cGIilhFRETKRMEIpmYEICPEXjNyNqnwSY6ZkYZdzbVzZkS9RkRERMpCwQiuNE16cB1z4OI0TU4WHP3B3HbMjDhqRpSmERERKRMFI7jSNGeDHTUjF6Vpkn+GnAumv0hMM3NMaRoREZFyoWAEV5om1RGMnDkEB9a5TnDWi3QFi5lFcaZpMk5A1rkKGqmIiEjVo2AEV5rmTHAstBhoGp99OBwObzYnXFy8CmZFTWikua26ERERkVJTMIIrTZOda4OhM6DpdZCVDh8MgWPbCs6M5OfsNaJUjYiISGl5HIysWbOGQYMGUa9ePSwWC4sWLbrkc1avXk3Hjh0JDQ3liiuu4O233y7VYL0lyBmM5EFQKNw1zzQ2u3AGZg8wq2ssVqjXoeAT1WtERESkzDwORs6dO0fbtm1566233Dp///799O/fn169erFlyxb++Mc/8sQTT/Dpp596PFhvCbanaXJy88yBkAgY+THUvQbOnzbH4tpAcHjBJ9ZsYq6VphERESm1QE+fkJCQQEJCgtvnv/322zRq1IipU6cCEB8fz6ZNm5g8eTJDhw719O29wpGmycq1uQ6G1YR7FsKsBDi5Gxr3KPxEx8yIWsKLiIiUmsfBiKc2btxI3759Cxzr168fM2bMIDs7m6CgoELPyczMJDPTtRtuWlqaV8dYIE2TX0RtGLMEfv4Y2txV+Ik1laYREREpK68XsCYnJxMbG1vgWGxsLDk5OZw4caLI50yaNInIyEjnpWHDhl4dY6E0TX4RdaDbY1AtpvBjzgJWpWlERERKq0JW01gcvTnsbDZbkccdJk6cSGpqqvNy6NAhr46vyDSNOxzBSGYqnD9TzqMSERHxD15P09StW5fk5OQCx1JSUggMDCQmpojZBiAkJISQkBBvD82p2DTNpQRXg2q14dxxk6oJi/LC6ERERKo2r8+MdOvWjeXLlxc4tmzZMjp16lRkvYgvOJqeeRyMQL4iVtWNiIiIlIbHwUh6ejpbt25l69atgFm6u3XrVhITTd3ExIkTGTVqlPP8Rx55hIMHDzJu3Dh27NjBzJkzmTFjBuPHjy+nj1B2jpmRHE/TNKAN80RERMrI4zTNpk2buPHGG533x40bB8B9993H7NmzSUpKcgYmAE2bNmXJkiWMHTuWf/7zn9SrV48333zzslnWC65gJKs0MyPOFTUqYhURESkNj4ORG264wVmAWpTZs2cXOnb99dfzww8/ePpWFUZpGhEREd/R3jSUMU2jXiMiIiJlomCEMqZpovKlaUqYMRIREZGiKRihjGmayAaABbIz4FzRTdxERESkeApGKGOaJjAEatQzt5WqERER8ZiCEcrQ9MxBG+aJiIiUmoIRXGmaUtWMgIpYRUREykDBCBAUWIY0DeTbMO9A+QxIRETEjygYAYICypimqd3CXCf9WE4jEhER8R8KRoCgwDKspgFo2NVcJ/8CmenlNCoRERH/oGCE/AWspUzTRNaHyEZgy4Ujm8pxZCIiIlWfghHKIU0D0Mg+O5L4TTmMSERExH8oGKEc0jTgStUoGBEREfGIghEKpmlK2gSwRI26mevDmyAvt5xGJiIiUvUpGMGVpgHIyStlMFInHkJqQNZZOLatnEYmIiJS9SkYwZWmgTKkagKs0KCzua1UjYiIiNsUjOBK0wBk55Rh591G15rrQwpGRERE3KVgBAgMyDczklceRazflnFEIiIi/kPBCGCxWJz705RpRU2DTmCxQtphSD1cTqMTERGp2hSM2DlX1JQlTRNcDeLamNuqGxEREXGLghE7R6qmTGkagIb2uhEFIyIiIm5RMGIXHFgOXVjB1YlVRawiIiJuUTBiVy5pGnDNjBzbBplnyzgqERGRqk/BiF2gtZzSNDXiIKox2PLg8Pcln5t9Ac4klu39REREKjkFI3aumZEyBiPg6jdyqbqRj++DN9rCgfVlf08REZFKSsGIXXC+/WnKzJ1N8w5uhF+/MjMo30wr+3uKiIhUUgpG7MotTQMFN83LzSn6nDWvum7v+hLSksr+viIiIpWQghG7ck3T1G4BoZGQfQ62Lyr8+KHvYe9K0yCt1tVgy4Ut75f9fUVERCohBSN2QeWZpgkIgC6/Mbe/GFe4G6tjVqTt3dBrnLm9+d+Ql1v29xYREalkFIzYOdrB55RHmgbg+j9AvQ5wIRUWPOwKNI78ALuXgSXABCItb4OwmqaF/O7l5fPeIiIilYiCETvHzEhWeaRpAKxBMPQ9CKoGB9fBhjfN8TV/N9fXDIOYKyEoDNqOMMc2zyqf9xYREalEFIzYlWuaxiHmSkh4xdxe+ZJJxexaAljguvGu8zqNMde7l8GZQ+X3/iIiIpWAghE7x9LeckvTOLS/B+Jvhbwc+PwJc6z1UKh1leucWldBk15mme8Pc8r3/UVERC5zCkbsHEt7yy1N42CxwKA3oHo9x4GCsyIOjtmRH+ZAbnb5jkFEROQypmDEzitpGofwaBjyLgSFQ4d7oU584XNaDILwWpCebJqhiYiI+IlAXw/gcuEIRnLKumtvcZr2gj8cAGtw0Y8HBpuUzvqpsPxPkHUOWt4OQaHeGY+IiMhlQjMjdo6lvdneCkYAAkNM2qY4nR8wy3xP7YOFD8OUeFj2vLkvIiJSRSkYsXMu7fVGmsZdUY3g0W+h93NQowGcP2WWBL/ZHt4fDNsXq55ERESqHAUjdq6aES/OjLijeixcNwGe/BHumgfNbgIspn38f+6F11ubZcJnk307Tl9KPVz8nj8iIlLpKBixc3Zg9XUw4mANhBb94Z5P4Ykt0HMsVKttClzX/B1m3Aw5mb4eZcU7vAlebwX/fdLXIxERkXKiYMTuskjTFCe6Kdz0Fxi7He6cbYKSM4mw878+HpgPHFhrro/84NtxiIhIuVEwYnfZpGlKEhgMrQZDx9Hmvj82SDu+y1ynHfHtOEREpNwoGLG77NI0JWl/L2CBfavg1H5fj6ZiHd9pri+kmuXPIiJS6SkYsfNq07PyVrMxXHGDub3lA1+OpGLl5cHxX13305J8NxYRESk3pQpGpk2bRtOmTQkNDaVjx46sXbu2xPPnzp1L27ZtCQ8PJy4ujjFjxnDy5MlSDdhbXDUjlWBmBKDjfeZ661z/WVmSdhiy882GKFUjIlIleByMzJ8/n6eeeopnn32WLVu20KtXLxISEkhMTCzy/HXr1jFq1CgeeOABtm3bxscff8z333/Pgw8+WObBl6fAypSmAbi6P4THwNkk2LPc16OpGI56EYe0o74Zh4iIlCuPg5EpU6bwwAMP8OCDDxIfH8/UqVNp2LAh06dPL/L8b775hiZNmvDEE0/QtGlTevbsycMPP8ymTZvKPPjyFFyZ0jRgurm2vdvc3vxv346lojjqRRw0MyIiUiV4FIxkZWWxefNm+vbtW+B437592bBhQ5HP6d69O4cPH2bJkiXYbDaOHTvGJ598woABA0o/ai+odGkagA72VM3upe7NEuRkeXc83uYIRqwh5lozIyIiVYJHwciJEyfIzc0lNja2wPHY2FiSk4vuCNq9e3fmzp3L8OHDCQ4Opm7dukRFRfGPf/yj2PfJzMwkLS2twMXbKl2aBqB2c2jUDWx5pnakJL8sgJfjYN3rFTM2b3CkaRp3M9cKRkREqoRSFbBaLtrszWazFTrmsH37dp544gn+9Kc/sXnzZr766iv279/PI488UuzrT5o0icjISOelYcOGpRmmRypdmsbBMTvyw/tmtUlRTh+Ez5+EvBxY/yZkX6i48ZUXm80VjFzZ21wrTSMiUiV4FIzUqlULq9VaaBYkJSWl0GyJw6RJk+jRowcTJkygTZs29OvXj2nTpjFz5kySkopemjlx4kRSU1Odl0OHDnkyzFKpFE3PitLyNgiJhDMHYc+Kwo/n5ZodgDPts0vnT8H2zyp2jOXhbJL5DBYrNOlljmlmRESkSvAoGAkODqZjx44sX15w9cby5cvp3r17kc/JyMggIKDg21itVsDMqBQlJCSEGjVqFLh4myNNU+mCkeBwaDvc3P7kftMILb91UyBxIwRXtzdLAzbNqNAhlgtHvUjMlVCzibmdcaJyzvKIiEgBHqdpxo0bx3vvvcfMmTPZsWMHY8eOJTEx0Zl2mThxIqNGjXKeP2jQIBYsWMD06dPZt28f69ev54knnqBLly7Uq1ev/D5JGVWqpmcX6/0cNO4JWWfhg6Hw40fm+JHNsOpv5nb/v5vzAgLh0LeQ/IvvxlsajhRN7ashrCYEhpr7Z9X4TESksgv09AnDhw/n5MmTvPjiiyQlJdG6dWuWLFlC48aNAUhKSirQc2T06NGcPXuWt956i9///vdERUXRu3dvXnnllfL7FOUguLKmaQBCI+HeBbDot/DLpyYtc2o//PyxqRNpNRja3gUWC7QYYNI0m2bCwCm+Hrn7HDMjtVuYz1GjHpzaZ1I10U19OzYRESkTi624XMllJC0tjcjISFJTU72WstmRlEbCG2upFRHCpudu8sp7eF1eHvzvL7D+DdexGvXht+vNbALAvtUw51YIjoDf74SQ6j4Zqm8kju4AACAASURBVMdm3mLSTUNnwDV3wOyBZgffIe9Bmzt9PToRESmCu9/f2pvGrtIWsOYXEAA3vwj9J4MlALDA4LddgQhA0+sgphlkpZuZk8rAZoOUHeZ27avNdQ17ik8rakREKj0FI3aVOk1zsS4PwW9WwQPLTPCRn8UCne43t7+fab7oL3fnjsOFMybAimlmjjmCEdWMiIhUegpG7IICHU3PKsGXszvi2kLDLkU/1vZuUwB67Gc4fIm2/N+8bVIk6cfLf4zuctSL1GwCQWHmdo365lozIyIilZ6CEbvAAFc7+EpQRlM24dHQaoi5XdIy35SdsPSPplbjp4/K9p42mymqLc3PNiVf8aqDM02jXiMiIpWdghE7R5oGICevigcj4ErV/LKg6C90mw2++gPYcs393cvK9n6rX4E328HGtzx/rnMlzdWuYwpGRESqDAUjdo40DVSRupFLadAJGnSG3Ez4eHThTfR2fmEaqAXYV38f3AiZZ0v3Xif3wtrXzO01k+FCqmfPd/YYyT8zYk/TnE2G3OzSjUtERC4LCkbsAvN1ia2Ujc88ZbHAkHdNK/lD38Ky51yPZZ+HpRPN7R5PQs2mkJcN+9eU7r2WPQ+59mDnwhn49l3Pnl/UzEh4LQgIAmyQfqx04xIRkcuCghG7IKufzYwARF8BQ94xt797B36yL/Xd8BacSYTq9aDnOLjqZnN89/KiX6cke1fCri/MDMv1fzDHNr7l/uzIuROm7TtAreau4wEBUCPO3FaqRkSkUlMwYmexWJwBid8EIwBXJ0Cv8eb250+YgGOdvTNr379CSAQ0yxeMFFWAenKvaTuferjg8dxs+Mo+w9LlNyYYqXW1fXbkHffG50jRRDWC4GoFH9OKGhGRKkHBSD6OVE2VWd7rrhv/CFfcCNkZMPcOc92oG7Qeah5v0hOsIZB22JUycbDZ4OP7YNUkmN4Dti10Pfb9DHN+eIwJRAKscP3T5jF3Z0eOF7GSxqG6ZkZERKoCBSP5OGZGsvxpZgRMkDB0BkQ2tB+wQMIrpq4EzM7ATXuZ2xenavasgOSfze0LZ0wx7KLH4PQBWPWyOd77eQiLMrdbDbbPjqS6NztSVPGqg1bUiIhUCQpG8gkOrEJdWD1VLQaGzYHIRnDdeNM0LT9HqmbPRcHIWntKp8vD9nSPBbZ+AG91NgFH3Wugg2sXZ49mR2w2OGbfXbjIYERpGhGRqkDBSD5+m6ZxqN8Bxv4MvZ8r/JijiDX/Et/EbyBxg1nV0vMp6PM8jP7CzLA4Vs8kvGoCkPzyz45883bh98rJgq3zTNrn4HpzrI5mRkREqqpAXw/gcuLoNeJ3aRp3xFxpVt+c2md2/o0f6JoVaXe3KzBo0gMeWWeKYGs0gMbdC7+WY3bk0wdMKmfzLLNSpvbVEBoFW+e6ZjuCI0zxa1z7wq/jnBlRMCIiUpkpGMnHuXNvjoKRIjW72SwB3rPc7BOze6nZvK7HUwXPC4syuweXpNVg2PK+aax2Nslc9q92PV6tDlz7W9Mp1lFvcrH8m+Xl5Znlvt52fBf870Xo9jg07ub99xMR8QMKRvIJcqRp/KEdfGlcZQ9Gdi+HzHRzrOXtZtbEUwFWGPUZnD8DJ341X/IndkHqEbjiemhzFwSFlvwaEbEmGMrLMTv7Vo/1fByeyDgFHw4zxbkZp+D+L737fiIifkLBSD5K01xCk55mt9+0I/DLJ+ZYz7Fle82wKLO7cHE7DJfEGggRdeHsUTMmbwYjebnw6YMmEAGzeWBakqvxWmWTl2vSYU16QXRTX49GRPycCljzUZrmEoLCzJeXQ7ObIa6N78YDFVfEuvIl2Ps/CAwztTPYYMdi776nN30zDRb/zlxERHxMwUg+StO4wbGqBqDXON+Nw6EigpFti1xdaW97Czo/6DpeGWVfgA3/MLcTy7ABoohIOVEwko8jTeOXfUbcFX8rhEVDi4FFr5SpaN7uNZKyAxY9am53/x1ccwe0vM3cd6RqKpst77s2F8zLgQPrfDseEfF7CkbycaRpspSmKV6NOJiwF4a97+uRGN6cGcnLhf+Mguxz0PR66PMXczyyATToQqVM1eRmw/o3ze1qdcz13pW+G48U7/AmmDvM7P0kUsUpGMknUGka9wQEVMwyWnd4Mxg5sNas9AmNhDtmmYJZh1a3m+vKlqr56T+QmmgCkVsmmWMKRi5Py543y+fX/N3XIxHxusvkG+XyEKw0TeXjDEa8kKb56T/mutUQ0y4/v7Kmamw22PUl7PkfZGWUbZzuyst11b50f9zU/1iscHIPnD5YMWMQ95xJNN2NAXYugZxM345HxMu0tDcfpWkqofwzIzaba3O/ssrKgO32FEyb4YUfd6RqDn9nUjVdH3b/tW02WP68q4g0IMgsbW56PdRrD5lppm9KegpknIAm10GbO8v+mbZ/ZgKP0CjTTC6kOjToDIe+gX1fQ8fRZX8PKR8/f+K6nZkKe7+Gq2/x3XhEvEzBSD6ONE22v+5NUxlVt/f5yM2EcyfgzEHY+YXZTdhiMctwazY1vTRqx0ODTu4FLL9+CVlnIaoRNOxa9DmtbjfByLZF7gcjNhss/5MrEKkeZzrIHlzv2ofnYls/NI3gIuq49x7Fva+jff+1vzWBCMCVvU0wslfBSKlknIIvfg/tRhRcaVZWP39srqvXM310ti1UMCJVmoKRfBxpmhylaSqPwBCoVtvMJLzVCS6cKfh40o8F719xIwycYu8VUgJHiuaaYcXXx7S8DZb+0f0GaDYbrPgLbLAXkPafbJYJn9oH+9eYy/FdEFYTImqbuo49K+DUXvPl1O2xkl/f4cRu2LUEgsLNzFGNenBiDxz72bXXj8OVvc3+QPtWmTTOxZsaSsk2zYBtC8yf02PfedYELyfT/P29WPIvkLIdrMEw8HWYN9z8eRZ3vkgVoGAkH2fTMwUjlUvNJiYYuXDGfNledTNc3R+Cq8Gp/ebL/vR+OLDepCOmdYMbnjH7y1iDCr/euRPmywWgzbDi39eTVI3NBv97AdZPNff7T4YuD5nbMVeaS6cxhZ/3/XvmN+8tc+HaR4uf1cnJgp2fw6ZZpvC2OJ3uh/Bo1/167U2B7oUzcHQrNOhY/HMrms0Gh7+H2i0gtIb33+/cScAG1Wq5/5xfl5rrzDT46hkY9m/3nve/v8LGt+CuD6FZn4KP/WwPhK/qay6O2bO9K+HqBPfHJlKJqIA1H2fNiNI0lcstr0DPcTDyU3h6H9w52wQRLQaYQs2BU+DehfDoRmh6HeRcMDMU794ARzYXfr1tC03/jbh2Zifhkri7qmbVJFj3urmd8HdXIHIprYeCNQRSthWe5XH45m14vSV8cr8JRCwBcGUfuHqACTYi6ppj1eNMr5T8rIHmZwKX36qada/DjJvh3eu9288lK8N02J3SAv7Z1QSj7kg/bpbfgikE3r7IFZyUxGaDLR+Yv4eLnyjYdC4vD37+1NxuY5+Va1lJV26JbxzfZZbwVzIKRvIJtCpNUyk16Ag3/RmuuqnkaeyYK2HUYrj9bdO47dgvMGsAJH5b8Lyf5pvrogpXL5Z/Vc2BYmo+vvsXrH7F3L7lFej6m6LPK0pYTRNUgdlL5mIH1sNXfzAzQxF14fo/wFM/w70L4O4P4TerYPwueO44jN1WdN3Jlb3N9cXByNlk+OAOmDcCvpkOyT+bL8tLSdkBnz0OKTvd/5wXO7zJBAhgZrb+PdCMp7ztXALTuprls7lZpmDYETReyp7lgA3i2kI3e2O8L37v2kSyOCnbId3+WdIOm1kSh8SN5lhIDbiqnznWarC53rXEdM8VKc7WefDPLrDAzV92LiMKRvIJVpqm6rNYoN3d8Pgm8yWcc97sxJuywzx+cq9JDVgCzKzEpUQ2gPhBgA0+GFr4C33H57Bkgrl9wx/h2kc8H3P7keb6548LLvHMyzM1KwDtRsLYX+DGP5oxXcwaWHw9iCMYOfyd67f0C6kmENmzHHZ9YVIQb/eEv18BH48pefZg2fOmy+vs/nBsm2efFeBCGnz6ANhyzRdyZEOzCujft5oVRpfy61Kz507GqeLPOXcCPhwOH91tltHWaODa9PH799zrW/PrV+b6qn5ww0SIbASph8wsWEn2/M9cRzYy19+9C4e+N7cdKZr4W127VjfobApZM9Muv9kruXxkn4f/vWhub1sIu77y7Xg8pGAkH6Vp/Ei1GBj+gfmP/sIZeH8InDnkWsVwxY3u7wI85F8mt59z3nzB7frSHE/8xuz0i82sVLn+6dKN9YobzZfR+dOu1wbzxZW0FYKrw00vFF3/4o6aTUxBr6M1fPYFMxty7GdTRHvjcybtE1TNjGHbAlPvUJSzyWZDQYCMkzB7oCnI9MSS8WZ35MhGMORduO9z0/b/xC4TkBQXCNlsZobjw2HwwxwTVBRn+Z9MMBEQZFJ8j38Hff4MjbqZ9MmlGo3lZMEee2DQ/BZTnzTQvlrpm2nFp9TA9fPp9ii0HQHYTPCUme5KxeRfyh0Q4EoHbleqRorx3btm5ZXDlxMqrodROVAwko/SNH4muBqM+A/Uutr8I35/sFlGC+6laByCwmD4XDNDkpsF8++BdVNNYJJzwRTT9n+t9D1QAqzQ9i5z2zG+rAxY8YK5fd3vzeqbsnDMjuxebmYlDq4zqYJ7PoXrJ5i0zzMHzeoOgB/eN1/IF/tpPtjyTL1NvfZw/hT8e5BJ8bjjx/nmNSxWGPoehEWZZdn3fW5qXo7vMAHOzi8gN8f1vOzzZtyO1A64+sRcLCcTdvzX3B4x36T4gquZP58+f7J/vjmm+Lk4iRvM0u9qtc3nBFM43Wqw+fyLnzCrky6WlQEHN5rbV/aGfv8H4bXM5/pwmAmMI+oW3B0bXKmanUrVSBHOn3Et3e8/2cwmnkmsVN17FYzkozSNHwqPNl+0NerDyd2mT0lQuKtOw12BwXDHbLjmTjPDsOLP5oulQWcYOqNgK/nSaGdP1exZYWYfNr5lAqjIRtD1t2V7bXAFI5tmws7/mmWld30IcW1c51iDoP0oExRknDCrd/Kz2UzOGszKoHsXQb0OroDk4IaS6ylO7TM1F2BWOzXK198l5kq4778QEWu+uD8aAVNbm3qLQ9/DrAT45VMICISbXzTBzLGfzWtebN9q00gsoq6ZdcqvcXczC5SXA6v+VvxYHYWqV/UruPT7lr9BSKSZsSpqFuPgBtMTp0YDqNXc/P1LsNcTOfrMXHNH4ZRa/U7m72jWWdfMilQOF1Jh/1rvBpHr3zD/39RuYVbMOf5ObXizcO1WTpZJ4xzb7r3xlIKCkXxcS3uVpvErkQ3MapuwmuZ+i4EQEuH561gDYfA70GGUuR/TDO6eD8HhZR9jrWam+Zot12x05yiyvPkvrtqCsmjSy3yBYwMsZlaiaa/C51kDocN95vamWQUfO7rFBAqBoeY3+bAoGLUI6nc06Z1ZCTCpPvxfHExtY1Yz/fNaeC0eXq4Pb7Y3X7aNe0Cv3xf9M3joa7MiKDzGLHddOxlm3GTeOywaRn0GPZ6EJj3Nc4qaHdn+mbmOH1R0D5nez5nrn+a7aonyc7TyB2jer+Bj1eu6lnh/P6Pwcx01H1fe6Jopaz0UmuVrmHZNEd12vb2qJu0ovHcTfP1y+b+2v/vPKFOAPbk5fP6kKZi3leN3TFqSKTAHM7MXYDW/TDVPMEH1F78372ez2Qu2r4WPR8P0bmb29uICfh9RMJKPI02jmRE/VPtq80XW7h5TBFpaAVYY9CaM+cp8cV68p01ZtBthrr/5J2RnmFmXVkPK57VDa7hmRwa85lolVJQOo0yB74G1cPxX1/Ef7bMiLQaY3iVgru9daP5jDAwzx7IzzAyUI3g5exSy7DMmMc1MnUhxxbaR9aHvSzBup1nC7ZjZqB0PD610BSHxg8z1jotmb3KzzcwPFP8Z63dwFSV//X+FHz+5x/StCQgyQcXFOo0xgd3B9YV/+3TMauTvLWKxmHqTiFho3NOszilK/lU15b2y6MunTeH26lcK/8w8YbPBqlfgy2e02zCYGqx9q8ztzFTYPBtm9oV/dDDtBfasuPTqq0tZ86qpV2vQxaSEHRJeMf/mDq4zRdVzbjUF26f22v99Wkzd1My+ZlXhnhXlGyR5yGKz+fDd3ZSWlkZkZCSpqanUqOG95kf/2XSIpz/5iRuvrs2sMV289j4ipXIhFSZfbf7jAXhgBTTsXH6vn3kWzh4zMxCXMm+EWWVz7aNm99+cTHjtajMDcs+n0Oymws+x2UzQce646dFx/pSptwmpYf5zDI0ysymedoE9d8I8P38B79lkeK0FYIOx200QA2YlywdDTJ3G+F+Lf6+UHaY5HjYT5NTP1wxuwz9g2XMmEBpVzCzF/HtNI7xOD7gKW1OPmH4wlgCYsLdg8zkw0+fWoOJri2w2M5uUtNX8fEd+4n4dUm528QXOvy419SoOYTXhkfWun5knti2Cj+0zZ44VaT3HQWxLz1/rcpSZ7qovcse/b4X9q00Be6shJmDfvhiyz7nOsVhN3VHDLubPKC/XzGjk5djrh3qav3+BwYVf/+ReeKuzmTEdvQSa9Cj4+LrXTdDjYA0xhdM9x5mVaeunwo8fQZ69L0nv5+C6CZ78RC7J3e9vdWDNJ1hpGrmchUaa3+Z/+sj8x1aegQiY/Woce9ZcSqf7TTCyda6ZGt693AQi1eMK12E4WCyu97hUO35PFNUxtXpdk9Y69I35Td+xpLpAiqaEoKdOvGk69tN8mHe3CbDqXmMec9SLNC9hr5jOD5pg5Kf5cNNfzMyTI0VTr0PhQASK/rLJz2IxacB3rze/xX7/3qWb52VlwOq/mWn8VkPgtn8WrF/KyjCrlwC6PmJWgCVthYUPm5lCTwLDrAwTpAFEX+naxuDnj81v7H1fMrU/ldWeFTB3mPm7P2Dypc9P/MYEIgFB0Gs8RDU0e0z1n2xmt/atMrOLZxLhyCZzKU5QuPn73OhawGJ+MbmQCkd/sC+B71s4EAG49jFTS5X8s5lZu+kFqNnYPBZaA257yyxL3/iWacRXVIqwgigYyUdpGrns9XvZTOO3v8e347iyt9lE8EyiKYZzTO23GXb57G/T8lZ7MLLYBCO5OWYVDpSchnLo+5J9n5htMKu/Keite40pQgVo3rf45za9zhSonvjVBCRdHspXL9K79J+pTgtToPvl0+aLv+l1xXcJ3rcKPn/KpJTABLF52TD4XVdAsnayq89K7+fNjNI715kvyfVvQK9x7o9t/VTTZyWyITyyzhSEr51iAsBdS0zKYsi/KueGf3m5sPRZ88X/vf0zFDX7l9/qV811uxEmEHEIiTD/ThxbTZxJNM0Lj9mXwAdYTSG2xWr+/hxYZwrG931tLhezBLhWgV0sMNikjM+fMv9eixJZ38xu9n6+fOrbSknBSD7am0Yue9ViXN0+fSkgADqOse+386b54gF734zLRPwg0xTu4AYzJX18p/lPPSzaVVtSkog6MGaJWblzcL1J77S+w3wh1bq65Nkdi8XMjnz5tJnB6HS/64vk4r1oPNX5IZPr37vSdNp8YEXBWZWMU6bx3NYPzP3q9Uydz9rJ5rdkS4CZYTm5x/zZAST8zXxJhjSD/q/CZ4+Zepmm17u3X9HpA2Y5O5jlysHhJmge9m+zceNnj5vAcN5dpiar1/jiN6C8HP003/z9cfj8KbO9RHEziYc3mfogi/XSAV1UI2hXTKAAJj2XssMEiEe3mi7ToZFmZiM0Euq2cc3aFSUkwr2CfB8GIqBgpAClaUQ80P4es/riuH3FSb0O5jf3y0VUI5OLP7rFzIg4fvNsMcD9BnFhUXDPAljwoJn9+dHe5+XiVTRFaXuX6QVzfKeZBj9/2tTH1Hfjy70kAQFw2zSzGiLpR5OG6fa4WeGz/TMT9ORmARbo/IBp5hZaA+q2Nqsofv7YBCRpR81MyVX9zAoyh3YjTUpi20L49H648VnTNyamWfEBxNJnzZLlpteZ7rH51brK9In56hmzy/HX/2fGffv04jdAzMs1f2Znk0wgV9yfV1oS7F5m0hjhNU2gGR5tlryXV7CTk+laZXT9M6bu48xBU4sx4LWin+OYFWl7t2kqWBYWi6m5qSp1N8VQMJKP0jQiHoioY2Yfti0w99tdRrMiDvGDTDCyfZFrma5jiay7gkLhzn+b2opNM82xkupFHEIjoe1w8xxHM7am15W+U25+NeJg4FRTLLp2ikmp5OVrAlf3GtNoL3+vlvhBcMdM087fsf9SYJiZCclfkGmxmOZ2hzeZGQ/HPifBEea38KbXmc/lmBnau9KsULJYIeHVoos7A4NNIW+9dmap6c7/wvSfTKfZlreZ17VYTC+OHz80RcKOHjH7VsOdswrvO5X8i2lUeK6ILQLqdTB1PkXV5nhq0yyTfqoeBz2fgsbdYM5tZsar1ZDCtRpHfoDdS03A50may89Vonky71OaRsRDne4319Zg9/byqWjx9tqQfasg/ZgJEBy7FHsiwAoDppjfhK+bYJqjuaPzg+Y6196ttiz1IhdrdburnXxeDtRpZYoRH/0GHl5bMBBxaHkb3DHD3lMGuG580b+5h9WE+xZDl4fNktHAMLMSKnGDmYl5sz3MvMUsVf3yGfOcLr8xhb8l6TDK1DBUrwepibD2NVOj8kZbk8qZ2hr+O9YEIqFRZvXHri9MV+P8TcMOb4LZA0wgEn2F6ZMT29o0hgsIMoWdc+8suCNySXJzYdUqmDfPXOfau+dmnnV1Mb3+D2b11xU3uHrtLH68cMt1x/nX3Fm5C3YrmJb25rP54GmGTt9Ao+hw1jxdzIoAEXGx2cxv/tXjoEX/S5/vC9O6mZ1ywXx5D55ese8/M8F8iQM8+WPZp+3zy8kyX9axrU06xF0H1pkVFp0fdG+mJjfHFFMe2WTSN3u/xjTIswuvBb/bbNJa7shMN3Uv2xfB7hWu5epgimm7Pw7t7zWbN84bYR6/4ga4ax4c2WxqT7LSTaA08uOC73tsu9mk8fxpE3iO+LjkxoALFsCTT8Lhw65jDRrAG29A9G5Y9bJZHfTYt66f1YVU07Dv7FHTm6hOC1PPcXSLWUWEBR77Dmo3d+/nUYW5+/2tYCSfnw6f4da31lMvMpQNE8tYZCYil4evJ5nf5sF0xK3o1Ry/fAqf3G9W1zz+fcW+t7ekHYWf/mPqJ47vMh17r7mjdK+Vdc7UqBzcYGp8Wg8tGCAdWGeW1GafM0Wxx3eZPZ+aXm9WOBVVnHlks+nxkZVuGu4Nf9+85vFfYcsc+OljM8uRfT08/Y/Czb4cqaa7a8JVOSa9dfHM366vYF4xe1j1+n3xK1z8jFeDkWnTpvH3v/+dpKQkWrVqxdSpU+nVq4jW0XaZmZm8+OKLfPDBByQnJ9OgQQOeffZZ7r///nL9MGW1IymNhDfWUisihE3PXWLZlohUDo4GZmFR8PtdhWsPvM1mM42l4tpAbKuKfW9vs9nMJoXeXomR+C3MvQMy08z95gmmA29JMx7715rn5Fww7faz0iFxo+vxPBu8kQ5pJXwF1rDApO7wyJqiC2KXPWcKbWNbuTaHrNe+fGpVqgivNT2bP38+Tz31FNOmTaNHjx688847JCQksH37dho1Knp50rBhwzh27BgzZsygWbNmpKSkkJOTU+S5vqSaEZEqqE68aUkfHlPxgQiY37Lb3V3x71sRLJaKWRLaqKvpdrvoUdP4q//kS6eXmvaCYXPM0uw9y+3jDTCrhzrcCyuWQto/Sn6NNBvUGFz8ypy+L5mLlJnHwciUKVN44IEHePBBU5g1depUli5dyvTp05k0aVKh87/66itWr17Nvn37iI420WKTJk3KNmovCdJqGpGqqag9ZKRyqd/R1G14onk/sxJq4z+hWW+zbLlGPfPYljTgEsEIQECcx0MVz3m0miYrK4vNmzfTt2/BzoN9+/Zlw4YNRT5n8eLFdOrUiVdffZX69evTvHlzxo8fz/nz54s8H0xaJy0trcClIjhmRnLUZ0REpGqIHwj3f2lWQTkCEYA4N4OMevUufY6UmUczIydOnCA3N5fY2NgCx2NjY0lOLnoXyX379rFu3TpCQ0NZuHAhJ06c4NFHH+XUqVPMnDmzyOdMmjSJF154wZOhlYuIUPPjyMrNI/V8NpFh5dAPQERELj+9eplVM0eOFL1brcViHi+hHlLKT6n6jFguampjs9kKHXPIy8vDYrEwd+5cunTpQv/+/ZkyZQqzZ88udnZk4sSJpKamOi+HDh0qzTA9ViM0iHqRpiBqZ1LFzMaIiIgPWK1m+S4UbtTmuD91qjlPvM6jYKRWrVpYrdZCsyApKSmFZksc4uLiqF+/PpGRkc5j8fHx2Gw2Dudf151PSEgINWrUKHCpKPFx5r12KBgREanahgyBTz6B+vULHm/QwBwfMsQ34/JDHgUjwcHBdOzYkeXLlxc4vnz5crp3L7ojYY8ePTh69Cjp6enOY7/++isBAQE0aNCgFEP2Llcw4mbnPhERqbyGDIEDB+Drr+HDD831/v0KRCqYx2macePG8d577zFz5kx27NjB2LFjSUxM5JFHHgFMimXUqFHO80eMGEFMTAxjxoxh+/btrFmzhgkTJnD//fcTFhZWfp+knDiDkWTNjIiI+AWrFW64Ae6+21wrNVPhPF7aO3z4cE6ePMmLL75IUlISrVu3ZsmSJTRu3BiApKQkEhMTnedHRESwfPlyfve739GpUydiYmIYNmwYL710ea7Njo8zW0LvSj5LTm4egVZt3yMiIuJNagd/kdw8G63/vJTz2bmsGHcdzepU9+r7iYiIVFXufn/r1/6LWAMsXF3XBCDbVTciIiLidR6nafxBfFwNth46w46kNG5tq4Y3IiIVJTU1lYyMDF8Po8KEh4cXWG3qrxSMFKGlvW5Ey3tFRCpOamoqb731FtnZ2b4eSoUJCgri8ccf9/uARMFIEdRrRESk4mVkx3PeHAAAIABJREFUZJCdnc2QIUOoXbu2r4fjdcePH2fBggVkZGQoGPH1AC5HLezByLG0TE6dyyK6WrCPRyQi4j9q165NnLt7x0iVoALWIkSEBNIo2myLrdkRERER71IwUox41Y2IiIhUCAUjxXDUjWxXMCIiIuJVCkaKoT1qREREKoaCkWK0tAcje1LOkpWT5+PRiIgIwLRp02jatCmhoaF07NiRtWvXlnh+ZmYmzz77LI0bNyYkJIQrr7ySmTNnFjjn008/pWXLloSEhNCyZUsWLlxY6HWOHDnCPffcQ0xMDOHh4bRr147NmzcXOGfHjh3ceuutREZGUr16da699toC26NI8RSMFKNBzTCqhwSSnWtj7/H0Ao8dPp1R6JiIiHjX/Pnzeeqpp3j22WfZsmULvXr1IiEhocQv/GHDhvG///2PGTNmsGvXLubNm0eLFi2cj2/cuJHhw4dz77338uOPP3LvvfcybNgwvv32W+c5p0+fpkePHgQFBfHll1+yfft2XnvtNaKiopzn7N27l549e9KiRQtWrVrFjz/+yPPPP09oaKh3fhhVjPamKcGdb2/g+wOnmTKsLUM6NADg4MlzDHxzHbk2Gxuf6UNkeFCFjUdEpCpLSkrinXfe4eGHHy5yaW/Xrl3p0KED06dPdx6Lj4/n9ttvZ9KkSYXO/+qrr7jrrrvYt28f0dHRRb7n8OHDSUtL48svv3Qeu+WWW6hZsybz5s0D4JlnnmH9+vUlzsLcddddBAUF8f7775fb560KtDdNObi4+Vl2bh5PfrSVs5k5ZGTl8svRVF8OT0TEb2RlZbF582b69u1b4Hjfvn3ZsGFDkc9ZvHgxnTp14tVXX6V+/fo0b96c8ePHc/78eec5GzduLPSa/fr1K/Cajte58847qVOnDu3bt+df//qX8/G8vDy++OILmjdvTr9+/ahTpw5du3Zl0aJF5fHR/YKCkRJcXMQ6dcWvbD10xvm4lv2KiFSMEydOkJubS2xsbIHjsbGxJCcnF/mcffv2sW7dOn755RcWLlzI1KlT+eSTT3jsscec5yQnJ1/yNfft28f06dO56qqrWLp0KY888ghPPPEEc+bMASAlJYX09HT+9re/ccstt7Bs2TIGDx7MkCFDWL16dXn9CKo0dWAtQf6ZkY17TzJt1V4A2jWMYuuhM1r2KyJSwSwWS4H7Nput0DGHvLw8LBYLc+fOdbZbnzJlCnfccQf//Oc/CQsLc+s18/Ly6NSpEy+//DIA7du3Z9u2bUyfPp1Ro0aRl2cWOdx2222MHTsWgHbt2rFhwwbefvttrr/++nL45FWbZkZKcHVsdQIscPJcFo9/+AM2Gwzv1JBHb7gS0LJfEZGKUqtWLaxWa6FZkJSUlEIzGw5xcXHUr1+/wL4v8fHx2Gw2Dh8+DEDdunUv+ZpxcXG0bNmywDnx8fHOwtlatWoRGBhY4jlSMgUjJQgLttKkVjXABCRX1KrGn29t6Zwx0bJfEZGKERwcTMeOHVm+fHmB48uXL6d79+5FPqdHjx4cPXqU9HTX6sdff/2VgIAAGjQwixK6detW6DWXLVtW4DV79OjBrl27Cpzz66+/0rhxY+fYOnfuXOI5UjIFI5fgCDyCrBbevLs94cGBZtlvqFn2uydFS3xFRCrCuHHjeO+995g5cyY7duxg7NixJCYm8sgjjwAwceJERo0a5Tx/xIgRxMTEMGbMGLZv386aNWuYMGEC999/vzNF8+STT7Js2TJeeeUVdu7cySuvvMKKFSt46qmnnK8zduxYvvnmG15++WX27NnDhx9+yLvvvlug9mTChAnMnz+ff/3rX+zZs4e33nqLzz//nEcffbSCfjqVm4KRS+jfOo7gwAD+NKgVreubqT6LxUJ83YIrbURExLuGDx/O1KlTefHFF2nXrh1r1qxhyZIlztmHpKSkAmmRiIgIli9fzpkzZ+jUqRMjR45k0KBBvPnmm85zunfvzkcffcSsWbNo06YNs2fPZv78+XTt2tV5TufOnVm4cCHz5s2jdevW/PWvf2Xq1KmMHDnSec7gwYN5++23efXVV7nmmmt47733+PTTT+nZs2cF/GQqP/UZcUNObh6B1oJx258/+4V/bzzIgz2b8tzAlsU8U0RE3OUPfTfy84fPqz4j5ejiQATyrbRJ1syIiIhIWSgYKaX8PUgqweSSiIjIZUvBSCldXdcs+z11LouUs5m+Ho6IiEilpWCklEKDrFxROwJAzc9ERETKQMFIGVy8d42IiIh4TsFIGcTHVQdg+1EFIyIiIqWlvWnKQDMjIiLl7/jx474eQoXwl8/pDgUjZdDSHozsP3GOC9m5hAZZfTwiEZHKKzw8nKCgIBYsWODroVSYoKAgwsPDfT0Mn1MwUgZ1qocQXS2YU+ey2JV8lrYNo3w9JBGRSisyMpLHH3+cjIwMXw+lwoSHhxfYyM9fKRgpA4vFQnxcddbvOcmOpDQFIyIiZRQZGakvZz+kAtYyaqm6ERERkTJRMFJG+TuxioiIiOcUjJRR/hU1agsvIiLiOQUjZXRl7QiCrBbOZuZw+PR5Xw9HRESk0lEwUkbBgQE0q2Nvfqa6EREREY8pGCkHjk6sKmIVERHxnIKRctC6nlmG9v2BUz4eiYiISOWjYKQc3BQfC8DGvSdJOXvBx6MRERGpXBSMlINGMeG0bxRFng2++CnJ18MRERGpVBSMlJNb29YDYPGPR308EhERkcpFwUg5GdAmjgALbEk8Q+JJ/9lXQUREpKwUjJSTOtVD6X5lLQA+/0mzIyIiIu5SMFKObm1nUjWfbT3i45GIiIhUHqUKRqZNm0bTpk0JDQ2lY8eOrF271q3nrV+/nsDAQNq1a1eat73s9WtVl2BrAL8eS2dnsnqOiIiIuMPjYGT+/Pk89dRTPPvss2zZsoVevXqRkJBAYmJiic9LTU1l1KhR9OnTp9SDvdxFhgVxY4vaAHy2VakaERERd3gcjEyZMoUHHniABx98kPj4eKZOnUrDhg2ZPn16ic97+OGHGTFiBN26dSv1YCuDW9vWB2Dx1qPaOE9ERMQNHgUjWVlZbN68mb59+xY43rdvXzZs2FDs82bNmsXevXv585//XLpRViJ94utQLdjKkTPn+SHxtK+HIyIictnzKBg5ceIEubm5xMbGFjgeGxtLcnJykc/ZvXs3zzzzDHPnzv3/9u47PMoq7R/495leMum9J7RAQgkE2dAERGkqCAqyStHXVVxBsLfdFfjp4lqwraCwii+KwkYQURSlI0VqAiF0kpBOepskM5OZ8/sjMK9jAiQhySTw/VzXXJuc58w857mvyNx7KhQKRaPuYzKZUF5e7vDqKDRKOUZF+wOo6x0hIiKiq2tcdvAHkiQ5/C6EqFcGAFarFX/+85+xYMECdO3atdGfv2jRIixYsKA5TWsX7uoTiHWJ2dhwNAeuWiW0Kjm0Sjn0agVGx/jDVaN0dhOJiIjaDUk0YWKD2WyGTqdDQkIC7rnnHnv53LlzkZSUhJ07dzrULy0thYeHB+Ryub3MZrNBCAG5XI5ffvkFI0aMqHcfk8kEk8lk/728vBwhISEoKyuDq6trkx7QGSxWG+IXbUVhpbnetU4+emx8cgg0SnkD7yQiIrpxlJeXw83N7Zrf303qGVGpVOjXrx82b97skIxs3rwZ48ePr1ff1dUVycnJDmVLlizBtm3b8M033yAiIqLB+6jVaqjV6qY0rV1RymVYNj0OP6fkodpsrXtZrNh7vgjnC4z416ZTePWuaGc3k4iIqF1o8jDN008/jWnTpiEuLg7x8fFYtmwZMjIyMGvWLADASy+9hOzsbKxcuRIymQwxMTEO7/f19YVGo6lXfqPpG+qBvqEeDmXbT+Xjoc8PYsWedNze3Q8DO3s7qXVERETtR5OX9k6ZMgXvvfceFi5ciD59+mDXrl348ccfERYWBgDIzc295p4jN6vhUb6YeksoAODZhKMor7E4uUVERETO16Q5I87S2DGnjsBoqsWY939FRnEVJvUNxjuTezu7SURERK2isd/fPJumjenVCiye3BuSBKw9koVNxxteEk1ERHSzYDLiBHHhnnhsaCcAwMvfJqOgwnSNdxAREd24mIw4yVO3d0GUvwHFRjNe3XDc2c0hIiJyGiYjTqJWyPH2fb2hkEn4MTkPPybnOrtJRERETsFkxIligtzw+LC64Zq/rz+OYmP9TdKIiIhudExGnGz2iM7o6ueCIqMZ8zekOFwTQmDD0Rw8vSYJJ3I6zvk8RERETcFkxMnUCjneurc3ZBKw4WgOfkmpW12TUVSFGSsO4smvE7EuMRsTPtqDz3anoQOsxCYiImoSJiPtQO8Qdzx6aXXNK+uP4/0tZ3H7uzux60wBVAoZYkPdYbbasPCHE5i54iBX3xAR0Q2FyUg7MW9kF3Ty0aOgwoR3t5yBqdaGgZ288PO8oVj3+EAsHB8NtUKGnWcKMOb9Xfj1bIGzm0xERNQimIy0ExqlHG/d1xtqhQyeehUWT+6NVY8MQIS3HpIkYXp8ODbMHoxufgYUVprx6MrD7CEhIqIbAreDb2fyK2rgolZAp2r4DMMaixVTPtmHo1lleHRoJF4e272NW0hERNQ43A6+g/I1aK6YiAB1PSjzRnYFAHyx7wKKKhvXO3Iipxz3L9uHbacutkg7iYiIWgqTkQ5oWDcf9Ap2Q7XFiuW/pl2zflm1BY99eQi/pRbjH9+loNZqa4NWEhERNQ6TkQ5IkiQ8OaILAGDlvvSrbpYmhMDz3xxFZnE1ACCrpBo/8XA+IiJqR5iMdFC3dfdFdKArqsxWfLo79Yr1PtuTjp9TLkIll2FsT38AwLJdqdyvhIiI2g0mIx2UJEl48ra63pH/3XsBpVX1e0cSM0qw6MeTAIBXxnXHaxN6QqOUITm7DPtSi9q0vURERFfCZKQDu6OHH7oHuKLSVIvPdjvOHSmtMmP2V4motQmM6xmA6fFh8NSrcF+/EAB1vSNERETtwZWXbVC7Vzd3pDMeX3UEK/akI9RLj9zSamSVVONIRgmyS6sR5qXDokk9IUkSAOCRIRFYtf8CdpwuwKm8ckT539hLpYmIqP1jMtLBjYr2Rzc/A05frMCzCUcdrqkVMnz0575w1SjtZWFeeoyJCcDG5Fws25WKxZP7tHWTiYiIHDAZ6eBkMgkLxkdjwfcn4K5VIthDi2APHYI9tBgQ6YlgD1299zw6NBIbk3OxISkHz43qhgA3LfLKarBiTxrWHsnGnb0C8OpdPey9KURERK2JO7DepKZ8sg/704oxMTYIcpmE9UnZsFj/70/hqZFdMXdkFye2kIiIOjruwEpX9ditkQCAdYnZSDicBYtV4JZwT/xlSAQA4N0tZ5BwKNOZTSQiopsEh2luUsO6+iI21B2JGaW4o4cfHru1E/qFeQAAFHIZlu44j5fWJcPPVYOhXX2c3FoiIrqRcZjmJlZttqLKXAsvF7VDuc0m8NR/k/BdUg5c1Ar897F4GDQKHLpQjIPpJUjJLkOfEHc8NzoKLmrms0RE1LDGfn8zGaEGmWqtmPHZAfyWWgy5TILVVv/PJNxLh/fvj0XvEHcntJCIiNo7zhmh66JWyPHJtDh08zPAahNQyCT0CXHHX4ZEYNHEngh00yC9qAqTlu7FxzvPw9ZAstJa9qcWoazK0mb3IyKi1sWeEbqqihoLzuZXoru/K7Qqub28rMqCl79NxsbkXADAwE5eeG5UN/QJcW/2kuDEjBL847sU/HVYJ4zpGdBgne+SsjF3dRK6B7hi/RMDoVbIG6xHRETOx2EaanVCCPz3UCbmbziBaosVABAd6IoHBoRhfJ9A6Jswn6So0oSxH/yKi+UmeLuosPO54fXeX2u1YeTinUgvqgIA/M/gCPz9zh4t90BERNSiOExDrU6SJEzpH4qNTw7GxL5BUClkSMkpx8vfJmPAP7filW+TcSSj5JonBNdNmD2Ki+UmAEBhpRkr9qTVq/ddUg7Si6qgu9RD8+nuNOw6U9DyD0ZERG2KPSPUYkqMZqw9koVV+zOQVmi0l0d46zExNggTYoMQ4ll/R9h/bzuLt385A41ShkcGR+Lf28/BoFHg1+eHw12nAuDYK/LimCjklFZj5b4L8DGosWnukHorgoiIyPnYM0JtzkOvwiNDIrH16Vux6pEBmBgbBK1SjrRCI97ZfAZD3tyOWV8cxvHsMvt79p0vwuLNZwAAC8fH4OnbuyLK34CKmlos3XneXm/9pV4RT70K0/4UhpfHdkcXXxcUVJjwwtrka/a+EBFR+8VkhFqcTCZhUGdvLJ7SB4f+NhLv3Ncbgzp7AQA2peThzg9346EVB7Dt1EU8uToRNgFM6huMyXEhkMkkPDeqGwDg8z3pyCurQa3Vhg+3nQVQd66OXq2ARinH+/fHQiWXYcvJi/jqQIbTnpeIiK4Ph2mozZy9WIElO87ju6Rs/H4lcBdfF3w3exB0qroJq0II3PfxPhy6UII/DwhF31APPJtwFJ56FXa/MNxeDwD+82sqXtt4EhqlDJ8/dAv+FOnVYu0VQuDdzWdgstrwwqgoyGQ8OJCIqCk4TEPtThc/A96d0gfbnhmG+/uHQCmX4KJWYMkDfR0SDEmS8PzoKADAmoOZePvn0wCAx4ZGOtQDgIcHRWBYNx/UWGyY9ul+rD2c1WLt/XR3Gj7Ydg6f7ExFwmGe00NE1FrYM0JOU1hpghCAj6HhyaczVxzAjtN1q2Ua6hW5rMZixTMJR7HxWN2eJ3NGdMZTI7tetScjMaMEL397HD4GNT64v499ouxlhy8UY8onv6H2UheOm1aJrc/cCm9OlCUiajT2jFC75+2ivmIiAgDP3tHN/nNDvSKXaZRyfHh/LJ4Y3gkA8OG2c3hydSJqLu198ntWm8CHW8/i3o/34WRuOXadKcDkT/Yhr6zGXqfYaMbsrxJRaxMY1ysAPQJcUVZtwesbTzb3UZulylyLqct+w7zViZygS0Q3NCYj1G7FBLnhuVHdcGevAEyLD7tq3bqJr1F4695eUMol/HAsF0Pe3I7nvzmKTcfzUGmqRVZJFe5ftg/vbD4Dq01gdLQ//FzVOHOxEvd+vBdphUbYbALz1iQht6wGkT56/GtSLyya2BOSBHybmI3dZwvb6OmBL/ZdwL7UIqxPysG6I9ltdl8iorbGYRq64ew7X4TZXx1BkdFsL1PJZVDIJVSZrdCr5Fg4PgYT+wYhq6Qa0z7dj/SiKni7qDCyux9WH8yERinDd08MRjd/AwBg/oYUfL43HeFeOmyaNxQa5f9tQ2801aLaYm3RIRyjqRZD3tyO4kvP4O2iwtZnhsFNq2yxexARtTYO09BNK76TF/a+NAJf/s8APDwoAuFeOpitNlSZrYgNdcePc4dgUr9gSJKEEE8dEmYNRI8AVxRWmrH6YN1E1dcm9LQnIgDwzB1d4e9adzjgR9vPwWYT2HOuEE+tSUK/1zYjftFWvLv5DMy1thZ5hpX7LqDYaEa4lw6RPnoUVprx7qX9WIiIbjTsGaGbQmpBJS6WmxAX7gGlvH4OXl5jwSP/ewgH0opxf/8QvDGpV706m47nYdaXh6GUS/A1aJBdWl2vTjc/A968txd6h7g3u62VploM/tc2lFZZsHhyb/gaNHjw0/2QScAPc4agRyD/GyCijoEH5RE1kcVqw6ncCsQEuTZ48rAQAn9ZeRhbTl4EABg0CtzdOxD39gtGVkk15m9IQZHRDJlUd4jfE8M711ul0xgfbT+Ht34+jUhvPX55aigUchmeWHUEG5NzERfmgYRZ8c0+GZmIqC0xGSFqBcVGMz7ZdR7RgW64o4efw9yRYqMZC79PwfqkHHtZpI8efUM9EBvqjt7B7gj31sPlKqcZV9RYMPhf21FWbcF7U/pgQmwQACCntBq3vbMT1RYr3rmvNyb1C269hyQiaiFMRoicZNupi3jjp1M4c7GyweteehVCvXQI89Shf4Qn7uwZCDdd3cTUD7eexTubz6CTjx6/PHUr5L/bK2XpjvP416ZT8HZR4cUx3WGzCViFgNUmEOyhxZAuPg71myopsxTJ2WWYGBsE/VUSJiKixmIyQuRkJUYzEjNLkJhRiiMZJTiZW2FfHfN7KrkMI3v44s5egXhx7TGU19Tig6mxuLt3oEM9c60No9/fhdQCY73PAIAQTy2m/SkMk+NCmjQ8VGOxYvHmM1j+ayqEAPxc1XhxTBQm9Am65nCQqdaKlJxyAECkt75Zw1LUsK/2Z2DB9ykYHeOPOSM6o7Ov4dpvImpnWjUZWbJkCd566y3k5uYiOjoa7733HoYMGdJg3XXr1mHp0qVISkqCyWRCdHQ05s+fj1GjRrX4wxC1d+U1FmQUVSGjuArn8iux8VguTl+scKjTxdcFm+YNbbCX41hWKd7fchYWm4BCJkEmSZAk4EBaMcqqLQAAtUKGCX2CMDzKBz2D3RHoprliUnE0sxTPJBzFufy6XhxPvcqeMPUNdcerd0Wjd4g7rDaBsmoLio1mZJZU4VB6MQ6mlSApq9RhBZGHTolwbz06+bhgeDdfDI/yueJmdXRlJUYzhr65HRWmWgCAJAF39grEkyM6o4sfkxLqOFotGVmzZg2mTZuGJUuWYNCgQfjkk0/wn//8BydOnEBoaGi9+vPmzUNgYCCGDx8Od3d3rFixAm+//Tb279+P2NjYFn0Yoo5GCIETueX49kg21ifloMhowvJpcRjZw69Jn1NttmLD0Wx8vvcCTuaWO1zz0qvQM9gNnXxcoFHKoFbIoVbIkFdeg5X7LsBqE/B2UeONiT0xuIs3Pt2dho+2n0OVuW4HWw+dEqXVFlzpXwovvQoqhQy5v9vF9jKtUo4RUb4Y2zMAI6J8oVXJG/gE+qNFP57EJ7tS0cXXBRHeevxyom7StCQB0/4UhgV3R3MSM3UIrZaMDBgwAH379sXSpUvtZd27d8eECROwaNGiRn1GdHQ0pkyZgn/84x+Nqs9khG4GtVYbymtq4alv/lCHEAKHLpRg3ZFsHMsqxem8Cvv5OldyZ68A/L/xMfD43X3zymrw5qZTWJfouPOrq0YBH4MasaEeuCXcE3HhHojw1kOSJFSZa5FeWIW0QiOOZZfip+Q8ZBRX2d9r0CgwOS4E0+PDEOalv2qbLFYbtp7Mx+YTF+FtUNXdK8zTPrfmWixWW4NLuFuS1SawPjEbXx3IwMjufnhsaGSLnOycW1aNYW/tgKnWhhUz+2N4lC9Scsrw4dZz2JSSBwD472PxuCXC87rvRdTaWiUZMZvN0Ol0SEhIwD333GMvnzt3LpKSkrBz585rfobNZkN4eDief/55zJ49u8E6JpMJJpPJ4WFCQkKYjBA1UY3FilN5FTiWVYrs0mqYLDaYam0w1VphtQmMifHH6JiAK74/s7gK1RYrPHQquOuUTfqCF0LgeHY5fkjOwcZjucgqqduXRZKAEd18MX1gOLr5GaBXy6FXKSCTSUgtqMSaQ5lYezgLhZWO82skqW4flyFdvPHkbV1g0NRPTGosVjz3zTH8mJyLkd19MSM+HPGdvJrdi1BpqoVOKXdIMoQQ2HoyH2/9fNphiG1kd1+8M7nPde+S+9K6Y/j6QCZuCffEmsf+5ND2y9fG9vTHkgf6Xdd9iNpCY5ORJg3mFhYWwmq1ws/PsQvZz88PeXl5jfqMd955B0ajEZMnT75inUWLFmHBggVNaRoRNUCjlKNPiDv6NHMTthBPXbPvLUkSega7oWewG14YFYWdZwvwv3vTseN0AbaeysfWU/kO9bVKOap/d7iht4sa4/sEorKmFgfTi5FaaMSpvAqcyqvA9tMFWDatHyJ9XOz1K2os+MvKQ/gttRgA8HPKRfycchGdfV0wPT4ME/sGX3VZ9WVlVRb8kJyDtYezcCSjFGqFDBHeeoR76RHurceh9GIculACoK6n6K7egUg4nIUtJ/Nx97934+MH+6F7QPP+T9P5gkr891AWAOD50d3qJVEzB0bg6wOZ+DnlIrJLqxHkrm3WfYjamyb1jOTk5CAoKAh79+5FfHy8vfz111/HF198gVOnTl31/V9//TUeeeQRfPfddxg5cuQV67FnhOjGlVpQiZX7LuCHY7koqTLD+rthJJkEDO/miyn9QzA8ytehJ6agwoTfUovw+saTyCuvgUGjwAdTYzG8my8KKkyYueIAUnLK4aJWYMHd0UjKLMXaI1n2uS86lRzj+wRi6i2h6Bnk5vBFX1BhwsH0Ymw8lovNJy9ec1t/jVKGhwZFYNbQTnDTKZGcVYZZXx5Gdmk1NEoZFtwdjdExAQ32klisNpzOq1tZdUuEp8NeNZc3txvZ3Rf/mdG/wXv/eflv2Hu+CLNu7YQXx0Q1LuhETtLuhmnWrFmDhx56CAkJCRg3blxjbwmAc0aIblRCCJhqbTCaamE0WeGiUVxzzkx+RQ0e//IIDl8ogSQBfx3WCT8cy8WFS4cdfv7QLYgJcgNQt3pp3eEsrPztgsOS6OhAV4ztGYD0QiMOXShBWqHjcukofwMm9Q3GuF4BMNfakFZkRFqBEWmFRujVCjw0KBx+rhqH95QYzZi7Jgm7zhTYy8K8dIgJdEOPQFcUVJhwLKsUKTnlMF1Kdjx0StwXF4IHBoSirNqCu/+9B5IE/DR3CKL8G/637peUPDz6xWG4aZX47aXbOCmY2rVWncDar18/LFmyxF7Wo0cPjB8//ooTWL/++ms8/PDD+PrrrzFhwoSm3A4AkxEicmSqtWL+hhR8fSDTXhbiqcUXDw9AuHf9ybFCCBxIK8bXBzLw4/G8ej0fl+ejDOrsjXtigxAd2PCRANditQks3XEOqw9m2ufINMRVo4BaKUdBxf/1AF9eVj0xNgiLp/S56j2Gvb0dmcXVWDSxJ6beUn8VI1F70epLez/++GPEx8dj2bJlWL58OVJSUhAWFoaXXnoJ2dnZWLlyJYC6RGT69Ol4//33MXHiRPvnaLVauLm5teiCNOgtAAASG0lEQVTDENHNQwiBL/dnYOH3KejqZ8CKmf3h+4feioaUGM1Yl5iN/alF6OLngrhwT/QN9bjuiad/VFplRkpOOY5nl+FkbjncdSr0CXFH7xB3hHnqYBMC208X4MvfLmDX2QIIASjlErY9M+yac3X+82sqXtt4Et38DNg0bwiX+VK71eqbnr355pvIzc1FTEwM3n33XQwdOhQAMHPmTKSnp2PHjh0AgGHDhjU4fDNjxgx8/vnnLfowRHTzKa+xwOXSapyOKqOoCt8lZSMqwBW3N2KPmbJqC+IXbUWV2YqvHhmAgZ2926CVRE3H7eCJiG5gf19/HF/8dgG39/DD8ulxzm4OUYMa+/3dursCERFRq5gxMBwAsOXkRZwvaPhQRqKOgodGEBF1QJ19XTC0qw92nSnAbe/sRKS3Hj2D3dAr2B39wz3qLV8mas+YjBARdVBP394VmcV1W/CnXnp9l5QDAAhy12JMjD/G9gpAbIg7ExNq1zhnhIiogys2mnEsqxTHsspwNLMU+1KL7Ju9AUCgmwZhXnpolDJoVXJolHK4apQI9tAi1FOHkEsvCXUTgitqalF+6RTomCA3h43ZiJqCE1iJiG5SNRYrdpzOx4/Jedh68iKMv0tMmkqlkCEuzAODOntjYCcv9Axyg6KVDyGkGweTESIiQo3FigNpxSittqDGbEW1xYoaixXFVWZkFVcjs6QKGcVVKK2q6wlRyCS4apUwaBSoNluR/7uN2QBArZAhKsAVMYGuiAlyQ5S/AQaNEhqlDBplXa9LaZUZ5wuMOJ9fidTCSmSXVMPfTYNOPi7o7OuCTj4uCHLXdujl2NQ4rXJQHhERdSwapRxDu/pcs16lqRZySYJGKbPPLxFCILXQiD3nCrHnXCH2nS9CeU0tjmaW4mhm6XW1K9BNgwXjYxq1rwrd+NgzQkREjWKzCaQXGXE8pxwpOWVIyS7H+YJKVJnrelsun7mjlEsI99Ij0kdf1wvioUVeWQ3O5VfifEEl0gqNsFjrvnru6h2I+Xf1gJeL2pmPRq2EwzRERNSmbLa6gw+Vcumq80pqLFa8t+Uslu06D5uoO5fn1bt64O7egVz1c4NhMkJERO3asaxSPP/NMZzKqwAA6FRyBLlrEeShRZC7Fn6uGuhUcuhUCuhUcmhVcphqbaisqUXFpVU/AgI9g9zQN9Sj3tlENRYrzhdUIr/chJggN/gYGtf7YrUJVNTUzaFx0yqZIF0HJiNERNTumWtt+GTnefx7+zn7ME9zBblrERvqDpsQOJVXgfRCI2y/+4brHuCKIV28MbizNzx0KqQWVtZNtC2oREZRFUqqzCirrktyLlPJZfAxqOHrqoafQYNOvnpE+bsiyt+ACG89FHIZyqot9iGo9EIj9GoFQjx1CPPUIdRTBxeNAlkl1UgvNCKt0IiM4ioEumtwd+8g+Ltd+3DHjozJCBERdRg1FitySquRXVqN7JK6/y2sNKHKbEWV2YpqsxVV5lqoFDIYNEoY1AoYNAqYrTYkZpTizMUKh8TjMjetEl4uKqQWGFu8zSqFDAa1AkVG81XrSRLQ0DetJAEDO3nhnthgjI7xh4u64TUlJUYzzlysQFqhEZWmWtRYLsXEYoVBo8SfIjzRN8yjXe4Hw2SEiIhuGpWmulU+SZmlUMll6OZvQDd/A3wNakiShMJKE/acK8Tus4XYe74IplorIr1dEOlTN9E2wtsFXi4quGmVcNMq4apRQkCgoMKE/AoT8stNyC2rxtn8SpzKLcfpvAqH/Vv8XTXo7OuCCG89jOZaZBbXLZm+WF63NFqjlCHcS48Ibz1CPHVIyijFgfRi+/sVMgmeehU8dCq465Tw0KlQVm3B2fxKFFaa6j3vH6kUMsSGuCO+kxe6+RnsG9m5aZUtH+wmYDJCRETUSmw2gaySapRVWxDurYNB0/CXfrXZiooaC7xd1PX2VcksrsL6xGx8m5iN1MKr99wEe2jR2dcFbloltJf2c9Gq5Mgtrca+1CJ70vNHrhoFwrz06HRpZVOkT10C9vtemMtZgJeLCvor9M40F5MRIiKiDkAIgdyyGhQbzSipMqOkyoLSKjM0Sjm6+RnQ2dflqkmCEAJphUbsSy3CofQSpBcZkVlchcLKqw8f/dEHU2Nxd+/A630cB9z0jIiIqAOQJAmB7loEumub/f7IS70eDwwIs5dXmWuRWVx96SDFSpzPN9r3eTHV1g0xSZAgSYAEQO7EVUNMRoiIiG5AOpXCPnemveNpR0RERORUTEaIiIjIqZiMEBERkVMxGSEiIiKnYjJCRERETsVkhIiIiJyKyQgRERE5FZMRIiIiciomI0RERORUTEaIiIjIqZiMEBERkVMxGSEiIiKnYjJCRERETsVkhIiIiJxK4ewGNIYQAgBQXl7u5JYQERFRY13+3r78PX4lHSIZqaioAACEhIQ4uSVERETUVBUVFXBzc7vidUlcK11pB2w2G3JycmAwGCBJUot9bnl5OUJCQpCZmQlXV9cW+1yqj7FuW4x322Gs2w5j3XZaKtZCCFRUVCAwMBAy2ZVnhnSInhGZTIbg4OBW+3xXV1f+YbcRxrptMd5th7FuO4x122mJWF+tR+QyTmAlIiIip2IyQkRERE4lnz9//nxnN8KZ5HI5hg0bBoWiQ4xYdWiMddtivNsOY912GOu205ax7hATWImIiOjGxWEaIiIiciomI0RERORUTEaIiIjIqZiMEBERkVPd1MnIkiVLEBERAY1Gg379+uHXX391dpM6vEWLFqF///4wGAzw9fXFhAkTcPr0aYc6QgjMnz8fgYGB0Gq1GDZsGFJSUpzU4hvDokWLIEkS5s2bZy9jnFtWdnY2HnzwQXh5eUGn06FPnz44fPiw/Trj3TJqa2vxt7/9DREREdBqtYiMjMTChQths9nsdRjr5tm1axfuuusuBAYGQpIkrF+/3uF6Y+JqMpkwZ84ceHt7Q6/X4+6770ZWVtb1N07cpFavXi2USqVYvny5OHHihJg7d67Q6/XiwoULzm5ahzZq1CixYsUKcfz4cZGUlCTGjRsnQkNDRWVlpb3OG2+8IQwGg1i7dq1ITk4WU6ZMEQEBAaK8vNyJLe+4Dhw4IMLDw0WvXr3E3Llz7eWMc8spLi4WYWFhYubMmWL//v0iLS1NbNmyRZw7d85eh/FuGa+99prw8vISP/zwg0hLSxMJCQnCxcVFvPfee/Y6jHXz/Pjjj+KVV14Ra9euFQDEt99+63C9MXGdNWuWCAoKEps3bxZHjhwRw4cPF7179xa1tbXX1babNhm55ZZbxKxZsxzKoqKixIsvvuikFt2Y8vPzBQCxc+dOIYQQNptN+Pv7izfeeMNep6amRri5uYmPP/7YWc3ssCoqKkSXLl3E5s2bxa233mpPRhjnlvXCCy+IwYMHX/E6491yxo0bJx5++GGHsokTJ4oHH3xQCMFYt5Q/JiONiWtpaalQKpVi9erV9jrZ2dlCJpOJTZs2XVd7bsphGrPZjMOHD+OOO+5wKL/jjjuwd+9eJ7XqxlRWVgYA8PT0BACkpaUhLy/PIfZqtRq33norY98MTzzxBMaNG4eRI0c6lDPOLWvDhg2Ii4vDfffdB19fX8TGxmL58uX264x3yxk8eDC2bt2KM2fOAACOHj2K3bt3Y+zYsQAY69bSmLgePnwYFovFoU5gYCBiYmKuO/Y35RZ2hYWFsFqt8PPzcyj38/NDXl6ek1p14xFC4Omnn8bgwYMRExMDAPb4NhT7CxcutHkbO7LVq1fjyJEjOHjwYL1rjHPLSk1NxdKlS/H000/j5ZdfxoEDB/Dkk09CrVZj+vTpjHcLeuGFF1BWVoaoqCjI5XJYrVa8/vrrmDp1KgD+bbeWxsQ1Ly8PKpUKHh4e9epc73fnTZmMXCZJksPvQoh6ZdR8s2fPxrFjx7B79+561xj765OZmYm5c+fil19+gUajuWI9xrll2Gw2xMXF4Z///CcAIDY2FikpKVi6dCmmT59ur8d4X781a9bgyy+/xFdffYXo6GgkJSVh3rx5CAwMxIwZM+z1GOvW0Zy4tkTsb8phGm9vb8jl8nqZXH5+fr2skJpnzpw52LBhA7Zv347g4GB7ub+/PwAw9tfp8OHDyM/PR79+/aBQKKBQKLBz50588MEHUCgU9lgyzi0jICAAPXr0cCjr3r07MjIyAPDvuiU999xzePHFF3H//fejZ8+emDZtGp566iksWrQIAGPdWhoTV39/f5jNZpSUlFyxTnPdlMmISqVCv379sHnzZofyzZs3Y+DAgU5q1Y1BCIHZs2dj3bp12LZtGyIiIhyuR0REwN/f3yH2ZrMZO3fuZOyb4LbbbkNycjKSkpLsr7i4ODzwwANISkpCZGQk49yCBg0aVG+J+pkzZxAWFgaAf9ctqaqqCjKZ41eTXC63L+1lrFtHY+Lar18/KJVKhzq5ubk4fvz49cf+uqa/dmCXl/Z++umn4sSJE2LevHlCr9eL9PR0ZzetQ3v88ceFm5ub2LFjh8jNzbW/qqqq7HXeeOMN4ebmJtatWyeSk5PF1KlTuSyvBfx+NY0QjHNLOnDggFAoFOL1118XZ8+eFatWrRI6nU58+eWX9jqMd8uYMWOGCAoKsi/tXbdunfD29hbPP/+8vQ5j3TwVFRUiMTFRJCYmCgBi8eLFIjEx0b6lRWPiOmvWLBEcHCy2bNkijhw5IkaMGMGlvdfro48+EmFhYUKlUom+ffval59S8wFo8LVixQp7HZvNJl599VXh7+8v1Gq1GDp0qEhOTnZeo28Qf0xGGOeW9f3334uYmBihVqtFVFSUWLZsmcN1xrtllJeXi7lz54rQ0FCh0WhEZGSkeOWVV4TJZLLXYaybZ/v27Q3++zxjxgwhROPiWl1dLWbPni08PT2FVqsVd955p8jIyLjutklCCHF9fStEREREzXdTzhkhIiKi9oPJCBERETkVkxEiIiJyKiYjRERE5FRMRoiIiMipmIwQERGRUzEZISIiIqdiMkJEHZIkSVi/fr2zm0FELYDJCBE12cyZMyFJUr3X6NGjnd00IuqAFM5uABF1TKNHj8aKFSscytRqtZNaQ0QdGXtGiKhZ1Go1/P39HV4eHh4A6oZQli5dijFjxkCr1SIiIgIJCQkO709OTsaIESOg1Wrh5eWFRx99FJWVlQ51PvvsM0RHR0OtViMgIACzZ892uF5YWIh77rkHOp0OXbp0wYYNG1r3oYmoVTAZIaJW8fe//x2TJk3C0aNH8eCDD2Lq1Kk4efIkgLpj4kePHg0PDw8cPHgQCQkJ2LJli0OysXTpUjzxxBN49NFHkZycjA0bNqBz584O91iwYAEmT56MY8eOYezYsXjggQdQXFzcps9JRC3guo/aI6KbzowZM4RcLhd6vd7htXDhQiFE3enNs2bNcnjPgAEDxOOPPy6EEGLZsmXCw8NDVFZW2q9v3LhRyGQykZeXJ4QQIjAwULzyyitXbAMA8be//c3+e2VlpZAkSfz0008t9pxE1DY4Z4SImmX48OFYunSpQ5mnp6f95/j4eIdr8fHxSEpKAgCcPHkSvXv3hl6vt18fNGgQbDYbTp8+DUmSkJOTg9tuu+2qbejVq5f9Z71eD4PBgPz8/GY/ExE5B5MRImoWvV5fb9jkWiRJAgAIIew/N1RHq9U26vOUSmW999pstia1iYicj3NGiKhV/Pbbb/V+j4qKAgD06NEDSUlJMBqN9ut79uyBTCZD165dYTAYEB4ejq1bt7Zpm4nIOdgzQkTNYjKZkJeX51CmUCjg7e0NAEhISEBcXBwGDx6MVatW4cCBA/j0008BAA888ABeffVVzJgxA/Pnz0dBQQHmzJmDadOmwc/PDwAwf/58zJo1C76+vhgzZgwqKiqwZ88ezJkzp20flIhaHZMRImqWTZs2ISAgwKGsW7duOHXqFIC6lS6rV6/GX//6V/j7+2PVqlXo0aMHAECn0+Hnn3/G3Llz0b9/f+h0OkyaNAmLFy+2f9aMGTNQU1ODd999F88++yy8vb1x7733tt0DElGbkYQQwtmNIKIbiyRJ+PbbbzFhwgRnN4WIOgDOGSEiIiKnYjJCRERETsU5I0TU4jj6S0RNwZ4RIiIiciomI0RERORUTEaIiIjIqZiMEBERkVMxGSEiIiKnYjJCRERETsVkhIiIiJyKyQgRERE5FZMRIiIicqr/D5gXKqwQHh/RAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5.5, min_value-.1, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]).to(DEVICE) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]]).to(DEVICE)\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67072,
     "status": "ok",
     "timestamp": 1739960743114,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "MlSPdqo3QDyr",
    "outputId": "364c407d-3bb7-4fd9-ac12-19a8480c9076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on test set: 13.22483581035202%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on test set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1739961996036,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "HSHGOjSmc3Vi",
    "outputId": "7c2a7917-9217-4397-8be2-0c96496d6b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> GAYLER\n",
      "= ['G', 'EY', 'L', 'AX', 'R']\n",
      "< G EY L AX R ['G', 'EY', 'L', 'AX', 'R']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f563cd1f730>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLJmB0V/sNcUHuHtZcdQwt",
   "collapsed_sections": [
    "8mDO6QlJZpUZ",
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
