{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1739957705963,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "29775173-7761-4953-d853-502b8b825ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn_gen/exp/en\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1739957711340,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "33e9e6e9-f2b0-4d04-e665-6f2600a2c57e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8274,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7a08073c-d249-49ab-ddaf-f827de5d8d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL =\"dot\"\n",
    "EMB_DIM = \"32\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"100\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "704ba764-a750-40fc-d5c9-0a6d289c3ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/en\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"validation_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    return graphemes, phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.')).lower()\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[1]) for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "1a7e253b-ee59-419e-f7d6-0e469cac96fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq), ...]\n",
    "  graphemes, phonemes = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  word = word.lower()\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1).to(DEVICE)\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "92da8620-4d32-4614-db38-6fdfcd7e04fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 19, 12, 26, 19, 8, 14, 19, 30, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "56a821f8-be28-4de8-8e2c-f5e7b8d2bc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f9cc7917460> ([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "([4, 8, 6, 26, 24, 10, 1], [18, 6, 34, 1])\n",
      "train grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "valid grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "test grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "train phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "valid phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "test phn 35 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'OY', 24: 'P', 25: 'Q', 26: 'R', 27: 'S', 28: 'SH', 29: 'T', 30: 'UW', 31: 'V', 32: 'W', 33: 'Y', 34: 'Z'}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "28 {\"'\": 4, 'c': 8, 'a': 6, 'u': 26, 's': 24, 'e': 10, 'o': 20, 'r': 23, 'm': 18, 'n': 19, 'q': 22, 't': 25, 'i': 14, 'b': 7, 'g': 12, 'h': 13, 'k': 16, 'l': 17, 'd': 9, 'v': 27, 'y': 30, 'z': 31, 'w': 28, 'j': 15, '-': 5, 'f': 11, 'p': 21, 'x': 29}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n",
      "32 {'K': 18, 'AX': 6, 'Z': 34, 'AO': 4, 'R': 26, 'S': 27, 'M': 20, 'N': 21, 'W': 32, 'T': 29, 'IY': 16, 'AA': 3, 'B': 8, 'G': 14, 'L': 19, 'EH': 11, 'D': 10, 'V': 31, 'Q': 25, 'NG': 22, 'SH': 28, 'EY': 12, 'HH': 15, 'AW': 5, 'UW': 30, 'AY': 7, 'JH': 17, 'Y': 33, 'F': 13, 'P': 24, 'CH': 9, 'OY': 23}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size).to(DEVICE)\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size).to(DEVICE)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size)).to(DEVICE)\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False).to(DEVICE)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size).to(DEVICE)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "9a095505-f179-48d0-c305-f4e69125f170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]]).to(DEVICE)\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size).to(DEVICE) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n",
    "\n",
    "del encoder_test\n",
    "del decoder_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    decoder_input = decoder_input.to(DEVICE)\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Backpropagate loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "      )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1739957723364,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "68700f7a-b173-4800-d808-8d922cd64e2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 32\n",
      "hidden_size: 100\n",
      "n_layers: 1\n",
      "Encoder has a total number of 41224 parameters\n",
      "Decoder has a total number of 78355 parameters\n",
      "Total number of all parameters is 119579\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2952362,
     "status": "ok",
     "timestamp": 1739960675722,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "e9e1eaf7-3a18-4620-b007-cbad6be38496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 1 finished in 0m 43.35s (- 71m 31.85s) (1 1.0%). train avg loss: 1.3978, val avg loss: 1.301\n",
      "Training for epoch 2 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 2 finished in 1m 24.49s (- 69m 0.12s) (2 2.0%). train avg loss: 0.6011, val avg loss: 1.0823\n",
      "Training for epoch 3 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 3 finished in 2m 4.16s (- 66m 54.63s) (3 3.0%). train avg loss: 0.5086, val avg loss: 1.0523\n",
      "Training for epoch 4 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 4 finished in 2m 44.12s (- 65m 38.91s) (4 4.0%). train avg loss: 0.453, val avg loss: 0.9565\n",
      "Training for epoch 5 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 5 finished in 3m 29.37s (- 66m 18.04s) (5 5.0%). train avg loss: 0.4024, val avg loss: 0.9397\n",
      "Training for epoch 6 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 6 finished in 4m 12.32s (- 65m 53.07s) (6 6.0%). train avg loss: 0.4044, val avg loss: 1.0034\n",
      "Training for epoch 7 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 7 finished in 4m 55.31s (- 65m 23.46s) (7 7.0%). train avg loss: 0.3762, val avg loss: 0.8215\n",
      "Training for epoch 8 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 8 finished in 5m 35.37s (- 64m 16.74s) (8 8.0%). train avg loss: 0.344, val avg loss: 0.8924\n",
      "Training for epoch 9 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 9 finished in 6m 13.25s (- 62m 53.94s) (9 9.0%). train avg loss: 0.3691, val avg loss: 0.856\n",
      "Training for epoch 10 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 10 finished in 6m 51.46s (- 61m 43.17s) (10 10.0%). train avg loss: 0.3285, val avg loss: 0.7951\n",
      "Training for epoch 11 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 11 finished in 7m 31.0s (- 60m 48.97s) (11 11.0%). train avg loss: 0.3111, val avg loss: 0.758\n",
      "Training for epoch 12 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 12 finished in 8m 10.8s (- 59m 59.2s) (12 12.0%). train avg loss: 0.2963, val avg loss: 0.7336\n",
      "Training for epoch 13 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 13 finished in 8m 53.35s (- 59m 29.37s) (13 13.0%). train avg loss: 0.3387, val avg loss: 0.7518\n",
      "Training for epoch 14 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 14 finished in 9m 33.93s (- 58m 45.55s) (14 14.0%). train avg loss: 0.2827, val avg loss: 0.7244\n",
      "Training for epoch 15 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 15 finished in 10m 12.05s (- 57m 48.31s) (15 15.0%). train avg loss: 0.2845, val avg loss: 0.7845\n",
      "Training for epoch 16 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 16 finished in 10m 50.22s (- 56m 53.68s) (16 16.0%). train avg loss: 0.2649, val avg loss: 0.7359\n",
      "Training for epoch 17 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 17 finished in 11m 32.73s (- 56m 22.14s) (17 17.0%). train avg loss: 0.265, val avg loss: 0.732\n",
      "Training for epoch 18 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 18 finished in 12m 13.9s (- 55m 43.3s) (18 18.0%). train avg loss: 0.2894, val avg loss: 0.713\n",
      "Training for epoch 19 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 19 finished in 12m 55.8s (- 55m 7.37s) (19 19.0%). train avg loss: 0.275, val avg loss: 0.7109\n",
      "Training for epoch 20 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 20 finished in 13m 37.95s (- 54m 31.79s) (20 20.0%). train avg loss: 0.2581, val avg loss: 0.7501\n",
      "Training for epoch 21 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 21 finished in 14m 16.96s (- 53m 43.8s) (21 21.0%). train avg loss: 0.2663, val avg loss: 0.7637\n",
      "Training for epoch 22 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 22 finished in 14m 55.42s (- 52m 54.66s) (22 22.0%). train avg loss: 0.2481, val avg loss: 0.6946\n",
      "Training for epoch 23 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 23 finished in 15m 36.46s (- 52m 15.1s) (23 23.0%). train avg loss: 0.2387, val avg loss: 0.6715\n",
      "Training for epoch 24 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 24 finished in 16m 17.22s (- 51m 34.54s) (24 24.0%). train avg loss: 0.258, val avg loss: 0.6711\n",
      "Training for epoch 25 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 25 finished in 16m 57.39s (- 50m 52.16s) (25 25.0%). train avg loss: 0.2334, val avg loss: 0.6698\n",
      "Training for epoch 26 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 26 finished in 17m 37.66s (- 50m 10.27s) (26 26.0%). train avg loss: 0.2602, val avg loss: 0.6801\n",
      "Training for epoch 27 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 27 finished in 18m 16.32s (- 49m 24.13s) (27 27.0%). train avg loss: 0.2242, val avg loss: 0.6993\n",
      "Training for epoch 28 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 28 finished in 18m 56.46s (- 48m 42.32s) (28 28.0%). train avg loss: 0.2334, val avg loss: 0.6497\n",
      "Training for epoch 29 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 29 finished in 19m 36.8s (- 48m 1.14s) (29 29.0%). train avg loss: 0.2231, val avg loss: 0.675\n",
      "Training for epoch 30 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 30 finished in 20m 18.07s (- 47m 22.16s) (30 30.0%). train avg loss: 0.2297, val avg loss: 0.7326\n",
      "Training for epoch 31 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 31 finished in 20m 59.98s (- 46m 44.47s) (31 31.0%). train avg loss: 0.2213, val avg loss: 0.6698\n",
      "Training for epoch 32 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 32 finished in 21m 41.91s (- 46m 6.57s) (32 32.0%). train avg loss: 0.24, val avg loss: 0.682\n",
      "Training for epoch 33 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 33 finished in 22m 20.88s (- 45m 22.39s) (33 33.0%). train avg loss: 0.2152, val avg loss: 0.6478\n",
      "Training for epoch 34 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 34 finished in 23m 2.51s (- 44m 43.69s) (34 34.0%). train avg loss: 0.2228, val avg loss: 0.6931\n",
      "Training for epoch 35 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 35 finished in 23m 44.79s (- 44m 6.03s) (35 35.0%). train avg loss: 0.2156, val avg loss: 0.6922\n",
      "Training for epoch 36 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 36 finished in 24m 24.55s (- 43m 23.65s) (36 36.0%). train avg loss: 0.2209, val avg loss: 0.7203\n",
      "Training for epoch 37 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 37 finished in 25m 0.96s (- 42m 35.69s) (37 37.0%). train avg loss: 0.2397, val avg loss: 0.6716\n",
      "Training for epoch 38 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 38 finished in 25m 36.11s (- 41m 46.29s) (38 38.0%). train avg loss: 0.2027, val avg loss: 0.7039\n",
      "Training for epoch 39 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 39 finished in 26m 16.45s (- 41m 5.74s) (39 39.0%). train avg loss: 0.2117, val avg loss: 0.6381\n",
      "Training for epoch 40 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 40 finished in 26m 51.35s (- 40m 17.02s) (40 40.0%). train avg loss: 0.2072, val avg loss: 0.6756\n",
      "Training for epoch 41 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 41 finished in 27m 25.94s (- 39m 28.55s) (41 41.0%). train avg loss: 0.2157, val avg loss: 0.6336\n",
      "Training for epoch 42 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 42 finished in 27m 59.44s (- 38m 39.23s) (42 42.0%). train avg loss: 0.2056, val avg loss: 0.6543\n",
      "Training for epoch 43 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 43 finished in 28m 37.2s (- 37m 56.29s) (43 43.0%). train avg loss: 0.1991, val avg loss: 0.7311\n",
      "Training for epoch 44 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 44 finished in 29m 12.21s (- 37m 10.09s) (44 44.0%). train avg loss: 0.2005, val avg loss: 0.6844\n",
      "Training for epoch 45 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 45 finished in 29m 53.31s (- 36m 31.82s) (45 45.0%). train avg loss: 0.1977, val avg loss: 0.7661\n",
      "Training for epoch 46 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 46 finished in 30m 35.77s (- 35m 55.04s) (46 46.0%). train avg loss: 0.2265, val avg loss: 0.8306\n",
      "Training for epoch 47 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 47 finished in 31m 17.4s (- 35m 17.07s) (47 47.0%). train avg loss: 0.2119, val avg loss: 0.6909\n",
      "Training for epoch 48 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 48 finished in 32m 5.23s (- 34m 45.67s) (48 48.0%). train avg loss: 0.1834, val avg loss: 0.6284\n",
      "Training for epoch 49 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 49 finished in 32m 48.01s (- 34m 8.34s) (49 49.0%). train avg loss: 0.1895, val avg loss: 0.6608\n",
      "Training for epoch 50 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 50 finished in 33m 30.0s (- 33m 30.0s) (50 50.0%). train avg loss: 0.2167, val avg loss: 0.6858\n",
      "Training for epoch 51 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 51 finished in 34m 12.12s (- 32m 51.64s) (51 51.0%). train avg loss: 0.2001, val avg loss: 0.6963\n",
      "Training for epoch 52 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 52 finished in 34m 55.01s (- 32m 13.85s) (52 52.0%). train avg loss: 0.1839, val avg loss: 0.6498\n",
      "Training for epoch 53 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 53 finished in 35m 37.08s (- 31m 35.14s) (53 53.0%). train avg loss: 0.1833, val avg loss: 0.6294\n",
      "Training for epoch 54 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 54 finished in 36m 19.23s (- 30m 56.38s) (54 54.0%). train avg loss: 0.1862, val avg loss: 0.6316\n",
      "Training for epoch 55 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 55 finished in 37m 0.79s (- 30m 17.01s) (55 55.0%). train avg loss: 0.221, val avg loss: 0.6419\n",
      "Training for epoch 56 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 56 finished in 37m 43.03s (- 29m 38.1s) (56 56.0%). train avg loss: 0.1861, val avg loss: 0.6449\n",
      "Training for epoch 57 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 57 finished in 38m 24.09s (- 28m 58.17s) (57 57.0%). train avg loss: 0.1894, val avg loss: 0.7129\n",
      "Training for epoch 58 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 58 finished in 39m 6.0s (- 28m 18.82s) (58 58.0%). train avg loss: 0.1804, val avg loss: 0.6287\n",
      "Training for epoch 59 has started (lr=0.001). Found 1586 batch(es).\n",
      "Epoch 59 finished in 39m 48.5s (- 27m 39.81s) (59 59.0%). train avg loss: 0.1892, val avg loss: 0.6941\n",
      "Training for epoch 60 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 60 finished in 40m 32.48s (- 27m 1.65s) (60 60.0%). train avg loss: 0.165, val avg loss: 0.6437\n",
      "Training for epoch 61 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 61 finished in 41m 15.29s (- 26m 22.56s) (61 61.0%). train avg loss: 0.1617, val avg loss: 0.6182\n",
      "Training for epoch 62 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 62 finished in 41m 56.25s (- 25m 42.22s) (62 62.0%). train avg loss: 0.1558, val avg loss: 0.5835\n",
      "Training for epoch 63 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 63 finished in 42m 37.43s (- 25m 1.98s) (63 63.0%). train avg loss: 0.1535, val avg loss: 0.6092\n",
      "Training for epoch 64 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 64 finished in 43m 18.53s (- 24m 21.67s) (64 64.0%). train avg loss: 0.1557, val avg loss: 0.6029\n",
      "Training for epoch 65 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 65 finished in 44m 0.63s (- 23m 41.88s) (65 65.0%). train avg loss: 0.1523, val avg loss: 0.6339\n",
      "Training for epoch 66 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 66 finished in 44m 42.99s (- 23m 2.15s) (66 66.0%). train avg loss: 0.153, val avg loss: 0.6343\n",
      "Training for epoch 67 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 67 finished in 45m 24.61s (- 22m 21.97s) (67 67.0%). train avg loss: 0.1495, val avg loss: 0.6222\n",
      "Training for epoch 68 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 68 finished in 46m 6.54s (- 21m 41.9s) (68 68.0%). train avg loss: 0.151, val avg loss: 0.6242\n",
      "Training for epoch 69 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 69 finished in 46m 43.98s (- 20m 59.76s) (69 69.0%). train avg loss: 0.1533, val avg loss: 0.6091\n",
      "Training for epoch 70 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 70 finished in 47m 20.94s (- 20m 17.54s) (70 70.0%). train avg loss: 0.1517, val avg loss: 0.6238\n",
      "Training for epoch 71 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 71 finished in 47m 56.52s (- 19m 34.92s) (71 71.0%). train avg loss: 0.157, val avg loss: 0.6116\n",
      "Training for epoch 72 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 72 finished in 48m 31.9s (- 18m 52.41s) (72 72.0%). train avg loss: 0.1532, val avg loss: 0.5973\n",
      "Training for epoch 73 has started (lr=0.0005). Found 1586 batch(es).\n",
      "Epoch 73 finished in 49m 6.3s (- 18m 9.73s) (73 73.0%). train avg loss: 0.1438, val avg loss: 0.6095\n",
      "Training for epoch 74 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 74 finished in 49m 39.87s (- 17m 26.98s) (74 74.0%). train avg loss: 0.1356, val avg loss: 0.5892\n",
      "Training for epoch 75 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 75 finished in 50m 17.65s (- 16m 45.88s) (75 75.0%). train avg loss: 0.1337, val avg loss: 0.6092\n",
      "Training for epoch 76 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 76 finished in 50m 53.31s (- 16m 4.2s) (76 76.0%). train avg loss: 0.1349, val avg loss: 0.6018\n",
      "Training for epoch 77 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 77 finished in 51m 29.62s (- 15m 22.87s) (77 77.0%). train avg loss: 0.1316, val avg loss: 0.6115\n",
      "Training for epoch 78 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 78 finished in 52m 5.38s (- 14m 41.52s) (78 78.0%). train avg loss: 0.1335, val avg loss: 0.5807\n",
      "Training for epoch 79 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 79 finished in 52m 44.22s (- 14m 1.12s) (79 79.0%). train avg loss: 0.1316, val avg loss: 0.5968\n",
      "Training for epoch 80 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 80 finished in 53m 19.81s (- 13m 19.95s) (80 80.0%). train avg loss: 0.1316, val avg loss: 0.6043\n",
      "Training for epoch 81 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 81 finished in 53m 56.72s (- 12m 39.23s) (81 81.0%). train avg loss: 0.1355, val avg loss: 0.5954\n",
      "Training for epoch 82 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 82 finished in 54m 33.37s (- 11m 58.54s) (82 82.0%). train avg loss: 0.1302, val avg loss: 0.6365\n",
      "Training for epoch 83 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 83 finished in 55m 9.33s (- 11m 17.81s) (83 83.0%). train avg loss: 0.1326, val avg loss: 0.6033\n",
      "Training for epoch 84 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 84 finished in 55m 43.41s (- 10m 36.84s) (84 84.0%). train avg loss: 0.1307, val avg loss: 0.6077\n",
      "Training for epoch 85 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 85 finished in 56m 18.48s (- 9m 56.2s) (85 85.0%). train avg loss: 0.1309, val avg loss: 0.5975\n",
      "Training for epoch 86 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 86 finished in 56m 53.61s (- 9m 15.7s) (86 86.0%). train avg loss: 0.1281, val avg loss: 0.6246\n",
      "Training for epoch 87 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 87 finished in 57m 29.25s (- 8m 35.4s) (87 87.0%). train avg loss: 0.1286, val avg loss: 0.6018\n",
      "Training for epoch 88 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 88 finished in 58m 5.92s (- 7m 55.35s) (88 88.0%). train avg loss: 0.1264, val avg loss: 0.6063\n",
      "Training for epoch 89 has started (lr=0.00025). Found 1586 batch(es).\n",
      "Epoch 89 finished in 58m 49.86s (- 7m 16.27s) (89 89.0%). train avg loss: 0.1301, val avg loss: 0.6517\n",
      "Training for epoch 90 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 90 finished in 59m 34.19s (- 6m 37.13s) (90 90.0%). train avg loss: 0.1238, val avg loss: 0.6206\n",
      "Training for epoch 91 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 91 finished in 60m 15.65s (- 5m 57.59s) (91 91.0%). train avg loss: 0.121, val avg loss: 0.6449\n",
      "Training for epoch 92 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 92 finished in 60m 57.06s (- 5m 18.0s) (92 92.0%). train avg loss: 0.1232, val avg loss: 0.6252\n",
      "Training for epoch 93 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 93 finished in 61m 39.81s (- 4m 38.48s) (93 93.0%). train avg loss: 0.1198, val avg loss: 0.6044\n",
      "Training for epoch 94 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 94 finished in 62m 22.2s (- 3m 58.86s) (94 94.0%). train avg loss: 0.1186, val avg loss: 0.619\n",
      "Training for epoch 95 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 95 finished in 63m 7.32s (- 3m 19.33s) (95 95.0%). train avg loss: 0.1209, val avg loss: 0.6096\n",
      "Training for epoch 96 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 96 finished in 63m 48.66s (- 2m 39.53s) (96 96.0%). train avg loss: 0.1193, val avg loss: 0.6342\n",
      "Training for epoch 97 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 97 finished in 64m 31.01s (- 1m 59.72s) (97 97.0%). train avg loss: 0.1208, val avg loss: 0.6096\n",
      "Training for epoch 98 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 98 finished in 65m 12.66s (- 1m 19.85s) (98 98.0%). train avg loss: 0.1201, val avg loss: 0.6159\n",
      "Training for epoch 99 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 99 finished in 65m 54.12s (- 0m 39.94s) (99 99.0%). train avg loss: 0.1197, val avg loss: 0.6339\n",
      "Training for epoch 100 has started (lr=0.000125). Found 1586 batch(es).\n",
      "Epoch 100 finished in 66m 35.77s (- 0m 0.0s) (100 100.0%). train avg loss: 0.1181, val avg loss: 0.6323\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get loss\n",
    "    unweighted_train_loss = train_batch(grps, phns, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "-498emHUaNzb",
    "outputId": "bab4a42d-c2d8-4a89-c7a9-eb0ace0bc12c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5.5, min_value-.1, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]).to(DEVICE) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]]).to(DEVICE)\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67072,
     "status": "ok",
     "timestamp": 1739960743114,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "MlSPdqo3QDyr",
    "outputId": "364c407d-3bb7-4fd9-ac12-19a8480c9076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on test set: 12.099986623335646%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, arpabet_phoneme_sequence = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on test set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1739961996036,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "HSHGOjSmc3Vi",
    "outputId": "7c2a7917-9217-4397-8be2-0c96496d6b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> RUBIOS\n",
      "= ['R', 'UW', 'B', 'IY', 'AO', 'W', 'Z']\n",
      "< R UW B IY AO W S ['R', 'UW', 'B', 'IY', 'AO', 'W', 'S']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9bf823e250>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 411.429x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLJmB0V/sNcUHuHtZcdQwt",
   "collapsed_sections": [
    "8mDO6QlJZpUZ",
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
