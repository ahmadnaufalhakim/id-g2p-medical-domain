{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec9kWAWVD9UU"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1739957705963,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "JT1nFx9SK5UF",
    "outputId": "29775173-7761-4953-d853-502b8b825ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/d/Hakims/college/S2/tesis/id-g2p-medical-domain/modules/prn_gen/exp/id\n"
     ]
    }
   ],
   "source": [
    "print(globals()[\"_dh\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4880,
     "status": "ok",
     "timestamp": 1739957711340,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "LdstRSwX86t4",
    "outputId": "33e9e6e9-f2b0-4d04-e665-6f2600a2c57e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8274,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FlovFUQYJj6-",
    "outputId": "7a08073c-d249-49ab-ddaf-f827de5d8d94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: jiwer in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ahmadnaufalhakim/.local/lib/python3.8/site-packages (from jiwer) (3.9.7)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-cudnn-cu12 (/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719612,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "tIgQTZ7ZJsfT"
   },
   "outputs": [],
   "source": [
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xGGFh-68xYx"
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "R2DTSa3h8zgf"
   },
   "outputs": [],
   "source": [
    "GRP_TYPE = \"unigram\" # @param [\"unigram\", \"bigram\", \"trigram\"]\n",
    "ATTN_MODEL = \"dot\"\n",
    "EMB_DIM = \"64\" # @param [16, 32, 64, 128, 256, 512]\n",
    "HIDDEN_SIZE = \"50\" # @param [64, 128, 256, 512, 1024]\n",
    "N_LAYERS = \"1\" # @param [1, 2]\n",
    "DROPOUT_PROBA = .1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiSP-GxlIvUG"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "FfAkZ0ErIxOW",
    "outputId": "704ba764-a750-40fc-d5c9-0a6d289c3ed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# PyTorch\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "USE_CUDA = (DEVICE.type == \"cuda\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Data preprocessing\n",
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "PAD_TOKEN = 2\n",
    "UNK_TOKEN = 3\n",
    "\n",
    "# Directories\n",
    "CURR_DIR = globals()[\"_dh\"][0]\n",
    "DATA_SOURCE_DIR = os.path.join(CURR_DIR, \"../../data/ma\")\n",
    "DATA_DIR = os.path.join(CURR_DIR, \"data\")\n",
    "if not os.path.exists(DATA_DIR) :\n",
    "  os.mkdir(DATA_DIR)\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"train_converted.csv\"), os.path.join(DATA_DIR, \"train.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"val_converted.csv\"), os.path.join(DATA_DIR, \"val.csv\"))\n",
    "shutil.copy(os.path.join(DATA_SOURCE_DIR, \"test_converted.csv\"), os.path.join(DATA_DIR, \"test.csv\"))\n",
    "MODELS_DIR = os.path.join(CURR_DIR, \"models\")\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)\n",
    "MODELS_DIR = os.path.join(MODELS_DIR, GRP_TYPE)\n",
    "if not os.path.exists(MODELS_DIR) :\n",
    "  os.mkdir(MODELS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd1ak2wwJJem"
   },
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFIgZGRJ9qLV"
   },
   "source": [
    "### `G2PDataset` torch dataset class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "qaOrjh2JJLLO"
   },
   "outputs": [],
   "source": [
    "class G2PDataset(Dataset) :\n",
    "  def __init__(self, graphemes_list, phonemes_list) -> None :\n",
    "    assert len(graphemes_list) == len(phonemes_list)\n",
    "    # Handle graphemes\n",
    "    self.graphemes_list = graphemes_list\n",
    "    self.grapheme2index = {}\n",
    "    self.index2grapheme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\", 3:\"<UNK>\"}\n",
    "    self.n_graphemes = 4\n",
    "    for graphemes in graphemes_list :\n",
    "      for grapheme in graphemes :\n",
    "        self.add_grapheme(grapheme)\n",
    "    i = 4\n",
    "    for grapheme in sorted(self.grapheme2index) :\n",
    "      self.grapheme2index[grapheme] = i\n",
    "      self.index2grapheme[i] = grapheme\n",
    "      i += 1\n",
    "    # Handle phonemes\n",
    "    self.phonemes_list = phonemes_list\n",
    "    self.phoneme2index = {}\n",
    "    self.index2phoneme = {0: \"<SOS>\", 1: \"<EOS>\", 2:\"<PAD>\"}\n",
    "    self.n_phonemes = 3\n",
    "    for phonemes in phonemes_list :\n",
    "      for phoneme in phonemes :\n",
    "        self.add_phoneme(phoneme)\n",
    "    i = 3\n",
    "    for phoneme in sorted(self.phoneme2index) :\n",
    "      self.phoneme2index[phoneme] = i\n",
    "      self.index2phoneme[i] = phoneme\n",
    "      i += 1\n",
    "\n",
    "  def add_grapheme(self, grapheme) :\n",
    "    if grapheme not in self.grapheme2index :\n",
    "      self.grapheme2index[grapheme] = self.n_graphemes\n",
    "      self.index2grapheme[self.n_graphemes] = grapheme\n",
    "      self.n_graphemes += 1\n",
    "\n",
    "  def add_phoneme(self, phoneme) :\n",
    "    if phoneme not in self.phoneme2index :\n",
    "      self.phoneme2index[phoneme] = self.n_phonemes\n",
    "      self.index2phoneme[self.n_phonemes] = phoneme\n",
    "      self.n_phonemes += 1\n",
    "\n",
    "  def __len__(self) :\n",
    "    return len(self.graphemes_list)\n",
    "\n",
    "  def __getitem__(self, index) -> str :\n",
    "    graphemes = [self.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in self.graphemes_list[index]] + [EOS_TOKEN]\n",
    "    phonemes = [self.phoneme2index[phoneme] for phoneme in self.phonemes_list[index]] + [EOS_TOKEN]\n",
    "    return graphemes, phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8IB7SapA7MM"
   },
   "source": [
    "### Helper functions to prepare `train/val/test` set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vU52JF_pBru4"
   },
   "outputs": [],
   "source": [
    "def extract_graphemes(grapheme_syllable_sequence:str, grp_type:str) :\n",
    "  word = ''.join(grapheme_syllable_sequence.split('.')).lower()\n",
    "  # Unigram\n",
    "  if grp_type == \"unigram\" :\n",
    "    return [*word]\n",
    "  # Bigram\n",
    "  elif grp_type == \"bigram\" :\n",
    "    if len(word) < 2 :\n",
    "      return [word]\n",
    "    return [word[i:i+2] for i in range(len(word)-1)]\n",
    "  # Trigram\n",
    "  elif grp_type == \"trigram\" :\n",
    "    if len(word) < 3 :\n",
    "      return [word]\n",
    "    return [word[i:i+3] for i in range(len(word)-2)]\n",
    "\n",
    "def extract_arpabet_phonemes(arpabet_phoneme_sequence:str) :\n",
    "  return arpabet_phoneme_sequence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1739957719613,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "59DHgoYQ-R6T"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(split_name:str, grp_type:str) :\n",
    "  assert split_name in [\"train\", \"val\", \"test\"]\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  print(f\"Reading {split_name} entries ..\")\n",
    "  # Read the file and split into lines\n",
    "  with open(os.path.join(DATA_DIR, f\"{split_name}.csv\"), encoding=\"utf-8\") as f_csv :\n",
    "    next(f_csv, None)\n",
    "    # Split every row into pairs\n",
    "    pairs = [[s.strip('\\n') for s in row.split(',')] for row in f_csv]\n",
    "    # Accumulate all lines into two graphemes and phonemes lists\n",
    "    graphemes_list = [extract_graphemes(pair[0], grp_type) for pair in pairs] # Split grapheme as desired\n",
    "    phonemes_list = [extract_arpabet_phonemes(pair[-1]) for pair in pairs]\n",
    "    # Create the G2PDataset object\n",
    "    g2p_dataset = G2PDataset(graphemes_list, phonemes_list)\n",
    "  return g2p_dataset, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1757,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "DwbB20gZDJOe",
    "outputId": "1a7e253b-ee59-419e-f7d6-0e469cac96fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train entries ..\n",
      "Reading val entries ..\n",
      "Reading test entries ..\n"
     ]
    }
   ],
   "source": [
    "train_g2p_dataset, train_pairs = prepare_dataset(\"train\", grp_type=GRP_TYPE)\n",
    "val_g2p_dataset, val_pairs = prepare_dataset(\"val\", grp_type=GRP_TYPE)\n",
    "test_g2p_dataset, test_pairs = prepare_dataset(\"test\", grp_type=GRP_TYPE)\n",
    "pairs = train_pairs + val_pairs + test_pairs\n",
    "\n",
    "# Equalize grapheme and phoneme mappings for val and test set\n",
    "## Valid set\n",
    "val_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "val_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "val_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "val_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "val_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "val_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "## Test set\n",
    "test_g2p_dataset.grapheme2index = train_g2p_dataset.grapheme2index\n",
    "test_g2p_dataset.index2grapheme = train_g2p_dataset.index2grapheme\n",
    "test_g2p_dataset.n_graphemes = train_g2p_dataset.n_graphemes\n",
    "test_g2p_dataset.phoneme2index = train_g2p_dataset.phoneme2index\n",
    "test_g2p_dataset.index2phoneme = train_g2p_dataset.index2phoneme\n",
    "test_g2p_dataset.n_phonemes = train_g2p_dataset.n_phonemes\n",
    "\n",
    "# Find the maximum output sequence length among graphemes and phonemes across all datasets\n",
    "MAX_LENGTH = -999\n",
    "for graphemes in train_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in train_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in val_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in val_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)\n",
    "for graphemes in test_g2p_dataset.graphemes_list :\n",
    "  if MAX_LENGTH < len(graphemes) :\n",
    "    MAX_LENGTH = len(graphemes)\n",
    "for phonemes in test_g2p_dataset.phonemes_list :\n",
    "  if MAX_LENGTH < len(phonemes) :\n",
    "    MAX_LENGTH = len(phonemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957721365,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "O9fmoIa9M6RG"
   },
   "outputs": [],
   "source": [
    "torch.save(train_g2p_dataset.index2grapheme, os.path.join(MODELS_DIR, \"id2grp.pth\"))\n",
    "torch.save(train_g2p_dataset.index2phoneme, os.path.join(MODELS_DIR, \"id2phn.pth\"))\n",
    "\n",
    "# Custom Collate function (for padding)\n",
    "def collate_fn(batch) :\n",
    "  # batch: [(input_seq, target_seq), ...]\n",
    "  graphemes, phonemes = zip(*batch)\n",
    "  # Pad sequences\n",
    "  graphemes_padded = pad_sequence([torch.tensor(x) for x in graphemes], padding_value=PAD_TOKEN)\n",
    "  phonemes_padded = pad_sequence([torch.tensor(y) for y in phonemes], padding_value=PAD_TOKEN)\n",
    "  return graphemes_padded, phonemes_padded\n",
    "\n",
    "train_dataloader = DataLoader(train_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)\n",
    "test_dataloader = DataLoader(test_g2p_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9rbldUGJN7b"
   },
   "source": [
    "## Turning grapheme and phoneme data to Tensors/Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "I2cem0ghY0mA"
   },
   "outputs": [],
   "source": [
    "def indexes_from_word(dataset, word, grp_type) :\n",
    "  assert grp_type in [\"unigram\", \"bigram\", \"trigram\"]\n",
    "  word = word.lower()\n",
    "  if grp_type == \"unigram\" :\n",
    "    graphemes = [*word]\n",
    "  elif grp_type == \"bigram\" :\n",
    "    graphemes = [word[i:i+2] for i in range(len(word)-1)] if len(word)>=2 else [word]\n",
    "  elif grp_type == \"trigram\" :\n",
    "    graphemes = [word[i:i+3] for i in range(len(word)-2)] if len(word)>=3 else [word]\n",
    "  return [dataset.grapheme2index.get(grapheme, UNK_TOKEN) for grapheme in graphemes] + [EOS_TOKEN]\n",
    "\n",
    "def variable_from_word(dataset, word, grp_type) :\n",
    "  indexes = indexes_from_word(dataset, word, grp_type)\n",
    "  var = torch.LongTensor(indexes).view(-1, 1).to(DEVICE)\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1739957721366,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "433SrerOr4_Y",
    "outputId": "92da8620-4d32-4614-db38-6fdfcd7e04fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 10, 19, 12, 26, 19, 8, 14, 19, 30, 6, 1]\n"
     ]
    }
   ],
   "source": [
    "print(indexes_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))\n",
    "# print(variable_from_word(train_g2p_dataset, \"menguncinya\", grp_type=GRP_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1522,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "vBgWZU1zZIEp",
    "outputId": "56a821f8-be28-4de8-8e2c-f5e7b8d2bc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.G2PDataset object at 0x7f9a4c49ef40> ([5, 5, 19, 30, 6, 1], [23, 3, 1])\n",
      "([5, 5, 19, 30, 6, 1], [23, 3, 1])\n",
      "([5, 5, 19, 30, 6, 1], [23, 3, 1])\n",
      "train grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "valid grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "test grp 32 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: '<UNK>', 4: \"'\", 5: '-', 6: 'a', 7: 'b', 8: 'c', 9: 'd', 10: 'e', 11: 'f', 12: 'g', 13: 'h', 14: 'i', 15: 'j', 16: 'k', 17: 'l', 18: 'm', 19: 'n', 20: 'o', 21: 'p', 22: 'q', 23: 'r', 24: 's', 25: 't', 26: 'u', 27: 'v', 28: 'w', 29: 'x', 30: 'y', 31: 'z'}\n",
      "train phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "valid phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "test phn 36 {0: '<SOS>', 1: '<EOS>', 2: '<PAD>', 3: 'AA', 4: 'AO', 5: 'AW', 6: 'AX', 7: 'AY', 8: 'B', 9: 'CH', 10: 'D', 11: 'EH', 12: 'EY', 13: 'F', 14: 'G', 15: 'HH', 16: 'IY', 17: 'JH', 18: 'K', 19: 'L', 20: 'M', 21: 'N', 22: 'NG', 23: 'NY', 24: 'OY', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'SH', 30: 'T', 31: 'UW', 32: 'V', 33: 'W', 34: 'Y', 35: 'Z'}\n",
      "28 {'-': 5, 'n': 19, 'y': 30, 'a': 6, 'b': 7, 'u': 26, 'r': 23, 'e': 10, 'l': 17, 's': 24, 'c': 8, 'o': 20, 'm': 18, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'i': 14, 'w': 28, 'd': 9, 't': 25, \"'\": 4, 'f': 11, 'j': 15, 'z': 31, 'v': 27, 'q': 22, 'x': 29}\n",
      "28 {'-': 5, 'n': 19, 'y': 30, 'a': 6, 'b': 7, 'u': 26, 'r': 23, 'e': 10, 'l': 17, 's': 24, 'c': 8, 'o': 20, 'm': 18, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'i': 14, 'w': 28, 'd': 9, 't': 25, \"'\": 4, 'f': 11, 'j': 15, 'z': 31, 'v': 27, 'q': 22, 'x': 29}\n",
      "28 {'-': 5, 'n': 19, 'y': 30, 'a': 6, 'b': 7, 'u': 26, 'r': 23, 'e': 10, 'l': 17, 's': 24, 'c': 8, 'o': 20, 'm': 18, 'p': 21, 'g': 12, 'k': 16, 'h': 13, 'i': 14, 'w': 28, 'd': 9, 't': 25, \"'\": 4, 'f': 11, 'j': 15, 'z': 31, 'v': 27, 'q': 22, 'x': 29}\n",
      "33 {'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'R': 27, 'AX': 6, 'L': 19, 'S': 28, 'CH': 9, 'AO': 4, 'M': 20, 'P': 25, 'EH': 11, 'NG': 22, 'K': 18, 'N': 21, 'HH': 15, 'G': 14, 'IY': 16, 'W': 33, 'D': 10, 'T': 30, 'Q': 26, 'AY': 7, 'AW': 5, 'F': 13, 'JH': 17, 'OY': 24, 'Y': 34, 'Z': 35, 'V': 32, 'SH': 29, 'EY': 12}\n",
      "33 {'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'R': 27, 'AX': 6, 'L': 19, 'S': 28, 'CH': 9, 'AO': 4, 'M': 20, 'P': 25, 'EH': 11, 'NG': 22, 'K': 18, 'N': 21, 'HH': 15, 'G': 14, 'IY': 16, 'W': 33, 'D': 10, 'T': 30, 'Q': 26, 'AY': 7, 'AW': 5, 'F': 13, 'JH': 17, 'OY': 24, 'Y': 34, 'Z': 35, 'V': 32, 'SH': 29, 'EY': 12}\n",
      "33 {'NY': 23, 'AA': 3, 'B': 8, 'UW': 31, 'R': 27, 'AX': 6, 'L': 19, 'S': 28, 'CH': 9, 'AO': 4, 'M': 20, 'P': 25, 'EH': 11, 'NG': 22, 'K': 18, 'N': 21, 'HH': 15, 'G': 14, 'IY': 16, 'W': 33, 'D': 10, 'T': 30, 'Q': 26, 'AY': 7, 'AW': 5, 'F': 13, 'JH': 17, 'OY': 24, 'Y': 34, 'Z': 35, 'V': 32, 'SH': 29, 'EY': 12}\n"
     ]
    }
   ],
   "source": [
    "print(train_g2p_dataset, train_dataloader.dataset[0])\n",
    "print(train_g2p_dataset[0])\n",
    "print(train_dataloader.dataset[0])\n",
    "print(\"train grp\", len(train_g2p_dataset.index2grapheme), train_g2p_dataset.index2grapheme)\n",
    "print(\"valid grp\", len(val_g2p_dataset.index2grapheme), val_g2p_dataset.index2grapheme)\n",
    "print(\"test grp\", len(test_g2p_dataset.index2grapheme), test_g2p_dataset.index2grapheme)\n",
    "print(\"train phn\", len(train_g2p_dataset.index2phoneme), train_g2p_dataset.index2phoneme)\n",
    "print(\"valid phn\", len(val_g2p_dataset.index2phoneme), val_g2p_dataset.index2phoneme)\n",
    "print(\"test phn\", len(test_g2p_dataset.index2phoneme), test_g2p_dataset.index2phoneme)\n",
    "print(len(train_g2p_dataset.grapheme2index), train_g2p_dataset.grapheme2index)\n",
    "print(len(val_g2p_dataset.grapheme2index), val_g2p_dataset.grapheme2index)\n",
    "print(len(test_g2p_dataset.grapheme2index), test_g2p_dataset.grapheme2index)\n",
    "print(len(train_g2p_dataset.phoneme2index), train_g2p_dataset.phoneme2index)\n",
    "print(len(val_g2p_dataset.phoneme2index), val_g2p_dataset.phoneme2index)\n",
    "print(len(test_g2p_dataset.phoneme2index), test_g2p_dataset.phoneme2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rR7MN5jhZKF_"
   },
   "source": [
    "## Model definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygVvCWJJZOeP"
   },
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "Q3UD4r8FZP5U"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module) :\n",
    "  def __init__(self, input_size, emb_dim, hidden_size, n_layers=1) -> None :\n",
    "    super(Encoder, self).__init__()\n",
    "    self.input_size = input_size\n",
    "    self.hidden_size = hidden_size\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.embedding = nn.Embedding(input_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim, hidden_size, n_layers, batch_first=False).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_inputs, hidden) :\n",
    "    embedded = self.embedding(token_inputs) # [seq_len, batch_size, emb_dim]\n",
    "    output, hidden = self.gru(embedded, hidden)\n",
    "    return output, hidden # output: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "  def init_hidden(self, batch_size=1) :\n",
    "    hidden = torch.zeros(self.n_layers, batch_size, self.hidden_size).to(DEVICE)\n",
    "    # hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVCH2fcZZRgY"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "P_7WmJUSZSgT"
   },
   "outputs": [],
   "source": [
    "class Attn(nn.Module) :\n",
    "  def __init__(self, method, hidden_size) -> None :\n",
    "    super(Attn, self).__init__()\n",
    "    self.method = method\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    if self.method == \"general\" :\n",
    "      self.attn = nn.Linear(self.hidden_size, hidden_size).to(DEVICE)\n",
    "    elif self.method == \"concat\" :\n",
    "      self.attn = nn.Linear(self.hidden_size*2, hidden_size).to(DEVICE)\n",
    "      self.v = nn.Parameter(torch.FloatTensor(hidden_size)).to(DEVICE)\n",
    "\n",
    "  def forward(self, hidden, encoder_outputs) :\n",
    "    # hidden shape: [1, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden_size]\n",
    "\n",
    "    if self.method == \"dot\" :\n",
    "      # Vectorized dot product for all positions in the sequence\n",
    "      attn_energies = torch.sum(hidden * encoder_outputs, dim=2) # [seq_len, batch_size]\n",
    "    elif self.method == \"general\" :\n",
    "      energy = self.attn(encoder_outputs) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(hidden * energy, dim=2)\n",
    "    elif self.method == \"concat\" :\n",
    "      hidden_expanded = hidden.expand(encoder_outputs.size(0), -1, -1) # [seq_len, batch_size, hidden_size]\n",
    "      energy = self.attn(torch.cat((hidden_expanded, encoder_outputs), 2)) # [seq_len, batch_size, hidden_size]\n",
    "      attn_energies = torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    # Normalize energies to weights\n",
    "    attn_weights = F.softmax(attn_energies, dim=0) # [seq_len, batch_size]\n",
    "    return attn_weights.transpose(0, 1).unsqueeze(1) # [batch_size, 1, seq_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLkvrRCoZWf3"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "oVtYeNNIZa8U"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module) :\n",
    "  def __init__(self, attn_model, emb_dim, hidden_size, output_size, n_layers=1, dropout_proba=.1) -> None :\n",
    "    super(Decoder, self).__init__()\n",
    "    self.attn_model = attn_model\n",
    "    self.hidden_size = hidden_size\n",
    "    self.output_size = output_size\n",
    "    self.n_layers = n_layers\n",
    "    self.dropout_proba = dropout_proba\n",
    "\n",
    "    # Define layers\n",
    "    self.embedding = nn.Embedding(output_size, emb_dim).to(DEVICE)\n",
    "    self.gru = nn.GRU(emb_dim + hidden_size, hidden_size, n_layers, dropout=dropout_proba, batch_first=False).to(DEVICE)\n",
    "    self.out = nn.Linear(hidden_size*2, output_size).to(DEVICE)\n",
    "\n",
    "    # Choose attention model\n",
    "    if attn_model != \"none\" :\n",
    "      self.attn = Attn(attn_model, hidden_size).to(DEVICE)\n",
    "\n",
    "  def forward(self, token_input, last_context, last_hidden, encoder_outputs) :\n",
    "    # token_input shape: [1, batch_size]\n",
    "    # last_context shape: [batch_size, hidden_size]\n",
    "    # last_hidden shape: [n_layers, batch_size, hidden_size]\n",
    "    # encoder_outputs shape: [seq_len, batch_size, hidden]\n",
    "    # Get the embedding of the current input token (last output token)\n",
    "\n",
    "    embedded = self.embedding(token_input) # [1, batch_size, emb_dim]\n",
    "    # Combine embedded input token and last context, run through RNN\n",
    "    rnn_input = torch.cat((embedded, last_context.unsqueeze(0)), dim=2) # [1, batch_size, emb_dim + hidden_size]\n",
    "    # GRU forward\n",
    "    rnn_output, hidden = self.gru(rnn_input, last_hidden) # rnn_output: [1, batch_size, hidden_size]\n",
    "\n",
    "    # Calculate attention from current RNN state and all encoder outputs; apply to encoder outputs\n",
    "    attn_weights = self.attn(rnn_output, encoder_outputs) # [batch_size, 1, seq_len]\n",
    "    context = torch.bmm(attn_weights, encoder_outputs.transpose(0, 1)) # [batch_size, 1, hidden_size]\n",
    "    context = context.transpose(0, 1) # [1, batch_size, hidden_size]\n",
    "\n",
    "    # Final output layer (next token prediction) using the RNN hidden state and context vector\n",
    "    rnn_output = rnn_output.squeeze(0)  # [batch_size, hidden_size]\n",
    "    context = context.squeeze(0)        # [batch_size, hidden_size]\n",
    "    output = torch.cat((rnn_output, context), dim=1) # [batch_size, hidden_size * 2]\n",
    "    output = F.log_softmax(self.out(output), dim=1) # [batch_size, output_size]\n",
    "\n",
    "    # Return final output, hidden state, and attention weights (for visualization)\n",
    "    return output, context, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mDO6QlJZpUZ"
   },
   "source": [
    "## Technical check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "kC8lx7n7Zr1Z",
    "outputId": "9a095505-f179-48d0-c305-f4e69125f170"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Input batch shape: torch.Size([4, 3])\n",
      "Encoder outputs shape: torch.Size([4, 3, 15])\n",
      "Encoder hidden shape: torch.Size([1, 3, 15])\n",
      "Step 0:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n",
      "Step 1:\n",
      "Decoder output shape: torch.Size([3, 100])\n",
      "Decoder context shape: torch.Size([3, 15])\n",
      "Decoder hidden shape: torch.Size([1, 3, 15])\n",
      "Attention shape: torch.Size([3, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# testing params\n",
    "batch_size = 3\n",
    "input_size = 100\n",
    "emb_dim = 25\n",
    "hidden_size = 15\n",
    "n_layers = 1\n",
    "\n",
    "# Init models\n",
    "encoder_test = Encoder(input_size, emb_dim, hidden_size, n_layers)\n",
    "decoder_test = Decoder(\"dot\", emb_dim, hidden_size, output_size=input_size, n_layers=n_layers)\n",
    "# Test encoder\n",
    "encoder_hidden = encoder_test.init_hidden(batch_size=batch_size)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "# Test input (seq_len=4, batch_size=3)\n",
    "input_batch = torch.LongTensor([[1,4,7], [2,5,8], [3,6,9], [4,7,10]]).to(DEVICE)\n",
    "print(\"Input batch shape:\", input_batch.shape)\n",
    "\n",
    "encoder_outputs, encoder_hidden = encoder_test(input_batch, encoder_hidden)\n",
    "print(\"Encoder outputs shape:\", encoder_outputs.shape)\n",
    "print(\"Encoder hidden shape:\", encoder_hidden.shape)\n",
    "\n",
    "# Test decoder\n",
    "decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE) # (1, batch_size)\n",
    "decoder_context = torch.zeros(batch_size, hidden_size).to(DEVICE) # (batch_size, hidden_size)\n",
    "decoder_hidden = encoder_hidden\n",
    "for di in range(2) :\n",
    "  decoder_output, decoder_context, decoder_hidden, attn = decoder_test(\n",
    "      decoder_input,\n",
    "      decoder_context,\n",
    "      decoder_hidden,\n",
    "      encoder_outputs\n",
    "  )\n",
    "  print(f\"Step {di}:\")\n",
    "  print(\"Decoder output shape:\", decoder_output.shape) # [batch_size, output_size]\n",
    "  print(\"Decoder context shape:\", decoder_context.shape)\n",
    "  print(\"Decoder hidden shape:\", decoder_hidden.shape) # [n_layers, batch_size, hidden_size]\n",
    "  print(\"Attention shape:\", attn.shape) # [batch_size, 1, seq_len]\n",
    "  decoder_input = torch.argmax(decoder_output, dim=1).unsqueeze(0) # Greedy decoding\n",
    "\n",
    "del encoder_test\n",
    "del decoder_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8eP0I6rZtvY"
   },
   "source": [
    "## Helper functions (for training log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "V-3uJwDCZvqz"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "def as_minutes(seconds) :\n",
    "  minutes = math.floor(seconds/60)\n",
    "  seconds -= minutes*60\n",
    "  return f\"{minutes}m {round(seconds, 2)}s\"\n",
    "\n",
    "def time_since(since, percent) :\n",
    "  now = time.time()\n",
    "  seconds = now - since\n",
    "  eta_seconds = seconds/(percent)\n",
    "  remaining_seconds = eta_seconds - seconds\n",
    "  return f\"{as_minutes(seconds)} (- {as_minutes(remaining_seconds)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbvh639cZxlA"
   },
   "source": [
    "## Train and validation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1739957722884,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "8l3KSCAaZy5K"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = .5\n",
    "\n",
    "def train_batch(input_batch, target_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion) :\n",
    "  encoder_optimizer.zero_grad()\n",
    "  decoder_optimizer.zero_grad()\n",
    "\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # # Debug: check for nan\n",
    "    # if torch.isnan(criterion(decoder_output, target_batch[di])).any() :\n",
    "    #   print(\"nan detected in decoder_output at step\", di)\n",
    "    #   print(f\"step {di}/{target_batch.size(0)-1}\")\n",
    "    #   print(f\"{di-1}:\\t{target_batch[di-1]}\")\n",
    "    #   for i in range(di, target_batch.size(0)) :\n",
    "    #     print(f\"{i}:\\t{target_batch[i]}\")\n",
    "    #   print(target_batch)\n",
    "    #   print(decoder_output.shape, target_batch[di].shape, criterion(decoder_output, target_batch[di]))\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Teacher forcing\n",
    "    decoder_input = target_batch[di].unsqueeze(0) if random.random() < teacher_forcing_ratio else decoder_output.argmax(1).unsqueeze(0)\n",
    "    decoder_input = decoder_input.to(DEVICE)\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  # Backpropagate loss\n",
    "  loss.backward()\n",
    "  encoder_optimizer.step()\n",
    "  decoder_optimizer.step()\n",
    "\n",
    "  return loss.item()\n",
    "\n",
    "def infer_batch(input_batch, target_batch, encoder, decoder, criterion) :\n",
    "  input_batch = input_batch.to(DEVICE)\n",
    "  target_batch = target_batch.to(DEVICE)\n",
    "\n",
    "  batch_size = input_batch.size(1)\n",
    "  # Forward through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_batch, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN] * batch_size]).to(DEVICE)\n",
    "  decoder_context = torch.zeros(batch_size, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  loss = 0\n",
    "  for di in range(target_batch.size(0)) :\n",
    "    decoder_output, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "        decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "      )\n",
    "    # Calculate loss for this step (sum over batch)\n",
    "    loss += criterion(decoder_output, target_batch[di])\n",
    "    # Greedy decoding without teacher forcing\n",
    "    topi = decoder_output.argmax(1)\n",
    "    decoder_input = topi.unsqueeze(0).detach() # detach from history\n",
    "\n",
    "  # Normalize loss\n",
    "  loss /= target_batch.size(0)\n",
    "\n",
    "  return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9nserDfZ4Xo"
   },
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1739957723364,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "s1JHP18oZ6zy",
    "outputId": "68700f7a-b173-4800-d808-8d922cd64e2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmadnaufalhakim/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_model: dot\n",
      "emb_dim: 64\n",
      "hidden_size: 50\n",
      "n_layers: 1\n",
      "Encoder has a total number of 19448 parameters\n",
      "Decoder has a total number of 30840 parameters\n",
      "Total number of all parameters is 50288\n"
     ]
    }
   ],
   "source": [
    "attn_model = ATTN_MODEL\n",
    "emb_dim = EMB_DIM\n",
    "hidden_size = HIDDEN_SIZE\n",
    "n_layers = N_LAYERS\n",
    "dropout_proba = DROPOUT_PROBA\n",
    "\n",
    "# Initialize models\n",
    "encoder = Encoder(train_g2p_dataset.n_graphemes, int(emb_dim), int(hidden_size), int(n_layers))\n",
    "decoder = Decoder(attn_model, int(emb_dim), int(hidden_size), train_g2p_dataset.n_phonemes, int(n_layers), dropout_proba=dropout_proba)\n",
    "n_encoder_parameters = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "n_decoder_parameters = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"attn_model: {attn_model}\")\n",
    "print(f\"emb_dim: {emb_dim}\")\n",
    "print(f\"hidden_size: {hidden_size}\")\n",
    "print(f\"n_layers: {n_layers}\")\n",
    "print(f\"Encoder has a total number of {n_encoder_parameters} parameters\")\n",
    "print(f\"Decoder has a total number of {n_decoder_parameters} parameters\")\n",
    "print(f\"Total number of all parameters is {n_encoder_parameters+n_decoder_parameters}\")\n",
    "\n",
    "# Move models to GPU\n",
    "encoder = encoder.to(DEVICE)\n",
    "decoder = decoder.to(DEVICE)\n",
    "\n",
    "# Learning rate and weight decay parameters\n",
    "learning_rate = .001\n",
    "weight_decay = 1e-5\n",
    "# Initialize optimizers and criterion\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss(ignore_index=PAD_TOKEN)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 999\n",
    "epochs_without_improvement = 0\n",
    "# Learning rate scheduling\n",
    "encoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(encoder_optimizer, factor=.5)\n",
    "decoder_scheduler = optim.lr_scheduler.ReduceLROnPlateau(decoder_optimizer, factor=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OI03JU0Z9dw"
   },
   "source": [
    "## Run the training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2952362,
     "status": "ok",
     "timestamp": 1739960675722,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "gP6Zh2q4aBvd",
    "outputId": "e9e1eaf7-3a18-4620-b007-cbad6be38496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 1 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 1 finished in 0m 8.68s (- 14m 19.17s) (1 1.0%). train avg loss: 2.0263, val avg loss: 1.9818\n",
      "Training for epoch 2 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 2 finished in 0m 16.91s (- 13m 48.39s) (2 2.0%). train avg loss: 1.3821, val avg loss: 1.6914\n",
      "Training for epoch 3 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 3 finished in 0m 24.51s (- 13m 12.35s) (3 3.0%). train avg loss: 0.8236, val avg loss: 0.9941\n",
      "Training for epoch 4 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 4 finished in 0m 32.74s (- 13m 5.69s) (4 4.0%). train avg loss: 0.4184, val avg loss: 0.738\n",
      "Training for epoch 5 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 5 finished in 0m 40.79s (- 12m 55.02s) (5 5.0%). train avg loss: 0.2731, val avg loss: 0.7072\n",
      "Training for epoch 6 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 6 finished in 0m 48.77s (- 12m 44.04s) (6 6.0%). train avg loss: 0.1953, val avg loss: 0.5495\n",
      "Training for epoch 7 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 7 finished in 0m 56.84s (- 12m 35.13s) (7 7.0%). train avg loss: 0.1537, val avg loss: 0.63\n",
      "Training for epoch 8 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 8 finished in 1m 4.84s (- 12m 25.61s) (8 8.0%). train avg loss: 0.1625, val avg loss: 0.4712\n",
      "Training for epoch 9 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 9 finished in 1m 12.57s (- 12m 13.78s) (9 9.0%). train avg loss: 0.1374, val avg loss: 0.5502\n",
      "Training for epoch 10 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 10 finished in 1m 20.16s (- 12m 1.42s) (10 10.0%). train avg loss: 0.1276, val avg loss: 0.3676\n",
      "Training for epoch 11 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 11 finished in 1m 28.26s (- 11m 54.09s) (11 11.0%). train avg loss: 0.0965, val avg loss: 0.4412\n",
      "Training for epoch 12 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 12 finished in 1m 36.12s (- 11m 44.85s) (12 12.0%). train avg loss: 0.0964, val avg loss: 0.3977\n",
      "Training for epoch 13 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 13 finished in 1m 43.65s (- 11m 33.63s) (13 13.0%). train avg loss: 0.0905, val avg loss: 0.4836\n",
      "Training for epoch 14 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 14 finished in 1m 51.6s (- 11m 25.57s) (14 14.0%). train avg loss: 0.0763, val avg loss: 0.3589\n",
      "Training for epoch 15 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 15 finished in 1m 59.57s (- 11m 17.59s) (15 15.0%). train avg loss: 0.0697, val avg loss: 0.3151\n",
      "Training for epoch 16 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 16 finished in 2m 7.31s (- 11m 8.38s) (16 16.0%). train avg loss: 0.0824, val avg loss: 0.3791\n",
      "Training for epoch 17 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 17 finished in 2m 15.22s (- 11m 0.17s) (17 17.0%). train avg loss: 0.0918, val avg loss: 0.4027\n",
      "Training for epoch 18 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 18 finished in 2m 23.3s (- 10m 52.83s) (18 18.0%). train avg loss: 0.0798, val avg loss: 0.3499\n",
      "Training for epoch 19 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 19 finished in 2m 31.12s (- 10m 44.24s) (19 19.0%). train avg loss: 0.0688, val avg loss: 0.3595\n",
      "Training for epoch 20 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 20 finished in 2m 38.9s (- 10m 35.62s) (20 20.0%). train avg loss: 0.0504, val avg loss: 0.4004\n",
      "Training for epoch 21 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 21 finished in 2m 46.94s (- 10m 28.02s) (21 21.0%). train avg loss: 0.0826, val avg loss: 0.4594\n",
      "Training for epoch 22 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 22 finished in 2m 55.09s (- 10m 20.78s) (22 22.0%). train avg loss: 0.0957, val avg loss: 0.3769\n",
      "Training for epoch 23 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 23 finished in 3m 2.86s (- 10m 12.17s) (23 23.0%). train avg loss: 0.0992, val avg loss: 0.373\n",
      "Training for epoch 24 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 24 finished in 3m 10.83s (- 10m 4.28s) (24 24.0%). train avg loss: 0.0766, val avg loss: 0.4246\n",
      "Training for epoch 25 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 25 finished in 3m 18.83s (- 9m 56.5s) (25 25.0%). train avg loss: 0.0628, val avg loss: 0.3799\n",
      "Training for epoch 26 has started (lr=0.001). Found 358 batch(es).\n",
      "Epoch 26 finished in 3m 27.0s (- 9m 49.14s) (26 26.0%). train avg loss: 0.0582, val avg loss: 0.3694\n",
      "Training for epoch 27 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 27 finished in 3m 35.33s (- 9m 42.18s) (27 27.0%). train avg loss: 0.0557, val avg loss: 0.3056\n",
      "Training for epoch 28 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 28 finished in 3m 43.34s (- 9m 34.3s) (28 28.0%). train avg loss: 0.0395, val avg loss: 0.3084\n",
      "Training for epoch 29 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 29 finished in 3m 51.13s (- 9m 25.88s) (29 29.0%). train avg loss: 0.0372, val avg loss: 0.3169\n",
      "Training for epoch 30 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 30 finished in 3m 59.01s (- 9m 17.68s) (30 30.0%). train avg loss: 0.0356, val avg loss: 0.3083\n",
      "Training for epoch 31 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 31 finished in 4m 7.41s (- 9m 10.69s) (31 31.0%). train avg loss: 0.0352, val avg loss: 0.2921\n",
      "Training for epoch 32 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 32 finished in 4m 15.44s (- 9m 2.81s) (32 32.0%). train avg loss: 0.0327, val avg loss: 0.3132\n",
      "Training for epoch 33 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 33 finished in 4m 23.1s (- 8m 54.16s) (33 33.0%). train avg loss: 0.0356, val avg loss: 0.2979\n",
      "Training for epoch 34 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 34 finished in 4m 31.24s (- 8m 46.52s) (34 34.0%). train avg loss: 0.0332, val avg loss: 0.3171\n",
      "Training for epoch 35 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 35 finished in 4m 39.21s (- 8m 38.53s) (35 35.0%). train avg loss: 0.036, val avg loss: 0.299\n",
      "Training for epoch 36 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 36 finished in 4m 47.37s (- 8m 30.89s) (36 36.0%). train avg loss: 0.0379, val avg loss: 0.2838\n",
      "Training for epoch 37 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 37 finished in 4m 55.17s (- 8m 22.59s) (37 37.0%). train avg loss: 0.0313, val avg loss: 0.3116\n",
      "Training for epoch 38 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 38 finished in 5m 3.09s (- 8m 14.52s) (38 38.0%). train avg loss: 0.0374, val avg loss: 0.2946\n",
      "Training for epoch 39 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 39 finished in 5m 11.01s (- 8m 6.45s) (39 39.0%). train avg loss: 0.0395, val avg loss: 0.3488\n",
      "Training for epoch 40 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 40 finished in 5m 19.33s (- 7m 58.99s) (40 40.0%). train avg loss: 0.0376, val avg loss: 0.2779\n",
      "Training for epoch 41 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 41 finished in 5m 27.92s (- 7m 51.89s) (41 41.0%). train avg loss: 0.0294, val avg loss: 0.2702\n",
      "Training for epoch 42 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 42 finished in 5m 35.79s (- 7m 43.72s) (42 42.0%). train avg loss: 0.0316, val avg loss: 0.2859\n",
      "Training for epoch 43 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 43 finished in 5m 43.72s (- 7m 35.63s) (43 43.0%). train avg loss: 0.0302, val avg loss: 0.2793\n",
      "Training for epoch 44 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 44 finished in 5m 52.2s (- 7m 28.26s) (44 44.0%). train avg loss: 0.03, val avg loss: 0.2969\n",
      "Training for epoch 45 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 45 finished in 6m 0.45s (- 7m 20.55s) (45 45.0%). train avg loss: 0.0278, val avg loss: 0.3246\n",
      "Training for epoch 46 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 46 finished in 6m 8.31s (- 7m 12.36s) (46 46.0%). train avg loss: 0.0277, val avg loss: 0.3094\n",
      "Training for epoch 47 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 47 finished in 6m 16.69s (- 7m 4.78s) (47 47.0%). train avg loss: 0.0315, val avg loss: 0.3202\n",
      "Training for epoch 48 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 48 finished in 6m 24.94s (- 6m 57.02s) (48 48.0%). train avg loss: 0.0325, val avg loss: 0.3435\n",
      "Training for epoch 49 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 49 finished in 6m 32.99s (- 6m 49.03s) (49 49.0%). train avg loss: 0.029, val avg loss: 0.3064\n",
      "Training for epoch 50 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 50 finished in 6m 41.43s (- 6m 41.43s) (50 50.0%). train avg loss: 0.028, val avg loss: 0.2931\n",
      "Training for epoch 51 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 51 finished in 6m 49.89s (- 6m 33.81s) (51 51.0%). train avg loss: 0.0277, val avg loss: 0.3378\n",
      "Training for epoch 52 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 52 finished in 6m 57.43s (- 6m 25.32s) (52 52.0%). train avg loss: 0.0338, val avg loss: 0.2438\n",
      "Training for epoch 53 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 53 finished in 7m 5.38s (- 6m 17.22s) (53 53.0%). train avg loss: 0.0336, val avg loss: 0.2761\n",
      "Training for epoch 54 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 54 finished in 7m 13.45s (- 6m 9.23s) (54 54.0%). train avg loss: 0.0314, val avg loss: 0.4008\n",
      "Training for epoch 55 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 55 finished in 7m 21.7s (- 6m 1.39s) (55 55.0%). train avg loss: 0.0319, val avg loss: 0.3137\n",
      "Training for epoch 56 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 56 finished in 7m 29.75s (- 5m 53.37s) (56 56.0%). train avg loss: 0.0244, val avg loss: 0.3311\n",
      "Training for epoch 57 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 57 finished in 7m 37.83s (- 5m 45.38s) (57 57.0%). train avg loss: 0.0257, val avg loss: 0.2461\n",
      "Training for epoch 58 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 58 finished in 7m 45.77s (- 5m 37.28s) (58 58.0%). train avg loss: 0.0253, val avg loss: 0.2858\n",
      "Training for epoch 59 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 59 finished in 7m 53.75s (- 5m 29.22s) (59 59.0%). train avg loss: 0.0279, val avg loss: 0.3029\n",
      "Training for epoch 60 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 60 finished in 8m 1.96s (- 5m 21.3s) (60 60.0%). train avg loss: 0.0306, val avg loss: 0.2712\n",
      "Training for epoch 61 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 61 finished in 8m 10.47s (- 5m 13.58s) (61 61.0%). train avg loss: 0.0265, val avg loss: 0.3077\n",
      "Training for epoch 62 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 62 finished in 8m 18.41s (- 5m 5.47s) (62 62.0%). train avg loss: 0.0307, val avg loss: 0.2391\n",
      "Training for epoch 63 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 63 finished in 8m 26.11s (- 4m 57.24s) (63 63.0%). train avg loss: 0.0249, val avg loss: 0.3049\n",
      "Training for epoch 64 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 64 finished in 8m 34.25s (- 4m 49.27s) (64 64.0%). train avg loss: 0.0225, val avg loss: 0.3433\n",
      "Training for epoch 65 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 65 finished in 8m 42.14s (- 4m 41.15s) (65 65.0%). train avg loss: 0.0253, val avg loss: 0.2983\n",
      "Training for epoch 66 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 66 finished in 8m 50.32s (- 4m 33.2s) (66 66.0%). train avg loss: 0.0252, val avg loss: 0.3417\n",
      "Training for epoch 67 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 67 finished in 8m 58.34s (- 4m 25.15s) (67 67.0%). train avg loss: 0.0245, val avg loss: 0.3002\n",
      "Training for epoch 68 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 68 finished in 9m 6.47s (- 4m 17.16s) (68 68.0%). train avg loss: 0.0232, val avg loss: 0.3572\n",
      "Training for epoch 69 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 69 finished in 9m 14.48s (- 4m 9.11s) (69 69.0%). train avg loss: 0.0216, val avg loss: 0.3407\n",
      "Training for epoch 70 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 70 finished in 9m 22.76s (- 4m 1.18s) (70 70.0%). train avg loss: 0.0261, val avg loss: 0.2944\n",
      "Training for epoch 71 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 71 finished in 9m 30.56s (- 3m 53.05s) (71 71.0%). train avg loss: 0.0286, val avg loss: 0.3072\n",
      "Training for epoch 72 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 72 finished in 9m 38.34s (- 3m 44.91s) (72 72.0%). train avg loss: 0.0231, val avg loss: 0.3039\n",
      "Training for epoch 73 has started (lr=0.0005). Found 358 batch(es).\n",
      "Epoch 73 finished in 9m 47.1s (- 3m 37.15s) (73 73.0%). train avg loss: 0.022, val avg loss: 0.3396\n",
      "Training for epoch 74 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 74 finished in 9m 55.6s (- 3m 29.26s) (74 74.0%). train avg loss: 0.0247, val avg loss: 0.3645\n",
      "Training for epoch 75 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 75 finished in 10m 3.45s (- 3m 21.15s) (75 75.0%). train avg loss: 0.0254, val avg loss: 0.3603\n",
      "Training for epoch 76 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 76 finished in 10m 11.38s (- 3m 13.07s) (76 76.0%). train avg loss: 0.0198, val avg loss: 0.3652\n",
      "Training for epoch 77 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 77 finished in 10m 19.99s (- 3m 5.19s) (77 77.0%). train avg loss: 0.0211, val avg loss: 0.3131\n",
      "Training for epoch 78 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 78 finished in 10m 28.31s (- 2m 57.22s) (78 78.0%). train avg loss: 0.0232, val avg loss: 0.341\n",
      "Training for epoch 79 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 79 finished in 10m 36.35s (- 2m 49.16s) (79 79.0%). train avg loss: 0.0191, val avg loss: 0.3561\n",
      "Training for epoch 80 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 80 finished in 10m 44.68s (- 2m 41.17s) (80 80.0%). train avg loss: 0.0204, val avg loss: 0.3339\n",
      "Training for epoch 81 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 81 finished in 10m 53.2s (- 2m 33.22s) (81 81.0%). train avg loss: 0.0204, val avg loss: 0.3769\n",
      "Training for epoch 82 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 82 finished in 11m 1.19s (- 2m 25.14s) (82 82.0%). train avg loss: 0.02, val avg loss: 0.3699\n",
      "Training for epoch 83 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 83 finished in 11m 9.14s (- 2m 17.05s) (83 83.0%). train avg loss: 0.0197, val avg loss: 0.3824\n",
      "Training for epoch 84 has started (lr=0.00025). Found 358 batch(es).\n",
      "Epoch 84 finished in 11m 17.65s (- 2m 9.08s) (84 84.0%). train avg loss: 0.0196, val avg loss: 0.4\n",
      "Training for epoch 85 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 85 finished in 11m 25.87s (- 2m 1.04s) (85 85.0%). train avg loss: 0.0184, val avg loss: 0.3562\n",
      "Training for epoch 86 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 86 finished in 11m 34.02s (- 1m 52.98s) (86 86.0%). train avg loss: 0.0197, val avg loss: 0.3473\n",
      "Training for epoch 87 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 87 finished in 11m 42.22s (- 1m 44.93s) (87 87.0%). train avg loss: 0.0189, val avg loss: 0.3706\n",
      "Training for epoch 88 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 88 finished in 11m 50.44s (- 1m 36.88s) (88 88.0%). train avg loss: 0.0179, val avg loss: 0.3711\n",
      "Training for epoch 89 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 89 finished in 11m 58.59s (- 1m 28.81s) (89 89.0%). train avg loss: 0.0173, val avg loss: 0.4304\n",
      "Training for epoch 90 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 90 finished in 12m 6.86s (- 1m 20.76s) (90 90.0%). train avg loss: 0.0173, val avg loss: 0.4223\n",
      "Training for epoch 91 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 91 finished in 12m 16.1s (- 1m 12.8s) (91 91.0%). train avg loss: 0.019, val avg loss: 0.3832\n",
      "Training for epoch 92 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 92 finished in 12m 24.76s (- 1m 4.76s) (92 92.0%). train avg loss: 0.0172, val avg loss: 0.4285\n",
      "Training for epoch 93 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 93 finished in 12m 33.08s (- 0m 56.68s) (93 93.0%). train avg loss: 0.0183, val avg loss: 0.3885\n",
      "Training for epoch 94 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 94 finished in 12m 42.88s (- 0m 48.69s) (94 94.0%). train avg loss: 0.0166, val avg loss: 0.3854\n",
      "Training for epoch 95 has started (lr=0.000125). Found 358 batch(es).\n",
      "Epoch 95 finished in 12m 51.38s (- 0m 40.6s) (95 95.0%). train avg loss: 0.0172, val avg loss: 0.4199\n",
      "Training for epoch 96 has started (lr=6.25e-05). Found 358 batch(es).\n",
      "Epoch 96 finished in 12m 59.8s (- 0m 32.49s) (96 96.0%). train avg loss: 0.0156, val avg loss: 0.4029\n",
      "Training for epoch 97 has started (lr=6.25e-05). Found 358 batch(es).\n",
      "Epoch 97 finished in 13m 8.31s (- 0m 24.38s) (97 97.0%). train avg loss: 0.0163, val avg loss: 0.4064\n",
      "Training for epoch 98 has started (lr=6.25e-05). Found 358 batch(es).\n",
      "Epoch 98 finished in 13m 16.46s (- 0m 16.25s) (98 98.0%). train avg loss: 0.0171, val avg loss: 0.4066\n",
      "Training for epoch 99 has started (lr=6.25e-05). Found 358 batch(es).\n",
      "Epoch 99 finished in 13m 24.5s (- 0m 8.13s) (99 99.0%). train avg loss: 0.0163, val avg loss: 0.392\n",
      "Training for epoch 100 has started (lr=6.25e-05). Found 358 batch(es).\n",
      "Epoch 100 finished in 13m 33.12s (- 0m 0.0s) (100 100.0%). train avg loss: 0.0177, val avg loss: 0.3984\n"
     ]
    }
   ],
   "source": [
    "# Training configurations\n",
    "n_epochs = 100\n",
    "# Keep track of time elapsed and running averages\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# Keep track of the best validation set loss\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs+1) :\n",
    "  # Set both encoder and decoder to training mode\n",
    "  encoder.train()\n",
    "  decoder.train()\n",
    "  print(f\"Training for epoch {epoch} has started (lr={encoder_optimizer.param_groups[0]['lr']}). Found {len(train_dataloader)} batch(es).\")\n",
    "  # Training\n",
    "  total_train_loss = 0\n",
    "  total_train_tokens = 0\n",
    "  for batch, (grps, phns) in enumerate(train_dataloader) :\n",
    "    # Count tokens (excluding padding)\n",
    "    total_train_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "    # Train and get loss\n",
    "    unweighted_train_loss = train_batch(grps, phns, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    # Track train loss for logging\n",
    "    total_train_loss += unweighted_train_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Set both encoder and decoder to evaluation mode\n",
    "  encoder.eval()\n",
    "  decoder.eval()\n",
    "  # Validation\n",
    "  with torch.no_grad() :\n",
    "    total_val_loss = 0\n",
    "    total_val_tokens = 0\n",
    "    for grps, phns in valid_dataloader :\n",
    "      # Count tokens (excluding padding)\n",
    "      total_val_tokens += (phns!=PAD_TOKEN).sum().item()\n",
    "      # Infer and get loss\n",
    "      val_loss = infer_batch(grps, phns, encoder, decoder, criterion)\n",
    "      # Track val loss for logging\n",
    "      total_val_loss += val_loss * (phns!=PAD_TOKEN).sum().item()\n",
    "\n",
    "  # Calculate epoch metrics\n",
    "  avg_train_loss = total_train_loss/total_train_tokens\n",
    "  avg_val_loss = total_val_loss/total_val_tokens\n",
    "  print(f\"Epoch {epoch} finished in {time_since(start, epoch/n_epochs)} ({epoch} {epoch*100/n_epochs}%). train avg loss: {round(avg_train_loss, 4)}, val avg loss: {round(avg_val_loss, 4)}\")\n",
    "\n",
    "  # Update schedulers based on validation loss\n",
    "  encoder_scheduler.step(avg_val_loss)\n",
    "  decoder_scheduler.step(avg_val_loss)\n",
    "\n",
    "  # Save the losses for visualization\n",
    "  train_losses.append(avg_train_loss)\n",
    "  val_losses.append(avg_val_loss)\n",
    "\n",
    "  # Save the model if the validation loss is better than the previous iterations' validation loss\n",
    "  if avg_val_loss < best_val_loss :\n",
    "    epochs_without_improvement = 0\n",
    "    if epoch > 1 :\n",
    "      previous_best_encoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      previous_best_decoder = [f for f in os.listdir(MODELS_DIR) if f.startswith(f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}\")][0]\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_encoder))\n",
    "      os.remove(os.path.join(MODELS_DIR, previous_best_decoder))\n",
    "    torch.save(encoder.state_dict(), os.path.join(MODELS_DIR, f\"train-encoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    torch.save(decoder.state_dict(), os.path.join(MODELS_DIR, f\"train-decoder-wdecay_1e_5-attn_{attn_model}-emb_{emb_dim}-hddn_{hidden_size}-layers_{n_layers}-epoch_{epoch}.pth\"))\n",
    "    best_val_loss = avg_val_loss\n",
    "  else :\n",
    "    epochs_without_improvement += 1\n",
    "    if epochs_without_improvement >= patience :\n",
    "      print(f\"Early stopping after {epoch} epochs\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvWFlA69aJXJ"
   },
   "source": [
    "## Visualize training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "-498emHUaNzb",
    "outputId": "bab4a42d-c2d8-4a89-c7a9-eb0ace0bc12c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_plot(**kwargs) :\n",
    "  plt.figure()\n",
    "  fig, ax = plt.subplots()\n",
    "  # This locator puts ticks at regular intervals\n",
    "  loc = ticker.MultipleLocator(base=.2)\n",
    "  ax.yaxis.set_major_locator(loc)\n",
    "  plt.title(\"Loss\")\n",
    "  legends = []\n",
    "  for k, v in kwargs.items() :\n",
    "    plt.plot(v)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    legends.append(k)\n",
    "    if k == \"val\" :\n",
    "      # Find the minimum value and its index\n",
    "      min_value = min(v)\n",
    "      min_index = v.index(min_value)\n",
    "      # Plot a red dot at the minimum value\n",
    "      plt.plot(min_index, min_value, \"ro\")\n",
    "      # Add text box in the middle of the plot showing the minimum value\n",
    "      plt.text(min_index-5.25, min_value+.15, f\"{min_value:.4f}\", bbox=dict(facecolor=\"white\", alpha=.5))\n",
    "  plt.legend(legends)\n",
    "\n",
    "show_plot(train=train_losses, val=val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8q3Ubs5aUWa"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgFQoUrINk_L"
   },
   "source": [
    "### Helper functions to evaluate encoder-decoder attention model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1739960676044,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "wHJTHcbONu7W"
   },
   "outputs": [],
   "source": [
    "def evaluate(word, max_length=MAX_LENGTH) :\n",
    "  # Convert word to tensor with batch dimension\n",
    "  input_variable = variable_from_word(test_g2p_dataset, word, grp_type=GRP_TYPE) # Already in [seq_len, 1]\n",
    "\n",
    "  # Run through encoder\n",
    "  encoder_hidden = encoder.init_hidden(batch_size=1)\n",
    "  encoder_outputs, encoder_hidden = encoder(input_variable, encoder_hidden)\n",
    "  # Prepare decoder inputs\n",
    "  decoder_input = torch.LongTensor([[SOS_TOKEN]]).to(DEVICE) # [1, 1]\n",
    "  decoder_context = torch.zeros(1, decoder.hidden_size).to(DEVICE)\n",
    "  decoder_hidden = encoder_hidden # Use last hidden state from encoder to start decoder\n",
    "\n",
    "  decoded_phonemes = []\n",
    "  attentions = torch.zeros(max_length, max_length)\n",
    "  for di in range(max_length) :\n",
    "    decoder_output, decoder_context, decoder_hidden, attn_weights = decoder(\n",
    "      decoder_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "    )\n",
    "    # Store attention\n",
    "    attentions[di, :attn_weights.size(2)] += attn_weights.squeeze(0).squeeze(0).cpu().data\n",
    "    # Get most likely token\n",
    "    topv, topi = decoder_output.data.topk(1)\n",
    "    ni = topi[0][0]\n",
    "    if ni.item() == EOS_TOKEN :\n",
    "      decoded_phonemes.append(\"<EOS>\")\n",
    "      break\n",
    "    else :\n",
    "      decoded_phonemes.append(test_g2p_dataset.index2phoneme[ni.item()])\n",
    "    # Next input is predicted token\n",
    "    decoder_input = torch.LongTensor([[ni.item()]]).to(DEVICE)\n",
    "\n",
    "  return decoded_phonemes, attentions[:di+1, 1:len(encoder_outputs)]\n",
    "\n",
    "def evaluate_randomly() :\n",
    "  pair = random.choice(pairs)\n",
    "  word, _, _, arpabet_phoneme_sequence = pair\n",
    "\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  output_phoneme_sequence = ' '.join(output_phonemes)\n",
    "  label_phonemes = arpabet_phoneme_sequence.split()\n",
    "\n",
    "  print('>', word)\n",
    "  print('=', label_phonemes)\n",
    "  print('<', output_phoneme_sequence, output_phonemes)\n",
    "  print('')\n",
    "  return pair, output_phonemes, decoder_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hedzsfDAM_LC"
   },
   "source": [
    "### Using `val` set (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 67072,
     "status": "ok",
     "timestamp": 1739960743114,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "MlSPdqo3QDyr",
    "outputId": "364c407d-3bb7-4fd9-ac12-19a8480c9076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone error rate (PER) on test set: 4.0401014217885525%\n"
     ]
    }
   ],
   "source": [
    "# Total Phone Error Rate (PER)\n",
    "total_per = .0\n",
    "for pair in val_pairs :\n",
    "  word, _, _, arpabet_phoneme_sequence = pair\n",
    "  output_phonemes, decoder_attns = evaluate(word, len(word)+1)\n",
    "  try :\n",
    "    output_phonemes.remove(\"<EOS>\")\n",
    "  except ValueError as e :\n",
    "    pass\n",
    "  total_per += wer(\n",
    "    arpabet_phoneme_sequence,\n",
    "    ' '.join(output_phonemes)\n",
    "  )\n",
    "average_per = total_per / len(val_pairs)\n",
    "print(f\"Phone error rate (PER) on test set: {average_per*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-yQDWj6lNzOZ"
   },
   "source": [
    "### Using randomly chosen words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1739961996036,
     "user": {
      "displayName": "23522026 Ahmad Naufal Hakim",
      "userId": "16621933245327613442"
     },
     "user_tz": -420
    },
    "id": "HSHGOjSmc3Vi",
    "outputId": "7c2a7917-9217-4397-8be2-0c96496d6b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> keresek\n",
      "= ['K', 'AX', 'R', 'EH', 'S', 'EH', 'Q']\n",
      "< K AX R EH S EH Q ['K', 'AX', 'R', 'EH', 'S', 'EH', 'Q']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98a9a189d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 420x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pair, output_phonemes, decoder_attns = evaluate_randomly()\n",
    "plt.matshow(decoder_attns.numpy())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLJmB0V/sNcUHuHtZcdQwt",
   "collapsed_sections": [
    "8mDO6QlJZpUZ",
    "T8eP0I6rZtvY"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
